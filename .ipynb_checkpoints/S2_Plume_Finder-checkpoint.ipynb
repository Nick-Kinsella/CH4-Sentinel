{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f561c3-51d4-4476-922d-876088df12c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentinel 2 CH4 Multi Band Multi Pass Mapper\n",
    "\n",
    "## Overview \n",
    "Varon et al. (2021) showed that methane plumes from point sources could be imaged by differencing Sentinel-2’s SWIR-1 and SWIR-2 bands. The tool runs an analysis using a  multi-band-multi-pass retrieval method: \n",
    "\n",
    "First it calculates a multi-band-single-pass calculation for both active emission and no emission dates, resulting in two datasets which are then used together for a multi-band-multi-pass method. \n",
    "The multi-band-single-pass equation is as follows: \n",
    "\n",
    "\n",
    "<div align=\"center\"><b>MBSP = B11 - cB12</b></div>\n",
    "\n",
    "Where:\n",
    "- B12 is the Sentinel-2 SWIR-2 band.\n",
    "- B11 is the Sentinel-2 SWIR-1 band. \n",
    "- c is calculated by least-squares fitting B12 to B11 across the scene.  \n",
    "\n",
    "Once active emission and no emission scenes have been calculated, the following equation is used to calculate the multi-band-multi-pass raster. \n",
    "\n",
    "<div align=\"center\"><b>MBMP = ActiveMBSP − NoMBSP</b></div>\n",
    "\n",
    "Where:\n",
    "- ActiveMBSP is the multiband single pass for the active emission scene\n",
    "- NoMBSP is the multiband single pass for the no emission scene.  \n",
    "\n",
    "The active emission scene and no emission scene are considered in this analysis to be one satelite pass apart.\n",
    "\n",
    "The section below imports the packages needed to run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9cfbc-e95b-4685-a7e2-19f2ccc7cf3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import folium\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import openeo\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.plot import show\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import numpy as np\n",
    "import requests\n",
    "from folium import Map, GeoJson, LayerControl, LatLngPopup\n",
    "from folium.raster_layers import ImageOverlay\n",
    "from IPython.display import display as ipy_display\n",
    "from skimage import exposure\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.ndimage import label\n",
    "from scipy.spatial import ConvexHull\n",
    "from shapely.geometry import Point, LineString\n",
    "from sklearn.decomposition import PCA\n",
    "import cdsapi\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tempfile import NamedTemporaryFile\n",
    "from folium import FeatureGroup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67714102-a656-4414-9e45-42c8c80460ea",
   "metadata": {},
   "source": [
    "## Connect to OpenEO\n",
    "\n",
    "The code below establishes a connection with the Copernicus openEO platform which provides a wide variety of earth observation datasets\n",
    "\n",
    "- If this does not read as 'Authorised successfully' or 'Authenticated using refresh token', then please ensure that you have completed the setup steps as outlined in section 2.3.6 of the how to guide. \n",
    "\n",
    "- If you have followed the steps in section 2.3.6 correctly and the problem persists, please look at https://dataspace.copernicus.eu/news for any information about service interruptions. \n",
    "\n",
    "- If there is no news of service problems you can raise a ticket here: https://helpcenter.dataspace.copernicus.eu/hc/en-gb/requests/new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfface4-832c-4c3b-b79c-a6886878cd83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "connection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\n",
    "connection.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d0674c-3b9c-4ab0-aafe-0526baa82e66",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Study Area. \n",
    "\n",
    "This loads the boudings for the oil and gas fields in Algeria. Hassi Messaoud is site 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110af1e-a1d9-4fb8-8663-51d279eac192",
   "metadata": {},
   "outputs": [],
   "source": [
    "studysite_csv = pandas.read_csv(r'C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\Algerian_Oil_and_Gas_Fields.csv')\n",
    "pandas.set_option('display.max_rows', None)\n",
    "print(studysite_csv.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0fbd3c-c769-490c-b130-5784a8138114",
   "metadata": {},
   "source": [
    "# Available dates for the analysis. \n",
    "\n",
    "Sentinel 2 provides data aproximately once every 3 days, so not every date you can enter into this tool is valid. The code below will tell you what dates are available to use for the oil/gas field of your choice. \n",
    "\n",
    "The two parameters you need to modify before running the code are: \n",
    "- site_id = 86 (change this to your chosen study site) \n",
    "- temporal_extent = [\"2023-01-31\", \"2023-03-12\"] (change this to your chosen date range using \"YYYY-MM-DD\" format)\n",
    "\n",
    "Once you have done this run the code and the available dates should appear below in a matter of seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb8600-dfdd-491b-bde9-2eaa760af099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spatial_extent(site_id):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "    return {\n",
    "        \"west\": site['west'],\n",
    "        \"south\": site['south'],\n",
    "        \"east\": site['east'],\n",
    "        \"north\": site['north']\n",
    "    }\n",
    "\n",
    "def fetch_available_dates(site_id, temporal_extent):\n",
    "    spatial_extent = get_spatial_extent(site_id)\n",
    "    catalog_url = f\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?box={spatial_extent['west']}%2C{spatial_extent['south']}%2C{spatial_extent['east']}%2C{spatial_extent['north']}&sortParam=startDate&sortOrder=ascending&page=1&maxRecords=1000&status=ONLINE&dataset=ESA-DATASET&productType=L2A&startDate={temporal_extent[0]}T00%3A00%3A00Z&completionDate={temporal_extent[1]}T00%3A00%3A00Z&cloudCover=%5B0%2C{cloud_cover}%5D\"\n",
    "    response = requests.get(catalog_url)\n",
    "    response.raise_for_status()\n",
    "    catalog = response.json()\n",
    "    dates = [date.split('T')[0] for date in map(lambda x: x['properties']['startDate'], catalog['features'])]\n",
    "    return dates\n",
    "\n",
    "# Please enter your perameters here.\n",
    "site_id = 86 # Specify the oil and gas field ID\n",
    "temporal_extent = [\"2020-01-01\", \"2020-01-31\"]  # Specify the the date range you want to check for available data.\n",
    "cloud_cover = 5\n",
    "\n",
    "available_dates = fetch_available_dates(site_id, temporal_extent)\n",
    "print(\"Available dates:\", available_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c953b692-eb71-4c15-b3d3-95025f77bcc4",
   "metadata": {},
   "source": [
    "## Choosing the Active Emission Date\n",
    "\n",
    "As mentioned in the overview, an active emission date must be chosen from one of the available datasets. \n",
    "\n",
    "Like before, the two parameters you need to modify before running the code are:\n",
    "\n",
    "- site_id = 86 (change this to your chosen study site)\n",
    "- temporal_extent = [\"2023-02-25\", \"2023-02-25\"] (change this to your chosen date range using \"YYYY-MM-DD\" format.) \n",
    "\n",
    "Please note that the temporal extent dates <u>MUST BE IDENTICAL</u> because we are only choosing a single date.\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a709165f-4542-46da-af8e-a7199df573c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_emission(site_id, temporal_extent):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    active_emission = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B11\", \"B12\"],\n",
    "    )\n",
    "    active_emission.download(\"Sentinel-2_active_emissionMBMP.Tiff\")\n",
    "\n",
    "# Enter perameters for the active emission day\n",
    "site_id = 86  # Specify the oil and gas field ID\n",
    "temporal_extent = [\"2020-01-04\", \"2020-01-04\"]\n",
    "\n",
    "active_emission(site_id, temporal_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc9eea-43af-400e-822f-725ce1afb0b2",
   "metadata": {},
   "source": [
    "## Choosing the No Emission Date\n",
    "\n",
    "Next we choose the no emission date using the same process. \n",
    "\n",
    "The two parameters you need to modify before running the code are:\n",
    "\n",
    "- site_id = 86 (change this to your chosen site)\n",
    "- temporal_extent = [\"2023-02-25\", \"2023-02-25\"] (change this to your chosen date range using \"YYYY-MM-DD\" format.) \n",
    "\n",
    "The temporal extent dates <u>MUST BE IDENTICAL</u>\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74d95f-bc49-4233-b767-6a1daaaf68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_emission(site_id, temporal_extent):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    no_emission = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B11\", \"B12\"],\n",
    "    )\n",
    "    no_emission.download(\"Sentinel-2_no_emissionMBMP.Tiff\")\n",
    "\n",
    "# Enter perameters for the active emission day\n",
    "site_id = 86  # Specify the oil and gas field ID\n",
    "temporal_extent = [\"2020-01-02\", \"2020-01-02\"]\n",
    "\n",
    "no_emission(site_id, temporal_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de701594-5589-41ad-8750-5a57f70cc130",
   "metadata": {},
   "source": [
    "## Choosing a Background Satelite Image\n",
    "\n",
    "This section helps with locating the source of the emission at the landfill by displaying a true colour satelite image of the landfill that the data will be superimposed over. I recommend choosing the same date as your active emission. \n",
    "\n",
    "Once again, the two parameters you need to modify before running the code are:\n",
    "\n",
    "- site_id = 86 (change this to your chosen site)\n",
    "- temporal_extent = [\"2023-02-25\", \"2023-02-25\"] (change this to your chosen date range using \"YYYY-MM-DD\" format.)\n",
    "\n",
    "The temporal extent dates <u>MUST BE IDENTICAL</u>\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9db215-2b88-4bf4-b65c-06dc75e94a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_to_epsg4326(data, meta):\n",
    "    \"\"\"\n",
    "    Reprojects the given raster data to EPSG:4326 and returns the updated data and metadata.\n",
    "    \"\"\"\n",
    "    target_crs = \"EPSG:4326\"\n",
    "    \n",
    "    # Calculate transform and metadata for the target CRS\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        meta['crs'], target_crs, meta['width'], meta['height'], *meta['bounds']\n",
    "    )\n",
    "    \n",
    "    # Update metadata for the new projection\n",
    "    new_meta = meta.copy()\n",
    "    new_meta.update({\n",
    "        \"crs\": target_crs,\n",
    "        \"transform\": transform,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "    })\n",
    "    \n",
    "    # Prepare an in-memory array for reprojected data\n",
    "    reprojected_data = []\n",
    "    for i in range(meta['count']):\n",
    "        # Create an empty numpy array to store the reprojected data for the band\n",
    "        destination = np.empty((height, width), dtype=data[i].dtype)\n",
    "        reproject(\n",
    "            source=data[i],\n",
    "            destination=destination,\n",
    "            src_transform=meta['transform'],\n",
    "            src_crs=meta['crs'],\n",
    "            dst_transform=transform,\n",
    "            dst_crs=target_crs,\n",
    "            resampling=Resampling.nearest\n",
    "        )\n",
    "        reprojected_data.append(destination)\n",
    "    \n",
    "    return reprojected_data, new_meta\n",
    "\n",
    "def truecolour_image(site_id, temporal_extent):\n",
    "    \"\"\"\n",
    "    Downloads and reprojects Sentinel-2 true-colour images for a given site and temporal extent.\n",
    "    \"\"\"\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    truecolour_image = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B02\", \"B03\", \"B04\"],\n",
    "    )\n",
    "    # Download the true colour image\n",
    "    file_path = \"Sentinel-2_truecolourMBMP.Tiff\"\n",
    "    truecolour_image.download(file_path)\n",
    "    \n",
    "    # Read the file into memory\n",
    "    with rasterio.open(file_path) as src:\n",
    "        data = [src.read(i) for i in range(1, src.count + 1)]\n",
    "        meta = src.meta.copy()\n",
    "        meta['bounds'] = src.bounds\n",
    "\n",
    "    # Reproject the data in memory\n",
    "    reprojected_data, reprojected_meta = reproject_to_epsg4326(data, meta)\n",
    "    \n",
    "    # Save the reprojected file\n",
    "    output_file = \"Sentinel-2_truecolour_reprojected.Tiff\"\n",
    "    with rasterio.open(output_file, \"w\", **reprojected_meta) as dest:\n",
    "        for i, band in enumerate(reprojected_data, start=1):\n",
    "            dest.write(band, i)\n",
    "    \n",
    "    # Print the CRS of the output file\n",
    "    with rasterio.open(output_file) as reprojected_file:\n",
    "        print(\"CRS of the reprojected file:\", reprojected_file.crs)\n",
    "\n",
    "# Enter parameters for the no emission day\n",
    "site_id = 86  # Specify the oil and gas field ID\n",
    "temporal_extent = [\"2020-01-04\", \"2020-01-04\"]\n",
    "\n",
    "truecolour_image(site_id, temporal_extent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fde51c-73cf-4816-b880-bf4715dc35aa",
   "metadata": {},
   "source": [
    "## Running Plume Visualiser Analysis\n",
    "The code below will use the satelite data to display any plumes above 1,400kgh-1. Provided all the variables above have been run correctly, this next section should take moments to complete. \n",
    "\n",
    "Three peramaters can to be adjusted.\n",
    "\n",
    "site_id = 86 (change this to your chosen site)\n",
    "brightness_factor = 0.05 (occasionally the true colour satelite image can be too bright or too dark. You can change this number to fix it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e39a4-71fd-4190-9838-2348bd4ee736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get bounds from the Oil and Gas Field bounding file\n",
    "def get_bounds(site_id, csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    site = df[df['id'] == site_id]\n",
    "    if site.empty:\n",
    "        raise ValueError(f\"Site ID {site_id} not found in the CSV file.\")\n",
    "    site = site.iloc[0]\n",
    "    return [[site['south'], site['west']], [site['north'], site['east']]]\n",
    "\n",
    "# Specify the site ID and input paths\n",
    "site_id = 86\n",
    "csv_path = r'C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\Algerian_Oil_and_Gas_Fields.csv'\n",
    "bounds = get_bounds(site_id, csv_path)\n",
    "\n",
    "# Define file paths\n",
    "Active_Multiband = \"Sentinel-2_active_emissionMBMP.Tiff\"\n",
    "No_Multiband = \"Sentinel-2_no_emissionMBMP.Tiff\"\n",
    "output_file = \"SWIR_diff_4326.tiff\"\n",
    "\n",
    "# Define a function for least squares fitting\n",
    "def least_squares_fit(x, y):\n",
    "    mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x_valid = x[mask]\n",
    "    y_valid = y[mask]\n",
    "    A = np.vstack([x_valid, np.ones_like(x_valid)]).T\n",
    "    m, c = np.linalg.lstsq(A, y_valid, rcond=None)[0]\n",
    "    return m, c\n",
    "\n",
    "# Open datasets and perform least squares fitting\n",
    "with rasterio.open(Active_Multiband) as Active_img, rasterio.open(No_Multiband) as No_img:\n",
    "    Active_B11 = Active_img.read(1)\n",
    "    Active_B12 = Active_img.read(2)\n",
    "    No_B11 = No_img.read(1)\n",
    "    No_B12 = No_img.read(2)\n",
    "\n",
    "    m_active, c_active = least_squares_fit(Active_B11.flatten(), Active_B12.flatten())\n",
    "    Corrected_Active_B12 = m_active * Active_B12 + c_active\n",
    "\n",
    "    m_no, c_no = least_squares_fit(No_B11.flatten(), No_B12.flatten())\n",
    "    Corrected_No_B12 = m_no * No_B12 + c_no\n",
    "\n",
    "    SWIR_diff = (Active_B11 - Corrected_Active_B12) - (No_B11 - Corrected_No_B12)\n",
    "    min_value = np.min(SWIR_diff)\n",
    "    if min_value < 0:\n",
    "        SWIR_diff = SWIR_diff - min_value\n",
    "\n",
    "# Reproject and save SWIR_diff to EPSG:4326\n",
    "with rasterio.open(Active_Multiband) as src:\n",
    "    target_crs = \"EPSG:4326\"\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, target_crs, src.width, src.height, *src.bounds\n",
    "    )\n",
    "    meta = src.meta.copy()\n",
    "    meta.update({\n",
    "        \"crs\": target_crs,\n",
    "        \"transform\": transform,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"count\": 1,\n",
    "        \"dtype\": SWIR_diff.dtype\n",
    "    })\n",
    "    with rasterio.open(output_file, \"w\", **meta) as dest:\n",
    "        reproject(\n",
    "            source=SWIR_diff,\n",
    "            destination=rasterio.band(dest, 1),\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=transform,\n",
    "            dst_crs=target_crs,\n",
    "            resampling=Resampling.nearest\n",
    "        )\n",
    "\n",
    "# Calculate center for map\n",
    "center_lat = (bounds[0][0] + bounds[1][0]) / 2\n",
    "center_lon = (bounds[0][1] + bounds[1][1]) / 2\n",
    "\n",
    "# Create Folium map\n",
    "m = Map(location=[center_lat, center_lon], zoom_start=10, control_scale=True)\n",
    "\n",
    "# Load and stretch SWIR_diff for visualization\n",
    "with rasterio.open(output_file) as src:\n",
    "    swir_bounds = [[src.bounds.bottom, src.bounds.left], [src.bounds.top, src.bounds.right]]\n",
    "    swir_data = src.read(1)\n",
    "    nodata_value = src.nodata if src.nodata is not None else -9999\n",
    "    swir_data = np.ma.masked_equal(swir_data, nodata_value)\n",
    "\n",
    "    # Apply stretching logic\n",
    "    mean = np.nanmean(swir_data)\n",
    "    std = np.nanstd(swir_data)\n",
    "    std_factor = 2  # Stretch factor\n",
    "    lower_bound = mean - std_factor * std\n",
    "    upper_bound = mean + std_factor * std\n",
    "    normalized_swir_data = (swir_data - lower_bound) / (upper_bound - lower_bound)\n",
    "    normalized_swir_data = np.clip(normalized_swir_data, 0, 1)\n",
    "\n",
    "    # Apply colormap\n",
    "    cmap = plt.get_cmap('plasma')\n",
    "    rgb_data = (cmap(normalized_swir_data)[:, :, :3] * 255).astype(np.uint8)\n",
    "\n",
    "# Load the true color image\n",
    "truecolour_sat = 'Sentinel-2_truecolour_reprojected.Tiff'\n",
    "img = rasterio.open(truecolour_sat)\n",
    "blue, green, red = img.read(1), img.read(2), img.read(3)\n",
    "\n",
    "# Adjust brightness dynamically\n",
    "brightness_factor = 0.03\n",
    "blue = np.clip(blue * brightness_factor, 0, 255)\n",
    "green = np.clip(green * brightness_factor, 0, 255)\n",
    "red = np.clip(red * brightness_factor, 0, 255)\n",
    "\n",
    "# Stack bands to create RGB image\n",
    "rgb = np.dstack((red, green, blue))\n",
    "rgb = rgb / rgb.max()\n",
    "rgb = np.log1p(rgb)\n",
    "rgb = rgb / rgb.max()\n",
    "\n",
    "# Add true color image overlay\n",
    "truecolour_overlay = ImageOverlay(\n",
    "    image=rgb,\n",
    "    bounds=swir_bounds,\n",
    "    opacity=1,  # Lower opacity for blending with SWIR overlay\n",
    "    interactive=True,\n",
    "    cross_origin=False,\n",
    "    zindex=1,  # Lower zindex to place below SWIR overlay\n",
    ")\n",
    "truecolour_overlay.add_to(m)\n",
    "\n",
    "# Add SWIR_diff overlay to map\n",
    "swir_overlay = ImageOverlay(\n",
    "    image=rgb_data,\n",
    "    bounds=swir_bounds,\n",
    "    opacity=1,  # Adjust opacity for visibility\n",
    "    interactive=True,\n",
    "    zindex=2  # Ensure SWIR overlay is above other layers\n",
    ")\n",
    "swir_overlay.add_to(m)\n",
    "\n",
    "# Add GeoJSON data as a layer group\n",
    "vector_point_path = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\known_point_sources.geojson\"\n",
    "gdf = gpd.read_file(vector_point_path)\n",
    "geojson_layer = FeatureGroup(name=\"Known Point Sources\", show=False)\n",
    "GeoJson(gdf.to_json()).add_to(geojson_layer)\n",
    "geojson_layer.add_to(m)\n",
    "\n",
    "# Layer control\n",
    "LayerControl().add_to(m)\n",
    "m.add_child(LatLngPopup())\n",
    "\n",
    "# Display map\n",
    "display(m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8623c7-0247-4561-b42d-3e5922b60225",
   "metadata": {},
   "source": [
    "## Plume tagging\n",
    "\n",
    "Maually input plume source coordinates here in the format (latitude, longitude), for example:  \n",
    "    (31.6887, 5.8102),  # Plume 1 (latitude, longitude)  \n",
    "    (31.7910, 5.8263),  # Plume 2 (latitude, longitude)  \n",
    "etc...\n",
    "\n",
    "Plumes that are segmented will need to have each of their segmets taged to be included in the analysis. Additional lines for more plumes can be added as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6528c93-29a2-4f84-8943-d5008410194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_coords = [\n",
    "    (31.8645, 6.1735),  # Plume 1 (latitude, longitude)\n",
    "    (31.8615, 6.2555),  # Plume 2 (latitude, longitude)\n",
    "    (31.6327, 6.0850),  # Plume 3 (latitude, longitude)\n",
    "    (31.6459, 5.9953),  # Plume 4 (latitude, longitude)\n",
    "    (31.7825, 5.8437),  # Plume 5 (latitude, longitude)\n",
    "    (31.8920, 6.0056),  # Plume 6 (latitude, longitude)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1567e74-955f-4dbb-b8ac-7b9c1b68671e",
   "metadata": {},
   "source": [
    "## Training data for regression model\n",
    "These are plumes taken from peer reviewed sources. They will be used to train the regression model that this system employs to estimate emission rate. Should more example plume data be found, it can be added here to improve the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eff60e-16cc-4173-817f-8e9d758da69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial dataset for regression model (Add new plumes directly here as needed)\n",
    "initial_data = {\n",
    "    \"Adjusted_Sum\": [1157.180431, 5595.239521, 4520.473715, 320.936628, 343.933175, 366.843504],\n",
    "    \"Width_px\": [13, 74, 42, 13, 8, 7],\n",
    "    \"Wind_speed\": [4.37, 3.65, 0.51, 0.92, 0.92, 0.92],\n",
    "    \"Emission_rate_kg_h\": [5453, 21000, 8500, 4326, 2160, 2757],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf9ea84-33c0-40b7-a932-2709086f888a",
   "metadata": {},
   "source": [
    "## Detemining wind speed\n",
    "\n",
    "This section determines the wind speed as part of the gas flux calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0feeddb-5d92-4834-b681-d64679f6a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract bounding box and calculate center from site_id\n",
    "def get_location_from_site_id(site_id, csv_path):\n",
    "    \"\"\"\n",
    "    Extract center latitude and longitude for a site based on site_id.\n",
    "\n",
    "    Args:\n",
    "    - site_id (int): The ID of the site to extract.\n",
    "    - csv_path (str): Path to the CSV containing site boundaries.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary with latitude and longitude of the center.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    site = df[df['id'] == site_id]\n",
    "    if site.empty:\n",
    "        raise ValueError(f\"Site ID {site_id} not found in the CSV file.\")\n",
    "    site = site.iloc[0]\n",
    "    center_lat = (site['south'] + site['north']) / 2\n",
    "    center_lon = (site['west'] + site['east']) / 2\n",
    "    return {'latitude': center_lat, 'longitude': center_lon}\n",
    "\n",
    "# Example: Define the site_id and path to the CSV file\n",
    "site_id = 86\n",
    "\n",
    "# Get the location for the ERA5 data request\n",
    "location = get_location_from_site_id(site_id, csv_path)\n",
    "\n",
    "# Initialize the CDS API client\n",
    "c = cdsapi.Client()\n",
    "\n",
    "# Define parameters for the data request\n",
    "date = '2020-01-04'\n",
    "\n",
    "# Retrieve ERA5 data and store it in a temporary file\n",
    "with NamedTemporaryFile(suffix='.nc') as tmp_file:\n",
    "    result = c.retrieve(\n",
    "        'reanalysis-era5-single-levels',\n",
    "        {\n",
    "            'product_type': 'reanalysis',\n",
    "            'variable': ['10m_u_component_of_wind', '10m_v_component_of_wind'],\n",
    "            'year': date.split('-')[0],\n",
    "            'month': date.split('-')[1],\n",
    "            'day': date.split('-')[2],\n",
    "            'time': ['10:00'],  # Specify time of interest\n",
    "            'format': 'netcdf',  # NetCDF format\n",
    "            'area': [\n",
    "                location['latitude'] + 0.25, location['longitude'] - 0.25,\n",
    "                location['latitude'] - 0.25, location['longitude'] + 0.25,\n",
    "            ],  # Small bounding box around the location\n",
    "        }\n",
    "    )\n",
    "    # Download data to the temporary file\n",
    "    result.download(tmp_file.name)\n",
    "    \n",
    "    # Load the dataset with xarray\n",
    "    ds = xr.open_dataset(tmp_file.name)\n",
    "\n",
    "# Extract u and v components\n",
    "u10 = ds['u10'].sel(latitude=location['latitude'], longitude=location['longitude'], method='nearest')\n",
    "v10 = ds['v10'].sel(latitude=location['latitude'], longitude=location['longitude'], method='nearest')\n",
    "\n",
    "# Calculate wind speed\n",
    "wind_speed = np.sqrt(u10**2 + v10**2)\n",
    "\n",
    "# Handle single timestep case\n",
    "if 'time' in u10.dims:\n",
    "    # Multiple timesteps (not likely in this case since we specified 10:00 only)\n",
    "    for time, speed in zip(u10.time.values, wind_speed.values):\n",
    "        print(f\"{time}: Wind Speed = {speed:.2f} m/s\")\n",
    "else:\n",
    "    # Single timestep\n",
    "    wind_speed_value = wind_speed.values.item()  # Convert array to scalar\n",
    "    print(f\"Wind Speed at 10:00 on {date}: {wind_speed_value:.2f} m/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3930168-7e93-4e4c-9f83-011f6f6ea8c7",
   "metadata": {},
   "source": [
    "## Running the tagged plume analysis\n",
    "\n",
    "This section loads the SWIR data and loads the colourmap in preparation for the analysis. It also provides the average/mean value of the dataset, allowing us to see how much a plume rises above background levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ddc9d-9dfa-4b93-a935-df53d8ceb5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TIFF file and perform initial processing\n",
    "swir_diff_path = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\SWIR_diff_4326.tiff\"\n",
    "\n",
    "with rasterio.open(swir_diff_path) as tiff_file:\n",
    "    raster_data = tiff_file.read(1)  # Read the first band\n",
    "    nodata_value = tiff_file.nodata if tiff_file.nodata is not None else -9999\n",
    "    bounds = tiff_file.bounds\n",
    "    transform = tiff_file.transform\n",
    "\n",
    "# Mask nodata values\n",
    "masked_data = np.ma.masked_equal(raster_data, nodata_value)\n",
    "\n",
    "# Calculate statistical values\n",
    "mean, std = np.nanmean(masked_data), np.nanstd(masked_data)\n",
    "std_factor = 2\n",
    "lower_bound, upper_bound = mean - std_factor * std, mean + std_factor * std\n",
    "normalized_data = (masked_data - lower_bound) / (upper_bound - lower_bound)\n",
    "normalized_data = np.clip(normalized_data, 0, 1)  # Clip to [0, 1]\n",
    "\n",
    "# Calculate the median value of the dataset\n",
    "dataset_median_value = np.ma.median(masked_data)\n",
    "print(f\"Median value of the dataset: {dataset_median_value}\")\n",
    "\n",
    "# Apply colormap\n",
    "cmap = plt.get_cmap('plasma')\n",
    "rgb_data = (cmap(normalized_data)[:, :, :3] * 255).astype(np.uint8)\n",
    "\n",
    "# Initialize the map\n",
    "center_lat = (bounds.top + bounds.bottom) / 2\n",
    "center_lon = (bounds.left + bounds.right) / 2\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=11, control_scale=True)\n",
    "\n",
    "# Define helper functions\n",
    "def get_raster_center(tiff_path):\n",
    "    with rasterio.open(tiff_path) as tiff_file:\n",
    "        bounds = tiff_file.bounds\n",
    "        center_lat = (bounds.top + bounds.bottom) / 2\n",
    "        center_lon = (bounds.left + bounds.right) / 2\n",
    "    return center_lat, center_lon\n",
    "\n",
    "def calculate_plume_width_pixels(plume_pixels, perp_direction):\n",
    "    perp_vector = np.array(perp_direction)\n",
    "    perp_vector = perp_vector / np.linalg.norm(perp_vector)\n",
    "    projections = plume_pixels @ perp_vector\n",
    "    return projections.ptp()  # Peak-to-peak width in the projection space\n",
    "\n",
    "def bresenham_line(x0, y0, x1, y1):\n",
    "    points = []\n",
    "    dx = abs(x1 - x0)\n",
    "    dy = abs(y1 - y0)\n",
    "    sx = 1 if x0 < x1 else -1\n",
    "    sy = 1 if y0 < y1 else -1\n",
    "    err = dx - dy\n",
    "\n",
    "    while True:\n",
    "        points.append((x0, y0))\n",
    "        if x0 == x1 and y0 == y1:\n",
    "            break\n",
    "        e2 = err * 2\n",
    "        if e2 > -dy:\n",
    "            err -= dy\n",
    "            x0 += sx\n",
    "        if e2 < dx:\n",
    "            err += dx\n",
    "            y0 += sy\n",
    "    return points\n",
    "\n",
    "def get_line_pixel_values(start, end, masked_data):\n",
    "    line_pixels = bresenham_line(int(start[0]), int(start[1]), int(end[0]), int(end[1]))\n",
    "    pixel_values = [masked_data[row, col] for row, col in line_pixels if 0 <= row < masked_data.shape[0] and 0 <= col < masked_data.shape[1]]\n",
    "    return pixel_values\n",
    "\n",
    "def count_line_pixels(start, end):\n",
    "    line_pixels = bresenham_line(int(start[0]), int(start[1]), int(end[0]), int(end[1]))\n",
    "    return len(line_pixels)\n",
    "\n",
    "def analyze_plume_with_cross_section_sum(masked_data, plume_coords, transform, initial_center):\n",
    "    plume_map = folium.Map(location=initial_center, zoom_start=11, control_scale=True)\n",
    "    plume_results = []\n",
    "    labeled_array, _ = label(masked_data > np.percentile(masked_data.compressed(), 80))\n",
    "\n",
    "    for i, (lat, lon) in enumerate(plume_coords):\n",
    "        try:\n",
    "            row, col = rasterio.transform.rowcol(transform, lon, lat)\n",
    "            row, col = int(row), int(col)\n",
    "            plume_label = labeled_array[row, col]\n",
    "            if plume_label == 0:\n",
    "                plume_results.append({\"Plume\": i + 1, \"Location (lat, lon)\": (lat, lon), \"Status\": \"No plume detected\"})\n",
    "                continue\n",
    "\n",
    "            plume_region = labeled_array == plume_label\n",
    "            plume_pixels = np.column_stack(np.where(plume_region))\n",
    "            pca = PCA(n_components=2)\n",
    "            pca.fit(plume_pixels)\n",
    "            perp_direction = [-pca.components_[0, 1], pca.components_[0, 0]]\n",
    "\n",
    "            plume_width_pixels = calculate_plume_width_pixels(plume_pixels, perp_direction)\n",
    "\n",
    "            centroid = plume_pixels.mean(axis=0)\n",
    "            perp_line_coords = [\n",
    "                (centroid[0] - perp_direction[0] * plume_width_pixels / 2, centroid[1] - perp_direction[1] * plume_width_pixels / 2),\n",
    "                (centroid[0] + perp_direction[0] * plume_width_pixels / 2, centroid[1] + perp_direction[1] * plume_width_pixels / 2),\n",
    "            ]\n",
    "\n",
    "            line_pixel_values = get_line_pixel_values(perp_line_coords[0], perp_line_coords[1], masked_data)\n",
    "            num_intersecting_pixels = count_line_pixels(perp_line_coords[0], perp_line_coords[1])\n",
    "\n",
    "            pixel_value_sum = sum(line_pixel_values)\n",
    "            adjusted_sum = pixel_value_sum - (dataset_median_value * num_intersecting_pixels)\n",
    "\n",
    "            perp_line_latlon = [\n",
    "                rasterio.transform.xy(transform, int(pt[0]), int(pt[1])) for pt in perp_line_coords\n",
    "            ]\n",
    "            folium.PolyLine(\n",
    "                locations=[(lat, lon) for lon, lat in perp_line_latlon],\n",
    "                color=\"red\",\n",
    "                weight=2,\n",
    "                opacity=0.8,\n",
    "                tooltip=f\"Plume {i + 1} Width Measurement\",\n",
    "            ).add_to(plume_map)\n",
    "\n",
    "            hull = ConvexHull(plume_pixels)\n",
    "            hull_coords = [(plume_pixels[vertex][0], plume_pixels[vertex][1]) for vertex in hull.vertices]\n",
    "            hull_latlon = [rasterio.transform.xy(transform, int(pt[0]), int(pt[1])) for pt in hull_coords]\n",
    "            folium.Polygon(\n",
    "                locations=[(lat, lon) for lon, lat in hull_latlon],\n",
    "                color=\"blue\",\n",
    "                weight=2,\n",
    "                fill=False,\n",
    "                popup=f\"Plume {i + 1} region\",\n",
    "            ).add_to(plume_map)\n",
    "\n",
    "            plume_results.append({\n",
    "                \"Plume\": i + 1,\n",
    "                \"Location (lat, lon)\": (lat, lon),\n",
    "                \"Intersecting Pixels\": num_intersecting_pixels,\n",
    "                \"Pixel Value Sum\": pixel_value_sum,\n",
    "                \"Adjusted Sum\": adjusted_sum\n",
    "            })\n",
    "        except Exception as e:\n",
    "            plume_results.append({\"Plume\": i + 1, \"Location (lat, lon)\": (lat, lon), \"Status\": f\"Error: {e}\"})\n",
    "    return plume_results, plume_map\n",
    "\n",
    "def add_swir_data_to_map(map_object, tiff_path):\n",
    "    with rasterio.open(tiff_path) as tiff_file:\n",
    "        swir_data = tiff_file.read(1)\n",
    "        bounds = tiff_file.bounds\n",
    "        nodata_value = tiff_file.nodata if tiff_file.nodata is not None else -9999\n",
    "    masked_data = np.ma.masked_equal(swir_data, nodata_value)\n",
    "    mean, std = np.nanmean(masked_data), np.nanstd(masked_data)\n",
    "    lower_bound, upper_bound = mean - 2 * std, mean + 2 * std\n",
    "    normalized_data = (masked_data - lower_bound) / (upper_bound - lower_bound)\n",
    "    normalized_data = np.clip(normalized_data, 0, 1)\n",
    "    cmap = plt.get_cmap(\"plasma\")\n",
    "    swir_rgb = (cmap(normalized_data)[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_bounds = [[bounds.bottom, bounds.left], [bounds.top, bounds.right]]\n",
    "    ImageOverlay(image=swir_rgb, bounds=image_bounds, opacity=1).add_to(map_object)\n",
    "\n",
    "# Convert the dataset into a DataFrame\n",
    "model_df = pd.DataFrame(initial_data)\n",
    "\n",
    "# Function to fit and update the regression model\n",
    "def update_model(df):\n",
    "    \"\"\"\n",
    "    Update the regression model based on the current dataset.\n",
    "\n",
    "    Args:\n",
    "    - df: DataFrame containing the plume data.\n",
    "\n",
    "    Returns:\n",
    "    - Updated regression model parameters as a dictionary.\n",
    "    \"\"\"\n",
    "    # Prepare features (X) and target (y)\n",
    "    X = df[[\"Adjusted_Sum\", \"Width_px\", \"Wind_speed\"]]\n",
    "    y = df[\"Emission_rate_kg_h\"]\n",
    "\n",
    "    # Fit the regression model\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X, y)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = reg.predict(X)\n",
    "    print(\"Model Evaluation:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mean_squared_error(y, y_pred):.2f}\")\n",
    "    print(f\"R-squared (R²): {r2_score(y, y_pred):.2f}\")\n",
    "\n",
    "    # Plot actual vs predicted emission rates\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y, y_pred, color=\"blue\", label=\"Predicted vs Actual\")\n",
    "    plt.plot([min(y), max(y)], [min(y), max(y)], color=\"red\", label=\"Ideal Fit Line\")\n",
    "    plt.xlabel(\"Actual Emission Rate (kg/h)\")\n",
    "    plt.ylabel(\"Predicted Emission Rate (kg/h)\")\n",
    "    plt.title(\"Regression Analysis: Actual vs Predicted\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Return updated model parameters\n",
    "    return {\n",
    "        \"intercept\": reg.intercept_,\n",
    "        \"CS_Sum_coef\": reg.coef_[0],\n",
    "        \"Width_px_coef\": reg.coef_[1],\n",
    "        \"Wind_speed_coef\": reg.coef_[2],\n",
    "    }\n",
    "\n",
    "# Update the model with the initial data\n",
    "model_params = update_model(model_df)\n",
    "\n",
    "# Get the center of the SWIR TIFF\n",
    "center_coords = get_raster_center(swir_diff_path)\n",
    "\n",
    "# Perform plume analysis, centering the map on the SWIR TIFF\n",
    "plume_analysis_results, plume_map = analyze_plume_with_cross_section_sum(masked_data, plume_coords, transform, center_coords)\n",
    "\n",
    "# Add wind speed to each plume analysis result\n",
    "wind_speed_value = 2.0  # Example wind speed value\n",
    "for plume in plume_analysis_results:\n",
    "    if \"Adjusted Sum\" in plume:\n",
    "        adjusted_sum = plume[\"Adjusted Sum\"]\n",
    "        width_px = plume[\"Intersecting Pixels\"]\n",
    "        emission_rate = (\n",
    "            model_params[\"intercept\"]\n",
    "            + model_params[\"CS_Sum_coef\"] * adjusted_sum\n",
    "            + model_params[\"Width_px_coef\"] * width_px\n",
    "            + model_params[\"Wind_speed_coef\"] * wind_speed_value\n",
    "        )\n",
    "        plume[\"Predicted Emission Rate (kg/h)\"] = emission_rate\n",
    "\n",
    "# Convert updated results to a DataFrame\n",
    "plume_df = pd.DataFrame(plume_analysis_results)\n",
    "plume_df.set_index(\"Plume\", inplace=True)\n",
    "\n",
    "# Display updated DataFrame with predicted emission rates\n",
    "print(\"Plume Analysis Results with Predicted Emission Rates:\")\n",
    "print(plume_df)\n",
    "\n",
    "# Add SWIR overlay to the map\n",
    "add_swir_data_to_map(plume_map, swir_diff_path)\n",
    "\n",
    "# Add true color image overlay\n",
    "truecolor_overlay = ImageOverlay(\n",
    "    image=rgb_data,\n",
    "    bounds=[[bounds.bottom, bounds.left], [bounds.top, bounds.right]],\n",
    "    opacity=1,\n",
    "    interactive=True,\n",
    "    cross_origin=False,\n",
    "    zindex=1,\n",
    ")\n",
    "truecolor_overlay.add_to(plume_map)\n",
    "\n",
    "# Add a layer control to toggle map layers\n",
    "LayerControl().add_to(plume_map)\n",
    "\n",
    "# Display the map with updated analysis\n",
    "ipy_display(plume_map)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
