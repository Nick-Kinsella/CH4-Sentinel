{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f561c3-51d4-4476-922d-876088df12c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentinel 2 CH4 Multi Band Multi Pass Mapper\n",
    "\n",
    "## Overview \n",
    "Varon et al. (2021) showed that methane plumes from point sources could be imaged by differencing Sentinel-2’s SWIR-1 and SWIR-2 bands. The tool runs an analysis using a  multi-band-multi-pass retrieval method: \n",
    "\n",
    "First it calculates a multi-band-single-pass calculation for both active emission and no emission dates, resulting in two datasets which are then used together for a multi-band-multi-pass method. \n",
    "The multi-band-single-pass equation is as follows: \n",
    "\n",
    "\n",
    "<div align=\"center\"><b>MBSP = B11 - cB12</b></div>\n",
    "\n",
    "Where:\n",
    "- B12 is the Sentinel-2 SWIR-2 band.\n",
    "- B11 is the Sentinel-2 SWIR-1 band. \n",
    "- c is calculated by least-squares fitting B12 to B11 across the scene.  \n",
    "\n",
    "Once active emission and no emission scenes have been calculated, the following equation is used to calculate the multi-band-multi-pass raster. \n",
    "\n",
    "<div align=\"center\"><b>MBMP = ActiveMBSP − NoMBSP</b></div>\n",
    "\n",
    "Where:\n",
    "- ActiveMBSP is the multiband single pass for the active emission scene\n",
    "- NoMBSP is the multiband single pass for the no emission scene.  \n",
    "\n",
    "The active emission scene and no emission scene are considered in this analysis to be one satelite pass apart.\n",
    "\n",
    "The section below imports the packages needed to run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9cfbc-e95b-4685-a7e2-19f2ccc7cf3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import folium\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import openeo\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import numpy as np\n",
    "import requests\n",
    "from folium import Map, LayerControl, LatLngPopup, GeoJson\n",
    "from folium.raster_layers import ImageOverlay\n",
    "from IPython.display import display\n",
    "from skimage import exposure\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.ndimage import label\n",
    "from scipy.spatial import ConvexHull\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67714102-a656-4414-9e45-42c8c80460ea",
   "metadata": {},
   "source": [
    "## Connect to OpenEO\n",
    "\n",
    "The code below establishes a connection with the Copernicus openEO platform which provides a wide variety of earth observation datasets\n",
    "\n",
    "- If this does not read as 'Authorised successfully' or 'Authenticated using refresh token', then please ensure that you have completed the setup steps as outlined in section 2.6 of the user guide. \n",
    "\n",
    "- If you have followed the steps in section 2.6 correctly and the problem persists, please look at https://dataspace.copernicus.eu/news for any information about service interruptions. \n",
    "\n",
    "- If there is no news of service problems you can raise a ticket here: https://helpcenter.dataspace.copernicus.eu/hc/en-gb/requests/new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfface4-832c-4c3b-b79c-a6886878cd83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "connection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\n",
    "connection.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d0674c-3b9c-4ab0-aafe-0526baa82e66",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Study Area. \n",
    "\n",
    "This loads the boudings for the oil and gas fields in Algeria. Hassi Messaoud is site 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110af1e-a1d9-4fb8-8663-51d279eac192",
   "metadata": {},
   "outputs": [],
   "source": [
    "studysite_csv = pandas.read_csv(r'C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\Algerian_Oil_and_Gas_Fields.csv')\n",
    "pandas.set_option('display.max_rows', None)\n",
    "print(studysite_csv.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0fbd3c-c769-490c-b130-5784a8138114",
   "metadata": {},
   "source": [
    "# Available dates for the analysis. \n",
    "\n",
    "Sentinel 2 provides data aproximately once every 3 days, so not every date you can enter into this tool is valid. The code below will tell you what dates are available to use for the landfill of your choice. \n",
    "\n",
    "The two parameters you need to modify before running the code are: \n",
    "- landfill_id = 86 (change this to your chosen study site) \n",
    "- temporal_extent = [\"2023-01-31\", \"2023-03-12\"] (change this to your chosen date range using \"YYYY-MM-DD\" format)\n",
    "\n",
    "Once you have done this run the code and the available dates should appear below in a matter of seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb8600-dfdd-491b-bde9-2eaa760af099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spatial_extent(site_id):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "    return {\n",
    "        \"west\": site['west'],\n",
    "        \"south\": site['south'],\n",
    "        \"east\": site['east'],\n",
    "        \"north\": site['north']\n",
    "    }\n",
    "\n",
    "def fetch_available_dates(site_id, temporal_extent):\n",
    "    spatial_extent = get_spatial_extent(site_id)\n",
    "    catalog_url = f\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?box={spatial_extent['west']}%2C{spatial_extent['south']}%2C{spatial_extent['east']}%2C{spatial_extent['north']}&sortParam=startDate&sortOrder=ascending&page=1&maxRecords=1000&status=ONLINE&dataset=ESA-DATASET&productType=L2A&startDate={temporal_extent[0]}T00%3A00%3A00Z&completionDate={temporal_extent[1]}T00%3A00%3A00Z&cloudCover=%5B0%2C{cloud_cover}%5D\"\n",
    "    response = requests.get(catalog_url)\n",
    "    response.raise_for_status()\n",
    "    catalog = response.json()\n",
    "    dates = [date.split('T')[0] for date in map(lambda x: x['properties']['startDate'], catalog['features'])]\n",
    "    return dates\n",
    "\n",
    "# Please enter your perameters here.\n",
    "site_id = 86 # Specify the oil and gas field ID\n",
    "temporal_extent = [\"2021-01-01\", \"2021-01-31\"]  # Specify the the date range you want to check for available data.\n",
    "cloud_cover = 5\n",
    "\n",
    "available_dates = fetch_available_dates(site_id, temporal_extent)\n",
    "print(\"Available dates:\", available_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c953b692-eb71-4c15-b3d3-95025f77bcc4",
   "metadata": {},
   "source": [
    "## Choosing the Active Emission Date\n",
    "\n",
    "As mentioned in the overview, an active emission date must be chosen from one of the available datasets. \n",
    "\n",
    "Like before, the two parameters you need to modify before running the code are:\n",
    "\n",
    "- site_id = 86 (change this to your chosen study site)\n",
    "- temporal_extent = [\"2023-02-25\", \"2023-02-25\"] (change this to your chosen date range using \"YYYY-MM-DD\" format.) \n",
    "\n",
    "Please note that the temporal extent dates <u>MUST BE IDENTICAL</u> because we are only choosing a single date.\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a709165f-4542-46da-af8e-a7199df573c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_emission(site_id, temporal_extent):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    active_emission = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B11\", \"B12\"],\n",
    "    )\n",
    "    active_emission.download(\"Sentinel-2_active_emissionMBMP.Tiff\")\n",
    "\n",
    "# Enter perameters for the active emission day\n",
    "site_id = 86  # Specify the oil and gas field ID\n",
    "temporal_extent = [\"2021-01-11\", \"2021-01-11\"]\n",
    "\n",
    "active_emission(site_id, temporal_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc9eea-43af-400e-822f-725ce1afb0b2",
   "metadata": {},
   "source": [
    "## Choosing the No Emission Date\n",
    "\n",
    "Next we choose the no emission date using the same process. \n",
    "\n",
    "The two parameters you need to modify before running the code are:\n",
    "\n",
    "- site_id = 86 (change this to your chosen site)\n",
    "- temporal_extent = [\"2023-02-25\", \"2023-02-25\"] (change this to your chosen date range using \"YYYY-MM-DD\" format.) \n",
    "\n",
    "The temporal extent dates <u>MUST BE IDENTICAL</u>\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74d95f-bc49-4233-b767-6a1daaaf68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_emission(site_id, temporal_extent):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    no_emission = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B11\", \"B12\"],\n",
    "    )\n",
    "    no_emission.download(\"Sentinel-2_no_emissionMBMP.Tiff\")\n",
    "\n",
    "# Enter perameters for the active emission day\n",
    "site_id = 86  # Specify the oil and gas field ID\n",
    "temporal_extent = [\"2021-01-08\", \"2021-01-08\"]\n",
    "\n",
    "no_emission(site_id, temporal_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de701594-5589-41ad-8750-5a57f70cc130",
   "metadata": {},
   "source": [
    "## Choosing a Background Satelite Image\n",
    "\n",
    "This section helps with locating the source of the emission at the landfill by displaying a true colour satelite image of the landfill that the data will be superimposed over. I recommend choosing the same date as your active emission. \n",
    "\n",
    "Once again, the two parameters you need to modify before running the code are:\n",
    "\n",
    "- site_id = 86 (change this to your chosen site)\n",
    "- temporal_extent = [\"2023-02-25\", \"2023-02-25\"] (change this to your chosen date range using \"YYYY-MM-DD\" format.)\n",
    "\n",
    "The temporal extent dates <u>MUST BE IDENTICAL</u>\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9db215-2b88-4bf4-b65c-06dc75e94a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truecolour_image(site_id, temporal_extent):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    truecolour_image = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B02\", \"B03\", \"B04\"],\n",
    "    )\n",
    "    truecolour_image.download(\"Sentinel-2_truecolourMBMP.Tiff\")\n",
    "\n",
    "# Enter parameters for the no emission day\n",
    "site_id = 86  # Specify the oil and gas field ID\n",
    "temporal_extent = [\"2021-01-11\", \"2021-01-11\"]\n",
    "\n",
    "truecolour_image(site_id, temporal_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fde51c-73cf-4816-b880-bf4715dc35aa",
   "metadata": {},
   "source": [
    "## Running the Analysis\n",
    "The code below runs the analysis. Provided all the variables above have been run correctly, this next section should take moments to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a8d32-f346-44a6-bf1b-4c4acbb955dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "Active_Multiband = \"Sentinel-2_active_emissionMBMP.Tiff\"\n",
    "No_Multiband = \"Sentinel-2_no_emissionMBMP.Tiff\"\n",
    "\n",
    "# Define a function for least squares fitting\n",
    "def least_squares_fit(x, y):\n",
    "    # Remove NaNs (if any) for valid calculations\n",
    "    mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x_valid = x[mask]\n",
    "    y_valid = y[mask]\n",
    "    \n",
    "    # Calculate least squares fit parameters\n",
    "    A = np.vstack([x_valid, np.ones_like(x_valid)]).T\n",
    "    m, c = np.linalg.lstsq(A, y_valid, rcond=None)[0]\n",
    "    return m, c\n",
    "\n",
    "# Open datasets and perform least squares fitting\n",
    "with rasterio.open(Active_Multiband) as Active_img, rasterio.open(No_Multiband) as No_img:\n",
    "    Active_B11 = Active_img.read(1)\n",
    "    Active_B12 = Active_img.read(2)\n",
    "    No_B11 = No_img.read(1)\n",
    "    No_B12 = No_img.read(2)\n",
    "    \n",
    "    # Perform least squares fitting for Active_B11 vs Active_B12\n",
    "    m_active, c_active = least_squares_fit(Active_B11.flatten(), Active_B12.flatten())\n",
    "    Corrected_Active_B12 = m_active * Active_B12 + c_active\n",
    "    \n",
    "    # Perform least squares fitting for No_B11 vs No_B12\n",
    "    m_no, c_no = least_squares_fit(No_B11.flatten(), No_B12.flatten())\n",
    "    Corrected_No_B12 = m_no * No_B12 + c_no\n",
    "    \n",
    "    # Calculate the fractional change\n",
    "    SWIR_diff = (Active_B11 - Corrected_Active_B12) - (No_B11 - Corrected_No_B12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e03e9-0ad7-4d49-9077-90f34f14dfcd",
   "metadata": {},
   "source": [
    "## Viewing the data. \n",
    "\n",
    "This section of code can be run to produce the map. Three peramaters can to be adjusted. \n",
    "\n",
    "- site_id = 86 (change this to your chosen site)\n",
    "- brightness_factor = 0.05 (occasionally the true colour satelite image can be too bright or too dark. You can change this number to fix it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bcc3d-b048-4bfb-9baf-4baf87a343fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get bounds from the Oil and Gas Field bounding file\n",
    "def get_bounds(site_id, csv_path):\n",
    "    # Load CSV data\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Take the data from a particular record\n",
    "    site = df[df['id'] == site_id]\n",
    "    if site.empty:\n",
    "        raise ValueError(f\"Site ID {site_id} not found in the CSV file.\")\n",
    "\n",
    "    # bounding box extents\n",
    "    site = site.iloc[0]\n",
    "    return [[site['south'], site['west']], [site['north'], site['east']]]\n",
    "\n",
    "# Specify the site ID and input paths\n",
    "site_id = 86  # Specify the oil and gas field ID\n",
    "csv_path = r'C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\Algerian_Oil_and_Gas_Fields.csv'\n",
    "bounds = get_bounds(site_id, csv_path)\n",
    "\n",
    "# Calculate the center of the map\n",
    "center_lat = (bounds[0][0] + bounds[1][0]) / 2\n",
    "center_lon = (bounds[0][1] + bounds[1][1]) / 2\n",
    "\n",
    "# Load the true color image\n",
    "truecolour_sat = 'Sentinel-2_truecolourMBMP.Tiff'\n",
    "img = rasterio.open(truecolour_sat)\n",
    "blue, green, red = img.read(1), img.read(2), img.read(3)\n",
    "\n",
    "# Adjust brightness dynamically\n",
    "brightness_factor = 0.03  # Brightness adjustment factor\n",
    "blue = np.clip(blue * brightness_factor, 0, 255)\n",
    "green = np.clip(green * brightness_factor, 0, 255)\n",
    "red = np.clip(red * brightness_factor, 0, 255)\n",
    "\n",
    "# Stack bands to create RGB image\n",
    "rgb = np.dstack((red, green, blue))\n",
    "rgb = rgb / rgb.max()  # Normalize values between 0 and 1\n",
    "\n",
    "# Apply logarithmic transformation to enhance contrast\n",
    "rgb = np.log1p(rgb)\n",
    "rgb = rgb / rgb.max()  # Normalize again after transformation\n",
    "\n",
    "# Create a Folium map with the dynamic center\n",
    "m = Map(location=[center_lat, center_lon], zoom_start=10, control_scale=True)\n",
    "\n",
    "# Add true color image overlay with dynamic bounds\n",
    "truecolour_overlay = ImageOverlay(\n",
    "    image=rgb,\n",
    "    bounds=bounds,\n",
    "    opacity=1,\n",
    "    interactive=True,\n",
    "    cross_origin=False,\n",
    "    zindex=1,\n",
    ")\n",
    "truecolour_overlay.add_to(m)\n",
    "\n",
    "# Assuming SWIR_diff has been calculated earlier in your workflow\n",
    "# Calculate mean and standard deviation of SWIR_diff\n",
    "mean, std = np.nanmean(SWIR_diff), np.nanstd(SWIR_diff)\n",
    "\n",
    "# Perform standard deviation stretch\n",
    "std_factor = 2  # Number of standard deviations for stretching\n",
    "lower_bound, upper_bound = mean - std_factor * std, mean + std_factor * std\n",
    "\n",
    "# Normalize SWIR_diff using standard deviation stretch\n",
    "normalized_SWIR_diff = (SWIR_diff - lower_bound) / (upper_bound - lower_bound)\n",
    "normalized_SWIR_diff = np.clip(normalized_SWIR_diff, 0, 1)  # Clip values to [0, 1]\n",
    "\n",
    "# Apply colormap to normalized SWIR_diff\n",
    "cmap = plt.get_cmap('plasma')\n",
    "SWIR_colored = cmap(normalized_SWIR_diff)\n",
    "\n",
    "# Add SWIR_diff overlay with dynamic bounds\n",
    "SWIR_overlay = ImageOverlay(\n",
    "    image=SWIR_colored,\n",
    "    bounds=bounds,\n",
    "    opacity=1,\n",
    "    interactive=True,\n",
    "    cross_origin=False,\n",
    "    zindex=2,\n",
    ")\n",
    "SWIR_overlay.add_to(m)\n",
    "\n",
    "# Load GeoJSON file for known point sources\n",
    "vector_point_path = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\known_point_sources.geojson\"\n",
    "gdf = gpd.read_file(vector_point_path)\n",
    "\n",
    "# Add GeoJSON overlay to the map\n",
    "GeoJson(gdf.to_json()).add_to(m)\n",
    "\n",
    "# Add a layer control to toggle map layers\n",
    "LayerControl().add_to(m)\n",
    "\n",
    "# Add a click event to display latitude and longitude on the map\n",
    "m.add_child(LatLngPopup())\n",
    "\n",
    "# Display the map\n",
    "display(m)\n",
    "\n",
    "# File saving output name\n",
    "output_file = \"SWIR_diff_4326.tiff\"\n",
    "\n",
    "# Reproject the raster to EPSG:4326\n",
    "source_crs = \"EPSG:32632\"  # Current CRS\n",
    "target_crs = \"EPSG:4326\"  # Target CRS\n",
    "\n",
    "# Calculate transform and metadata for the target CRS\n",
    "transform, width, height = calculate_default_transform(\n",
    "    source_crs, target_crs, img.width, img.height, *img.bounds\n",
    ")\n",
    "\n",
    "# Update metadata for the target CRS\n",
    "meta = img.meta.copy()\n",
    "meta.update({\n",
    "    \"crs\": target_crs,\n",
    "    \"transform\": transform,\n",
    "    \"width\": width,\n",
    "    \"height\": height,\n",
    "    \"count\": 1,  # Single band for SWIR_diff\n",
    "    \"dtype\": SWIR_diff.dtype\n",
    "})\n",
    "\n",
    "# Save reprojected raster directly\n",
    "with rasterio.open(output_file, \"w\", **meta) as dest:\n",
    "    reproject(\n",
    "        source=SWIR_diff,\n",
    "        destination=rasterio.band(dest, 1),\n",
    "        src_transform=img.transform,\n",
    "        src_crs=source_crs,\n",
    "        dst_transform=transform,\n",
    "        dst_crs=target_crs,\n",
    "        resampling=Resampling.nearest\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8623c7-0247-4561-b42d-3e5922b60225",
   "metadata": {},
   "source": [
    "## Plume tagging\n",
    "\n",
    "Maually input plume source coordinates here in the format (latitude, longitude), for example:  \n",
    "    (31.6887, 5.8102),  # Plume 1 (latitude, longitude)  \n",
    "    (31.7910, 5.8263),  # Plume 2 (latitude, longitude)  \n",
    "etc...\n",
    "\n",
    "Plumes that are segmented will need to have each of their segmets taged to be included in the analysis. Additional lines for more plumes can be added as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6528c93-29a2-4f84-8943-d5008410194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_coords = [\n",
    "    (31.6887, 5.8102),  # Plume 1 (latitude, longitude)\n",
    "    (31.7910, 5.8263),  # Plume 2 (latitude, longitude)\n",
    "    (31.7978, 5.8341),  # Plume 4 (latitude, longitude)\n",
    "    (31.9101, 6.0135),  # Plume 3 (latitude, longitude)\n",
    "    (31.6389, 6.0025),  # Plume 4 (latitude, longitude)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3930168-7e93-4e4c-9f83-011f6f6ea8c7",
   "metadata": {},
   "source": [
    "## Loading and configuring map.\n",
    "\n",
    "This section loads the SWIR data and loads the colourmap in preparation for the analysis. It also provides the average/mean value of the dataset, allowing us to see how much a plume rises above background levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ddc9d-9dfa-4b93-a935-df53d8ceb5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TIFF file\n",
    "tiff_file_path = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\SWIR_diff_4326.tiff\"\n",
    "with rasterio.open(tiff_file_path) as tiff_file:\n",
    "    raster_data = tiff_file.read(1)  # Read the first band\n",
    "    nodata_value = tiff_file.nodata if tiff_file.nodata is not None else -9999\n",
    "    bounds = tiff_file.bounds\n",
    "    transform = tiff_file.transform\n",
    "\n",
    "# Mask nodata values\n",
    "masked_data = np.ma.masked_equal(raster_data, nodata_value)\n",
    "mean, std = np.nanmean(masked_data), np.nanstd(masked_data)\n",
    "std_factor = 2\n",
    "lower_bound, upper_bound = mean - std_factor * std, mean + std_factor * std\n",
    "normalized_data = (masked_data - lower_bound) / (upper_bound - lower_bound)\n",
    "normalized_data = np.clip(normalized_data, 0, 1)  # Clip to [0, 1]\n",
    "\n",
    "# Apply colormap\n",
    "cmap = plt.get_cmap('plasma')\n",
    "rgb_data = (cmap(normalized_data)[:, :, :3] * 255).astype(np.uint8)\n",
    "\n",
    "# Initialize the map\n",
    "center_lat = (bounds.top + bounds.bottom) / 2\n",
    "center_lon = (bounds.left + bounds.right) / 2\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=11, control_scale=True)\n",
    "\n",
    "# Add SWIR_diff overlay\n",
    "image_bounds = [[bounds.bottom, bounds.left], [bounds.top, bounds.right]]\n",
    "swir_overlay = ImageOverlay(\n",
    "    image=rgb_data,\n",
    "    bounds=image_bounds,\n",
    "    opacity=1,\n",
    "    interactive=True,\n",
    "    cross_origin=False,\n",
    "    zindex=1,\n",
    ")\n",
    "swir_overlay.add_to(m)\n",
    "\n",
    "# Mark plume locations\n",
    "for i, (lat, lon) in enumerate(plume_coords):\n",
    "    folium.CircleMarker(\n",
    "        location=[lat, lon],\n",
    "        radius=5,\n",
    "        color=\"red\",\n",
    "        fill=True,\n",
    "        fill_color=\"red\",\n",
    "        fill_opacity=1,\n",
    "        popup=f\"Plume {i + 1}\",\n",
    "    ).add_to(m)\n",
    "\n",
    "# Calculate the mean value of the masked data\n",
    "dataset_mean_value = masked_data.mean()\n",
    "\n",
    "# Print the mean value\n",
    "print(f\"Mean value of the dataset: {dataset_mean_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c42726-641e-437e-95ff-7619431d88a3",
   "metadata": {},
   "source": [
    "## Viewing the data. \n",
    "\n",
    "Now everything is loaded, we can run the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c506dd-68ac-4de3-8297-f4db7fd6cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze plumes\n",
    "def analyze_plume(masked_data, plume_coords, transform):\n",
    "    plume_results = []\n",
    "    labeled_array, _ = label(masked_data > np.percentile(masked_data.compressed(), 65))  # Identify plumes\n",
    "    for i, (lat, lon) in enumerate(plume_coords):\n",
    "        try:\n",
    "            row, col = rasterio.transform.rowcol(transform, lon, lat)\n",
    "            row, col = int(row), int(col)\n",
    "            plume_label = labeled_array[row, col]\n",
    "            if plume_label == 0:\n",
    "                plume_results.append({\n",
    "                    \"Plume\": i + 1,\n",
    "                    \"Location (lat, lon)\": (lat, lon),\n",
    "                    \"Status\": \"No plume detected\",\n",
    "                })\n",
    "            else:\n",
    "                plume_region = labeled_array == plume_label\n",
    "                plume_values = masked_data[plume_region]\n",
    "                plume_pixels = np.column_stack(np.where(plume_region))\n",
    "\n",
    "                # Convert pixel coordinates to lat/lon\n",
    "                plume_longitudes, plume_latitudes = rasterio.transform.xy(\n",
    "                    transform, plume_pixels[:, 0], plume_pixels[:, 1]\n",
    "                )\n",
    "                points = np.array(list(zip(plume_latitudes, plume_longitudes)))\n",
    "                hull = ConvexHull(points)\n",
    "                polygon_coordinates = [(points[vertex, 0], points[vertex, 1]) for vertex in hull.vertices]\n",
    "\n",
    "                # Add polygon to the map\n",
    "                folium.Polygon(\n",
    "                    locations=polygon_coordinates,\n",
    "                    color=\"blue\",\n",
    "                    weight=1,\n",
    "                    fill=True,\n",
    "                    fill_color=\"blue\",\n",
    "                    fill_opacity=0.4,\n",
    "                    popup=f\"Plume {i + 1} region\",\n",
    "                ).add_to(m)\n",
    "\n",
    "                plume_results.append({\n",
    "                    \"Plume\": i + 1,\n",
    "                    \"Location (lat, lon)\": (lat, lon),\n",
    "                    \"Max Value\": plume_values.max(),\n",
    "                    \"Mean Value\": plume_values.mean(),\n",
    "                    \"Size (pixels)\": plume_region.sum(),\n",
    "                })\n",
    "        except Exception as e:\n",
    "            plume_results.append({\n",
    "                \"Plume\": i + 1,\n",
    "                \"Location (lat, lon)\": (lat, lon),\n",
    "                \"Status\": f\"Error: {e}\",\n",
    "            })\n",
    "    return plume_results\n",
    "\n",
    "# Perform analysis\n",
    "plume_results = analyze_plume(masked_data, plume_coords, transform)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "plume_df = pd.DataFrame([{\n",
    "    \"Plume\": result[\"Plume\"],\n",
    "    \"Location (lat, lon)\": result[\"Location (lat, lon)\"],\n",
    "    \"Max Value\": result.get(\"Max Value\", None),\n",
    "    \"Mean Value\": result.get(\"Mean Value\", None),\n",
    "    \"Size (pixels)\": result.get(\"Size (pixels)\", None),\n",
    "    \"Status\": result.get(\"Status\", \"Plume detected\"),\n",
    "} for result in plume_results])\n",
    "\n",
    "# Display DataFrame\n",
    "print(plume_df)\n",
    "\n",
    "# Add a layer control and click event\n",
    "LayerControl().add_to(m)\n",
    "m.add_child(LatLngPopup())\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562a179-7b1b-484c-8c6c-4a511807ca27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
