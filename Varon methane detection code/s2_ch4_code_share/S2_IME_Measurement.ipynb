{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f561c3-51d4-4476-922d-876088df12c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentinel-2 Individual Plume Analysis Tool\n",
    "\n",
    "# Overview\n",
    "This tool processes Sentinel-2 data to measure methane emissions, particularly from oil and gas fields. It follows this approach:\n",
    "\n",
    "1. **Data Retrieval**: Downloads Sentinel-2 data for user-defined dates from a pre-coded list of sites.\n",
    "\n",
    "2. **Preprocessing**: Processes shortwave infrared (SWIR) bands, which are sensitive to methane. Then it compares data from an active emission day with a \"no emission\" day using a Multi-Band Multi-Pass method.\n",
    "\n",
    "3. **Plume Analysis**: Identifies areas with elevated methane levels using a thresholding method. Then it measures the total methane in the image, the length of the plume, and downloads wind speed data from the ERA5 API.\n",
    "\n",
    "4. **Result**: Calculates the emission rate in kg/h using the Integrated Mass Enhancement (IME) method, along with the uncertainty range.\n",
    "\n",
    "This workflow enables accurate estimation of methane emissions from satellite data and quantifies their impact based on plume characteristics and environmental factors.\n",
    "\n",
    "The section below imports the packages needed to run the script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9cfbc-e95b-4685-a7e2-19f2ccc7cf3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Core System and Numerical Operations\n",
    "import numpy as np  # For numerical operations and array manipulations\n",
    "import pandas as pd  # For handling tabular data (e.g., CSV files)\n",
    "\n",
    "# File Handling and Temporary Files\n",
    "from tempfile import NamedTemporaryFile  # For creating temporary files\n",
    "\n",
    "# Data Analysis and Manipulation\n",
    "import xarray as xr  # For working with multidimensional arrays (e.g., NetCDF files)\n",
    "import cdsapi  # For accessing the Copernicus Climate Data Store API\n",
    "import requests  # For making HTTP requests (e.g., downloading data)\n",
    "import openeo  # For cloud-based geospatial data processing\n",
    "\n",
    "# Geospatial Data Handling\n",
    "import rasterio  # For working with raster data\n",
    "from rasterio.plot import show  # For visualising raster data\n",
    "\n",
    "# Mathematical and Geometric Computations\n",
    "from scipy.ndimage import label  # For segmentation and labelling of regions\n",
    "\n",
    "# Interactive Maps and Visualisation\n",
    "import matplotlib.pyplot as plt  # For plotting and visualisation\n",
    "\n",
    "# radiative transfer model imports\n",
    "import setup\n",
    "import radtran as rt\n",
    "import time\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy import interpolate\n",
    "import scipy.ndimage as ndimage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67714102-a656-4414-9e45-42c8c80460ea",
   "metadata": {},
   "source": [
    "## Connect to OpenEO\n",
    "\n",
    "The code below establishes a connection with the Copernicus openEO platform which provides a wide variety of earth observation datasets\n",
    "\n",
    "- If this does not read as 'Authorised successfully' or 'Authenticated using refresh token', then please ensure that you have completed the setup steps as outlined in section 2.3.6 of the how to guide. \n",
    "\n",
    "- If you have followed the steps in section 2.3.6 correctly and the problem persists, please look at https://dataspace.copernicus.eu/news for any information about service interruptions. \n",
    "\n",
    "- If there is no news of service problems you can raise a ticket here: https://helpcenter.dataspace.copernicus.eu/hc/en-gb/requests/new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfface4-832c-4c3b-b79c-a6886878cd83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "connection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\n",
    "connection.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d0674c-3b9c-4ab0-aafe-0526baa82e66",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dispaly field names and select site_id. \n",
    "\n",
    "This loads the plume list. The plume boudings need to be manually inputted into an .csv file with the column headdings: \n",
    "- id\n",
    "- name\n",
    "- west\n",
    "- south\n",
    "- east\n",
    "- north\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110af1e-a1d9-4fb8-8663-51d279eac192",
   "metadata": {},
   "outputs": [],
   "source": [
    "studysite_csv = pd.read_csv(r'C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\Individual_Plume_Boundings.csv')\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(studysite_csv.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4115bf0d-be37-48b7-bed1-f3929708b174",
   "metadata": {},
   "source": [
    "## Plume choice\n",
    "\n",
    "In the code box below, specify the plume number we are interested in for analysis. \n",
    "\n",
    "<p style=\"text-align: center;\"><b>site_id</b> = 5</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f938e585-a992-4004-b7a6-c71fb7322bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file\n",
    "csv_file_path = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\Individual_Plume_Boundings.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "studysite_csv = pd.read_csv(csv_file_path)\n",
    "\n",
    "site_id = 3  # Specify the oil and gas field ID for the field you want to examine.\n",
    "\n",
    "# Retrieve the name of the field from the dataset\n",
    "field_name = studysite_csv[studysite_csv['id'] == site_id].iloc[0]['name']\n",
    "\n",
    "# Print a confirmation message\n",
    "print(f\"Site {site_id} ({field_name}) loaded correctly.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb74f40-ba0f-4dbb-9d38-08e5b33dc11f",
   "metadata": {},
   "source": [
    "# Multi-Band Multi-Pass Analysis\n",
    "\n",
    "Varon et al. (2021) showed that methane plumes from point sources could be imaged by differencing Sentinel-2’s SWIR-1 and SWIR-2 bands. The tool runs an analysis using a  multi-band-multi-pass retrieval method: \n",
    "\n",
    "First it calculates a multi-band-single-pass calculation for both active emission and no emission dates, resulting in two datasets which are then used together for a multi-band-multi-pass method. \n",
    "The multi-band-single-pass equation is as follows: \n",
    "\n",
    "\n",
    "<div align=\"center\"><b>MBSP = cB12 - B11 / B11  </b></div>\n",
    "\n",
    "Where:\n",
    "- <b>B12</b> is the Sentinel-2 SWIR-2 band.\n",
    "- <b>B11</b> is the Sentinel-2 SWIR-1 band. \n",
    "- <b>c</b> is calculated by least-squares fitting B12 to B11 across the scene.  \n",
    "\n",
    "Once active emission and no emission scenes have been calculated, the following equation is used to calculate the multi-band-multi-pass raster. \n",
    "\n",
    "<div align=\"center\"><b>MBMP = ActiveMBSP − NoMBSP</b></div>\n",
    "\n",
    "Where:\n",
    "- <b>ActiveMBSP</b> is the multiband single pass for the active emission scene\n",
    "- <b>NoMBSP</b> is the multiband single pass for the no emission scene.  \n",
    "\n",
    "The active emission scene and no emission scene are considered in this analysis to be one satelite pass apart. To begin this process we need to determine what days have available satelite data. \n",
    "\n",
    "# Available dates for the analysis. \n",
    "\n",
    "Sentinel 2 provides data aproximately once every 2 - 3 days, so not every date you can enter into this tool is valid. The code below will tell you what dates are available to use for the oil/gas field of your choice. \n",
    "\n",
    "The one parameter you need to modify before running the code is: \n",
    "\n",
    "- <b>temporal_extent</b> = [\"2020-01-01\", \"2020-01-31\"] (change this to your chosen date range using \"YYYY-MM-DD\" format.)\n",
    "\n",
    "Once you have done this run the code and the available dates should appear below in a matter of seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb8600-dfdd-491b-bde9-2eaa760af099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spatial_extent(site_id):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "    return {\n",
    "        \"west\": site['west'],\n",
    "        \"south\": site['south'],\n",
    "        \"east\": site['east'],\n",
    "        \"north\": site['north']\n",
    "    }\n",
    "\n",
    "def fetch_available_dates(site_id, temporal_extent):\n",
    "    spatial_extent = get_spatial_extent(site_id)\n",
    "    catalog_url = f\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?box={spatial_extent['west']}%2C{spatial_extent['south']}%2C{spatial_extent['east']}%2C{spatial_extent['north']}&sortParam=startDate&sortOrder=ascending&page=1&maxRecords=1000&status=ONLINE&dataset=ESA-DATASET&productType=L2A&startDate={temporal_extent[0]}T00%3A00%3A00Z&completionDate={temporal_extent[1]}T00%3A00%3A00Z&cloudCover=%5B0%2C{cloud_cover}%5D\"\n",
    "    response = requests.get(catalog_url)\n",
    "    response.raise_for_status()\n",
    "    catalog = response.json()\n",
    "    dates = [date.split('T')[0] for date in map(lambda x: x['properties']['startDate'], catalog['features'])]\n",
    "    return dates\n",
    "\n",
    "# Please enter your perameters here.\n",
    "temporal_extent = [\"2019-10-01\", \"2019-11-30\"]  # Specify the the date range you want to check for available data.\n",
    "cloud_cover = 5\n",
    "\n",
    "available_dates = fetch_available_dates(site_id, temporal_extent)\n",
    "print(\"Available dates:\", available_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c953b692-eb71-4c15-b3d3-95025f77bcc4",
   "metadata": {},
   "source": [
    "## Choosing the \"Active Emission\" Date\n",
    "\n",
    "A so called active emission date must be chosen from one of the available datasets. This will be the chosen day we are looking for plumes.  \n",
    "\n",
    "Like before, the one parameter you need to modify before running the code is:\n",
    "\n",
    "<p style=\"text-align: center;\"><b>temporal_extent</b> = [\"2020-01-17\", \"2020-01-17\"]</p>\n",
    "\n",
    "Change this to your chosen date range using \"YYYY-MM-DD\" format. \n",
    "\n",
    "Please note that the temporal extent dates <b><u>MUST BE IDENTICAL</u></b> because we are only choosing a single date.\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a709165f-4542-46da-af8e-a7199df573c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_emission(site_id, active_temporal_extent):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    active_emission = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=active_temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B11\", \"B12\", \"sunZenithAngles\", \"viewZenithMean\"],\n",
    "    )\n",
    "    active_emission.download(\"Sentinel-2_active_emissionMBMP.Tiff\")\n",
    "    \n",
    "    sun_zenith_mean = None\n",
    "    view_zenith_mean = None\n",
    "\n",
    "    with rasterio.open(\"Sentinel-2_active_emissionMBMP.Tiff\") as src:\n",
    "        band_names = [\"B11\", \"B12\", \"sunZenithAngles\", \"viewZenithMean\"]\n",
    "        means = {band_names[i]: np.mean(src.read(i+1)) for i in range(src.count)}\n",
    "\n",
    "    print(f\"Mean value of B11: {means['B11']}\")\n",
    "    print(f\"Mean value of B12: {means['B12']}\")\n",
    "    print(f\"Mean value of sunZenithAngles: {means['sunZenithAngles']}\")\n",
    "    print(f\"Mean value of viewZenithMean: {means['viewZenithMean']}\")\n",
    "\n",
    "    return means[\"sunZenithAngles\"], means[\"viewZenithMean\"]\n",
    "\n",
    "# Enter parameters for the active emission day\n",
    "active_temporal_extent = [\"2019-11-20\", \"2019-11-20\"]\n",
    "\n",
    "# Store results for later use\n",
    "sun_zenith_mean, view_zenith_mean = active_emission(site_id, active_temporal_extent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc9eea-43af-400e-822f-725ce1afb0b2",
   "metadata": {},
   "source": [
    "## Choosing the \"No Emission\" Date\n",
    "\n",
    "Next we choose the no emission date using the same process. This is the dataset we will compare the \"Active Emission\" one too. The recommended choice is the satelite overpass immediately before the \"Active Emission\" one. \n",
    "\n",
    "<b>So if your active emission day is 2020-01-17, your no emission day would be 2020-01-14</b>\n",
    "\n",
    "In an ideal world, the \"No Emission\" day should contain no emissions, but in fields with a lot of activity like Hassi Messaoud, this may not be possible. Such an instance will not cause problems in most cases. The emissions for these dates will simply appear as dark clouds on the SWIR data and can be ignored in the analysis. \n",
    "\n",
    "The one parameter you need to modify before running the code is:\n",
    "\n",
    "<p style=\"text-align: center;\"><b>temporal_extent</b> = [\"2020-01-14\", \"2020-01-14\"]</p>\n",
    "\n",
    "The temporal extent dates <b><u>MUST BE IDENTICAL</u></b>\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74d95f-bc49-4233-b767-6a1daaaf68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_emission(site_id, temporal_extent):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    no_emission = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=no_temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B11\", \"B12\"],\n",
    "    )\n",
    "    no_emission.download(\"Sentinel-2_no_emissionMBMP.Tiff\")\n",
    "\n",
    "# Enter perameters for the active emission day\n",
    "no_temporal_extent = [\"2019-10-06\", \"2019-10-06\"]\n",
    "\n",
    "no_emission(site_id, no_temporal_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fde51c-73cf-4816-b880-bf4715dc35aa",
   "metadata": {},
   "source": [
    "## Running Plume Analysis\n",
    "\n",
    "The following code box performs the MBMP analysis as outlined earlier. Not mentioned earlier is that the sentinel-2 data is divided by 10,000 to obtain the reflectance values as per the documentation on Units in: https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Data/S2L1C.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601f22b5-8303-4bfa-8b75-9844be8784a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_fit_no_intercept(x, y):\n",
    "    \"\"\"Computes least-squares scaling factor c (forcing intercept = 0).\"\"\"\n",
    "    mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x_valid = x[mask]\n",
    "    y_valid = y[mask]\n",
    "    \n",
    "    # Compute scaling factor c as the least-squares solution to y = c * x\n",
    "    c = np.sum(x_valid * y_valid) / np.sum(x_valid ** 2)  # Least squares slope with zero intercept\n",
    "    \n",
    "    return c\n",
    "\n",
    "# Define file paths\n",
    "Active_Multiband = \"Sentinel-2_active_emissionMBMP.Tiff\"\n",
    "No_Multiband = \"Sentinel-2_no_emissionMBMP.Tiff\"\n",
    "output_file = \"SWIR_diff.tiff\"\n",
    "\n",
    "# Open datasets and perform least squares fitting\n",
    "with rasterio.open(Active_Multiband) as Active_img, rasterio.open(No_Multiband) as No_img:\n",
    "    # Read data and convert to float for safe division\n",
    "    Active_B11 = Active_img.read(1).astype(float) / 10000.0\n",
    "    Active_B12 = Active_img.read(2).astype(float) / 10000.0\n",
    "    No_B11 = No_img.read(1).astype(float) / 10000.0\n",
    "    No_B12 = No_img.read(2).astype(float) / 10000.0\n",
    "\n",
    "    # Compute scaling factor c for each pass (forcing intercept to 0)\n",
    "    c_active = least_squares_fit_no_intercept(Active_B11.flatten(), Active_B12.flatten())\n",
    "    c_no = least_squares_fit_no_intercept(No_B11.flatten(), No_B12.flatten())\n",
    "\n",
    "    # Correct Band 12 using computed c values\n",
    "    Corrected_Active_B12 = c_active * Active_B12\n",
    "    Corrected_No_B12 = c_no * No_B12\n",
    "\n",
    "    # Compute MBSP retrieval using the correct methodology equation\n",
    "    MBSP_active = c_active * (Active_B12 - Active_B11) / Active_B11\n",
    "    MBSP_no = c_no * (No_B12 - No_B11) / No_B11\n",
    "\n",
    "    # Compute MBMP difference (Final MBMP retrieval)\n",
    "    SWIR_diff = MBSP_active - MBSP_no\n",
    "\n",
    "\n",
    "# Save SWIR_diff\n",
    "with rasterio.open(Active_Multiband) as src:\n",
    "    meta = src.meta.copy()\n",
    "    meta.update({\n",
    "        \"count\": 1,\n",
    "        \"dtype\": SWIR_diff.dtype\n",
    "    })\n",
    "    with rasterio.open(output_file, \"w\", **meta) as dest:\n",
    "        dest.write(SWIR_diff, 1)\n",
    "\n",
    "# Print output file name and its values as a numpy array\n",
    "print(f\"Output file saved as: {output_file}\")\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define output file path\n",
    "output_file = \"SWIR_diff.tiff\"\n",
    "\n",
    "# Open the output file and read data\n",
    "with rasterio.open(output_file) as src:\n",
    "    SWIR_diff_data = src.read(1)  # Read the first (and only) band\n",
    "    extent = [src.bounds.left, src.bounds.right, src.bounds.bottom, src.bounds.top]  # Get spatial extent\n",
    "\n",
    "# Mask NaN or NoData values\n",
    "SWIR_diff_data = np.ma.masked_where(SWIR_diff_data == src.nodata, SWIR_diff_data)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(SWIR_diff_data, cmap='coolwarm', extent=extent, origin=\"upper\")\n",
    "plt.colorbar(label=\"SWIR Difference Value\")\n",
    "plt.title(\"SWIR Difference Map\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5209f335-ef2a-47d0-8436-786d8206caa8",
   "metadata": {},
   "source": [
    "## Radiative Transfer Model Part 1 - Functions\n",
    "\n",
    "The following section is part 1 of the radiative transfer model referred to in Varon et al. 2021, kindly given by Dr Daniel Varon. The first code box defines a series of functions used by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6528c93-29a2-4f84-8943-d5008410194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2020 GHGSat Inc.\n",
    "\n",
    "'''\n",
    "THIS LICENSE AGREEMENT (“LICENSE”) IS A LEGAL AGREEMENT BETWEEN YOU (“USER”) AND GHGSAT INC. (“GHGSAT”), LOCATED AT 500-3981 ST-LAURENT, MONTREAL, QC, CANADA H2W1Y5 GOVERNING THE GHGSAT SENTINEL-2 METHANE SOFTWARE CODE (THE “SOFTWARE”). USER WILL BE DEEMED TO HAVE ACCEPTED AND AGREED TO THE TERMS AND CONDITIONS OF THIS LICENSE IF USER DOWNLOADS AND/OR USES THE SOFTWARE. \n",
    "1.\tOWNERSHIP: The Software is protected by copyright law and is also confidential information; it is licensed for limited purposes.  All title in and to the Software and all intellectual property rights in or related thereto, including any copy, translation, modification, or adaptation of the Software will remain the exclusive property of GHGSAT INC. (“GHGSAT”).  \n",
    "2.\tGRANT OF LICENSE:  GHGSAT grants to User a limited, non-transferable, non-exclusive, perpetual license for academic research and non-commercial use (the “Internal Use”) to utilise the Software and any accompanying written materials, and anything derived therefrom, solely as set forth in this License (the “Grant of License”).  \n",
    "3.\tPERMITTED USES:  User agrees and understands that it MAY: a. make an unlimited number of copies of the Software for Internal Use only; b. provide the Software to collaborators directly related to Internal Use of the Software all of whom must agree (i) to maintain confidentiality of the Software under terms no less restrictive than User’s duty hereunder and (ii) that they will not retain the Software or copies thereof after completion of User’s Internal Use; c. store, post or process the Software in a system that is not accessible by the public, and commensurate with standards regarding the protection of sensitive data; and d. publish research incorporating the Software provided that User first notifies GHGSat of its intent to publish such research and gives GHGSat adequate opportunity to ensure the Software is accurately represented. User shall not alter, cover, remove or otherwise interfere with any copyright notice(s) inscribed on/in the Software. Any approved publication or other work that incorporates the Software must conspicuously acknowledge the following: “GHGSAT Data and Products – Copyright © 2021 GHGSAT Inc. All rights reserved.”\n",
    "4.\tWARRANTY:  GHGSAT is supplying the Software “as is”. GHGSAT GIVES NO WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT\n",
    "5.\tLIMITATION ON LIABILITY: IN NO EVENT WILL GHGSAT BE LIABLE FOR DAMAGES RELATING TO THE SOFTWARE OR OTHERWISE ARISING OUT OF, RELATED TO, OR IN ANY WAY CONNECTED WITH THIS LICENSE, REGARDLESS OF THE FORM OF ACTION, WHETHER BASED ON CONTRACT, NEGLIGENCE, PRODUCT LIABILITY, TRADE PRACTICES, OR OTHERWISE, INCLUDING CONSEQUENTIAL, INDIRECT, SPECIAL, PUNITIVE, OR INCIDENTAL DAMAGES OR LOST PROFITS, WHETHER FORESEEABLE OR UNFORESEEABLE, OF ANY KIND. THE LIMITATIONS CONTAINED IN THIS SECTION ARE NOT MADE WHERE PROHIBITED BY LAW. \n",
    "6.\tMISCELLANEOUS: (1) This License will be terminated as soon as User fails to comply with or is in breach of these terms and User shall promptly destroy the Software or return it to GHGSat. (2) The laws of the Province of Ontario, Canada govern this License. \n",
    "7.\tCONFIDENTIALITY: The User acknowledges that the Software and the data contained therein are valuable intellectual property and that part of the value therein derives from maintaining confidentiality of the Software and the associated data. Accordingly, the User agrees that it shall hold the Software and the associated data in the strictest confidence and will not disclose same to anyone other than to those of its collaborators who need to have access to the Software and its associated data for the purposes of Internal Use. \n",
    "'''\n",
    "\n",
    "# Global variables\n",
    "c = 299792458.\n",
    "kB = 1.38064852e-23\n",
    "deg = np.pi/180\n",
    "mbartoatm = 0.000986923\n",
    "kpatoatm = 0.00986923/1000.\n",
    "kmtocm = 1E5\n",
    "mtocm = 100.\n",
    "mol=6.022140857E23\n",
    "start_time = time.time()\n",
    "\n",
    "# Key directories\n",
    "aux_data_dir = 'aux_data'\n",
    "hapi_data_dir = 'hapi_data'\n",
    "\n",
    "def importMRTP(num_layers, targheight, obsheight, solarangle, obsangle, ch4_scale=1.1029, co2_scale=1.2424, h2o_scale=1):\n",
    "    '''\n",
    "    Load auxiliary data for vertical profiles of temperature, pressure, and CH4, CO2, and H2O mixing ratio.\n",
    "    These data come from the U.S. Standard Atmosphere. \n",
    "    Also calculate the pathlength in each layer for input observation angles.\n",
    "    CH4 and CO2 profiles need to be scaled up to match modern-day concentrations.\n",
    "\n",
    "    Arguments\n",
    "        num_layers [int]   : Number of vertical pressure layers for the radiative transfer calculation\n",
    "        targheight [float] : Target elevation above sea level in km\n",
    "        obsheight  [float] : Altitude of satellite instrument in km. Can use 100 km as if satellite were at top of atmosphere\n",
    "        solarangle [float] : Solar zenith angle in degrees\n",
    "        obsangle   [float] : Viewing zenith angle of instrument in degrees\n",
    "        ch4_scale  [float] : Scale factor multiplying U.S. Standard CH4 profile (1.1029 implies 1875 ppb at the surface)\n",
    "        co2_scale  [float] : Same but for U.S. Standard CO2 profile (1.2424 implies 410 ppm at the surface)\n",
    "        h2o_scale  [float] : Same but for U.S. Standard H2O profile\n",
    "\n",
    "    Returns\n",
    "        pathlength [float] : Path length in each layer [cm]\n",
    "        pressavg   [float] : Average pressure in each layer [atm]\n",
    "        tempavg    [float] : Average temperature in each layer [K]\n",
    "        mrCH4avg   [float] : Average CH4 mixing ratio in each layer\n",
    "        mrCO2avg   [float] : Average CO2 mixing ratio in each layer\n",
    "        mrH2Oavg   [float] : Average H2O mixing ratio in each layer\n",
    "    ''' \n",
    "        \n",
    "    # Mixing Ratio\n",
    "    mrCH4 = np.transpose(np.genfromtxt(f'{aux_data_dir}/ch4.dat'))\n",
    "    mrCO2 = np.transpose(np.genfromtxt(f'{aux_data_dir}/co2.dat'))\n",
    "    mrH2O = np.transpose(np.genfromtxt(f'{aux_data_dir}/h2o.dat'))\n",
    "    \n",
    "    # Temperature\n",
    "    temp = np.transpose(np.genfromtxt(f'{aux_data_dir}/temperature.dat'))\n",
    "    \n",
    "    # Pressure\n",
    "    press = np.transpose(np.genfromtxt(f'{aux_data_dir}/pressure.dat'))\n",
    "    \n",
    "    # Define altitude in cm\n",
    "    altitude = press[1][::-1] * kmtocm\n",
    "    # Define pressure in atm\n",
    "    pressure = press[0][::-1] * mbartoatm\n",
    "    \n",
    "    # Find pressure as a function of altitude\n",
    "    altfine = np.arange(0, 10, 0.01)\n",
    "    pressfine = np.interp(altfine, press[1], press[0]*mbartoatm)\n",
    "    idfine = (np.abs(altfine-targheight)).argmin()\n",
    "    pressmax = pressfine[idfine]    \n",
    "    \n",
    "    # Interpolate to get layers evenly spaced in pressure\n",
    "    dpress = (pressmax-2.9608E-5)/num_layers\n",
    "    pressinterp = np.arange(0, pressmax+dpress, dpress)\n",
    "    altinterp = np.interp(pressinterp, pressure, altitude)\n",
    "\n",
    "    # Find temperature at each altitude\n",
    "    alttemp = temp[1]*kmtocm\n",
    "    temperature = temp[0]\n",
    "    tempinterp = np.interp(altinterp, alttemp, temperature)\n",
    "    \n",
    "    # Find mixing ratios at each altitude\n",
    "    altmrCH4 = mrCH4[1]*kmtocm\n",
    "    altmrCO2 = mrCO2[1]*kmtocm\n",
    "    altmrH2O = mrH2O[1]*kmtocm\n",
    "    mixrateCH4 = mrCH4[0]*ch4_scale\n",
    "    mixrateCO2 = mrCO2[0]*co2_scale\n",
    "    mixrateH2O = mrH2O[0]*h2o_scale\n",
    "    \n",
    "    # Interpolate and then sample using the altitude sample points determined from isobaric pressure increases\n",
    "    mrCH4interp = np.interp(altinterp, altmrCH4, mixrateCH4)\n",
    "    mrCO2interp = np.interp(altinterp, altmrCO2, mixrateCO2)\n",
    "    mrH2Ointerp = np.interp(altinterp, altmrH2O, mixrateH2O)\n",
    "    \n",
    "    def find_nearest_alt(array,value):\n",
    "        idx = (np.abs(array-value)).argmin()\n",
    "        secondpass = array[idx:len(array)]\n",
    "        zeroarray = np.zeros(idx)\n",
    "        upwellingpass = np.concatenate((zeroarray, secondpass))\n",
    "        return upwellingpass\n",
    "    \n",
    "    upwellingpass = find_nearest_alt(altinterp, obsheight*kmtocm)\n",
    "    \n",
    "    # Find path length of each layer\n",
    "    pathlengthdown = np.zeros(num_layers)\n",
    "    pathlengthup = np.zeros(num_layers)\n",
    "    for i in range(0, num_layers):\n",
    "        pathlengthdown[i] = np.absolute(altinterp[i]-altinterp[i+1])\n",
    "        pathlengthup[i] = np.absolute(upwellingpass[i]-upwellingpass[i+1])\n",
    "        \n",
    "    # Calculate path given the Solar and observation angle from Nadir\n",
    "    pathlength = pathlengthdown/np.cos(solarangle*deg) + pathlengthup/np.cos(obsangle*deg)\n",
    " \n",
    "    # Define average value in layers\n",
    "    pressavg = np.zeros(len(pathlength))\n",
    "    tempavg = np.zeros(len(pathlength))\n",
    "    mrCH4avg = np.zeros(len(pathlength))\n",
    "    mrCO2avg = np.zeros(len(pathlength))\n",
    "    mrH2Oavg = np.zeros(len(pathlength))   \n",
    "    for i in range(0,len(pathlength)):\n",
    "        pressavg[i] = (pressinterp[i+1]+pressinterp[i])/2.\n",
    "        tempavg[i] = (tempinterp[i+1]+tempinterp[i])/2.\n",
    "        mrCH4avg[i] = (mrCH4interp[i+1]+mrCH4interp[i])/2.\n",
    "        mrCO2avg[i] = (mrCO2interp[i+1]+mrCO2interp[i])/2.\n",
    "        mrH2Oavg[i] = (mrH2Ointerp[i+1]+mrH2Ointerp[i])/2.\n",
    "\n",
    "    return pathlength, pressavg, tempavg, mrCH4avg, mrCO2avg, mrH2Oavg\n",
    "\n",
    "def radtran(targheight, obsheight, solarangle, obsangle, instrument, band, num_layers=100):\n",
    "    '''\n",
    "    Computes the top-of-atmosphere spectral radiance (TOASR) for an input instrument and spectral band.\n",
    "\n",
    "    Arguments\n",
    "        targheight [float] : Target elevation above sea level in km\n",
    "        obsheight  [float] : Altitude of satellite instrument in km. Can use 100 km as if satellite were at top of atmosphere\n",
    "        solarangle [float] : Solar zenith angle in degrees\n",
    "        obsangle   [float] : Viewing zenith angle of instrument in degrees\n",
    "        instrument [str]   : MSI instrument. Choose 'S2A' or 'S2B'\n",
    "        band       [int]   : Spectral band. Choose 11 or 12\n",
    "        num_layers [int]   : Number of vertical pressure layers for the radiative transfer calculation\n",
    "\n",
    "    Returns\n",
    "        toasr          [float] : Band-integrated top-of-atmosphere spectral radiance [W/m2/m/sr]\n",
    "        odCH4pts       [float] : CH4 optical depth by wavelength\n",
    "        odCO2pts       [float] : CO2 optical depth by wavelength\n",
    "        odH2Opts       [float] : H2O optical depth by wavelength\n",
    "        solar_spectrum [float] : Upwelling solar spectrum\n",
    "        cdCH4          [float] : CH4 slant column density in mol/m2\n",
    "    '''\n",
    "\n",
    "    start_time = time.time()   \n",
    "    \n",
    "    print('Creating the transmission spectrum...')\n",
    "    \n",
    "    # Import pressure, temperature, path-length, and mixing ratios\n",
    "    (L_cm, press_atm, temp, mrCH4, mrCO2, mrH2O) = importMRTP(num_layers, targheight, obsheight, solarangle, obsangle)\n",
    "    \n",
    "    # Load absorption cross_sections        \n",
    "    wavelength = np.load(f'{hapi_data_dir}/abs_wave_hapi_{instrument}_band{band}.npy')\n",
    "    press_load = np.load(f'{hapi_data_dir}/abs_press_hapi_{instrument}_band{band}.npy')\n",
    "    temp_load = np.load(f'{hapi_data_dir}/abs_temp_hapi_{instrument}_band{band}.npy')   \n",
    "    absCH4_load  = np.load(f'{hapi_data_dir}/abs_ch4_hapi_{instrument}_band{band}.npy')\n",
    "    absCO2_load = np.load(f'{hapi_data_dir}/abs_co2_hapi_{instrument}_band{band}.npy')\n",
    "    absH2O_load = np.load(f'{hapi_data_dir}/abs_h2o_hapi_{instrument}_band{band}.npy')\n",
    "    num_wave = len(wavelength)\n",
    "\n",
    "    # Get solar spectrum\n",
    "    solarspec = np.transpose(np.genfromtxt(f'{aux_data_dir}/SUNp01_4000_to_7000.txt'))\n",
    "    wavesolar = 1E7/solarspec[0][::-1]\n",
    "    radiancesolar = solarspec[1][::-1]*(100*solarspec[0][::-1]**2)\n",
    "    solarradiance = np.interp(wavelength,wavesolar,radiancesolar)\n",
    "    \n",
    "    # Calculate optical density\n",
    "    odCH4pts_upper = np.zeros(num_wave)\n",
    "    odCH4pts_lower = np.zeros(num_wave)\n",
    "    odCO2pts = np.zeros(num_wave)\n",
    "    odH2Opts = np.zeros(num_wave)\n",
    "    \n",
    "    interp_order = 3\n",
    "    for i in range(num_wave):\n",
    "        \n",
    "        fCH4_tp = scipy.interpolate.RectBivariateSpline(temp_load, press_load, absCH4_load.T[i], kx=interp_order, ky=interp_order)\n",
    "        fCO2_tp = scipy.interpolate.RectBivariateSpline(temp_load, press_load, absCO2_load.T[i], kx=interp_order, ky=interp_order)\n",
    "        fH2O_tp = scipy.interpolate.RectBivariateSpline(temp_load, press_load, absH2O_load.T[i], kx=interp_order, ky=interp_order)\n",
    "               \n",
    "        for j in range(num_layers):\n",
    "            \n",
    "            # Calculate density\n",
    "            temperature_K = temp[j]\n",
    "            pressure_atm = press_atm[j]\n",
    "            pressure_Pa = pressure_atm*101325\n",
    "            density_m3 = pressure_Pa/(kB*temperature_K)\n",
    "            density_cm3 = density_m3/(1E6)\n",
    "            \n",
    "            # Evaluate interpolation function\n",
    "            f_CH4_temp = fCH4_tp(temperature_K, pressure_atm)\n",
    "            f_CO2_temp = fCO2_tp(temperature_K, pressure_atm)\n",
    "            f_H2O_temp = fH2O_tp(temperature_K, pressure_atm)\n",
    "                        \n",
    "            # Calculate the (unit-less) optical density: OD = abs*n*MR*L\n",
    "            lim_low = 6\n",
    "            if j >= num_layers - lim_low:\n",
    "                # Lowest 6 pressure layers = lowest 500 m of atmosphere (lower)\n",
    "                odCH4pts_lower[i] = odCH4pts_lower[i] + f_CH4_temp*density_cm3*mrCH4[j]*L_cm[j]\n",
    "            else:\n",
    "                # The rest of the atmosphere (upper)\n",
    "                odCH4pts_upper[i] = odCH4pts_upper[i] + f_CH4_temp*density_cm3*mrCH4[j]*L_cm[j]\n",
    "            odCO2pts[i] = odCO2pts[i] + f_CO2_temp*density_cm3*mrCO2[j]*L_cm[j]\n",
    "            odH2Opts[i] = odH2Opts[i] + f_H2O_temp*density_cm3*mrH2O[j]*L_cm[j]\n",
    "\n",
    "    # Calculate slant column density of methane\n",
    "    cdCH4 = np.sum((press_atm/kpatoatm/(kB*temp)/mtocm**3)*mrCH4*L_cm/mol*mtocm**2)\n",
    "\n",
    "    press_atm_lower = press_atm[-lim_low:]\n",
    "    temp_lower = temp[-lim_low:]\n",
    "    L_cm_lower = L_cm[-lim_low:]\n",
    "    cdCH4_lower = np.sum((press_atm_lower/kpatoatm/(kB*temp_lower)/mtocm**3)*mrCH4[-lim_low:]*L_cm_lower/mol*mtocm**2)\n",
    "\n",
    "    # Calculate the Top-Of-Atmosphere Spectral Radiance (TOASR) in the band [W/m2/m/sr]\n",
    "    solar_spectrum = solarradiance/np.pi * np.cos(solarangle*deg)\n",
    "    toasr = np.mean(np.exp(-(odCH4pts_lower + odCH4pts_upper + odCO2pts + odH2Opts)) * solar_spectrum)\n",
    "    \n",
    "    print(\"--- %s seconds --- to run radtran()\" % (time.time() - start_time))\n",
    "\n",
    "    return toasr, odCH4pts_lower, odCH4pts_upper, odCO2pts, odH2Opts, solar_spectrum, cdCH4, cdCH4_lower\n",
    "\n",
    "def retrieve(frac_refl_data, instrument, method, targheight, obsheight, solarangle, obsangle, num_layers=100):\n",
    "    '''\n",
    "    Infer methane column enhancements from fractional reflectance measurements.\n",
    "\n",
    "    Arguments\n",
    "        frac_refl_data [float] : Array of fractional reflectance data, deltaR = (cR-R0)/R0\n",
    "                                 e.g., DeltaR_SBMP from eq. (1) in Varon et al. 2021 AMT\n",
    "        instrument     [str]   : MSI instrument. Choose 'S2A' or 'S2B'\n",
    "        method         [str]   : Retrieval method corresponding to frac_refl_data\n",
    "                                 Choose 'MBSP' or 'SBMP'\n",
    "        targheight     [float] : Target elevation above sea level in km\n",
    "        obsheight      [float] : Altitude of satellite instrument in km. Can use 100 km as if satellite were at top of atmosphere\n",
    "        solarangle     [float] : Solar zenith angle in degrees\n",
    "        obsangle       [float] : Viewing zenith angle of instrument in degrees\n",
    "        num_layers     [int]   : Number of vertical pressure layers for the radiative transfer calculation\n",
    "    '''\n",
    "\n",
    "    # Choose method\n",
    "    if method == 'SBMP':\n",
    "        \n",
    "        # Get toasr, optical depths, etc. from radtran()\n",
    "        toasr_12, odCH4_lower_12, odCH4_upper_12, odCO2_12, odH2O_12, solar_spectrum_12, cdCH4, cdCH4_lower = radtran(targheight, obsheight, solarangle, obsangle, instrument, band=12, num_layers=100)\n",
    "\n",
    "        def frac_abs_SBMP_difference(ch4_enh, data): \n",
    "            '''\n",
    "            Fractional absorption model to compare with measurements for SBMP method.\n",
    "            \n",
    "            Arguments\n",
    "                ch4_enh [float] : Modeled enhancement as fraction of background\n",
    "                data    [float] : Actual (cR-R0)/R0\n",
    "            '''\n",
    "                \n",
    "            ch4 = ch4_enh + 1\n",
    "            toasr_CH4enh_12 = np.mean(np.exp(-(ch4*odCH4_lower_12 + odCH4_upper_12 + odCO2_12 + odH2O_12))*solar_spectrum_12)\n",
    "            frac_abs_SBMP = (toasr_CH4enh_12 - toasr_12)/toasr_12\n",
    "            \n",
    "            return frac_abs_SBMP - data\n",
    "    \n",
    "    elif method == 'MBSP':\n",
    "\n",
    "        # Get toasr, optical depths, etc. from radtran()\n",
    "        toasr_11, odCH4_lower_11, odCH4_upper_11, odCO2_11, odH2O_11, solar_spectrum_11, _, _ = radtran(targheight, obsheight, solarangle, obsangle, instrument, band=11, num_layers=num_layers)\n",
    "        toasr_12, odCH4_lower_12, odCH4_upper_12, odCO2_12, odH2O_12, solar_spectrum_12, cdCH4, cdCH4_lower = radtran(targheight, obsheight, solarangle, obsangle, instrument, band=12, num_layers=num_layers)\n",
    "        \n",
    "        def frac_abs_MBSP_difference(ch4_enh, data):\n",
    "            '''\n",
    "            Fractional absorption model to compare with measurements for MBSP method.\n",
    "            \n",
    "            Arguments\n",
    "                ch4_enh [float] : Modeled enhancement as fraction of background\n",
    "                data    [float] : Actual (cR-R0)/R0\n",
    "            '''\n",
    "                \n",
    "            ch4 = ch4_enh + 1\n",
    "            toasr_CH4enh_12 = np.mean(np.exp(-(ch4*odCH4_lower_12 + odCH4_upper_12 + odCO2_12 + odH2O_12))*solar_spectrum_12)\n",
    "            toasr_CH4enh_11 = np.mean(np.exp(-(ch4*odCH4_lower_11 + odCH4_upper_11 + odCO2_11 + odH2O_11))*solar_spectrum_11)\n",
    "\n",
    "            frac_abs_12 = (toasr_CH4enh_12 - toasr_12)/toasr_12\n",
    "            frac_abs_11 = (toasr_CH4enh_11 - toasr_11)/toasr_11\n",
    "            \n",
    "            frac_abs_MBSP = frac_abs_12 - frac_abs_11 \n",
    "                \n",
    "            return frac_abs_MBSP - data\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Bad method selection. Must be \"MBSP\" or \"SBMP\".')\n",
    "     \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Do retrieval\n",
    "    (num_rows, num_cols) = frac_refl_data.shape\n",
    "    ch4_out = np.zeros((num_rows, num_cols))\n",
    "\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "\n",
    "            data_temp = frac_refl_data[i,j]\n",
    "                \n",
    "            if np.isnan(data_temp):\n",
    "                print('Found nan, skipping.')\n",
    "                ch4_out[i,j] = np.nan\n",
    "            \n",
    "            # Solve for the best-fit fractional column (fraction of background)\n",
    "            else:\n",
    "                if method == 'SBMP':\n",
    "                    ch4_temp = scipy.optimize.newton(lambda ch4_scale: frac_abs_SBMP_difference(ch4_scale,data_temp), 0, rtol=0.0001, maxiter=10000, disp=False)\n",
    "                elif method == 'MBSP':\n",
    "                    ch4_temp = scipy.optimize.newton(lambda ch4_scale: frac_abs_MBSP_difference(ch4_scale,data_temp), 0, rtol=0.0001, maxiter=10000, disp=False)\n",
    "\n",
    "                # Convert the fractional column to absolute vertical column density in mol/m2   \n",
    "                AMF = 1/np.cos(obsangle*deg) + 1/np.cos(solarangle*deg)\n",
    "                ch4_out[i,j] = ch4_temp * (cdCH4_lower/cdCH4)*(cdCH4/AMF)\n",
    "        \n",
    "    # Time    \n",
    "    print(\"--- %s seconds --- to optimize\" % (time.time() - start_time))\n",
    "\n",
    "    return ch4_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef2391b-4c77-4b59-b700-768e672fb816",
   "metadata": {},
   "source": [
    "## Radiative Transfer Model Part 2 - Download HAPI data \n",
    "\n",
    "If this is the fist time you're runnning this tool you will need to download the requisite HAPI data. If so, please set this to <b>\"True\"</b>. If you have already done this, it can be set to <b>\"False\"</b> so that this legnthy process is avoided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daef41a-9013-454f-a5dc-df8b285cfea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True if you need to setup your data directory\n",
    "run_setup = False\n",
    "\n",
    "if run_setup:\n",
    "    setup.setup_retrieval_directory('S2A','hapi_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5b473-29ff-418d-b0e8-e1084c070605",
   "metadata": {},
   "source": [
    "## Radiative Transfer Model Part 3 - Reflectance Values to mol/m2\n",
    "\n",
    "This section converts the reflectance data of Sentinel-2 to usable scientific units (mol/m2). \n",
    "\n",
    "The following section may reqire some user input. The target height will need to be changed for the area of study to reflect its altitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac6edf3-6ffb-4542-b09d-204a0a0a1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "num_layers = 100\n",
    "targheight = 0.17 # in kilometres \n",
    "obsheight = 786 # in kilometres\n",
    "solarangle = sun_zenith_mean\n",
    "obsangle = view_zenith_mean\n",
    "instrument = 'S2A' # Sentinel-2A or 2B\n",
    "method = 'SBMP' # We use SBMP in the case of MBMP as they process the same. \n",
    "\n",
    "# Path to your .tiff file\n",
    "tiff_file = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Varon methane detection code\\s2_ch4_code_share\\SWIR_diff.tiff\"\n",
    "\n",
    "# Read the .tiff file\n",
    "with rasterio.open(tiff_file) as src:\n",
    "    # Read the image data into a numpy array\n",
    "    frac_refl_data = src.read(1)  # Assumes the data is in the first band\n",
    "\n",
    "# Try the column retrieval\n",
    "methane_column_retrieval = rt.retrieve(frac_refl_data, instrument, method, targheight, obsheight, solarangle, obsangle, num_layers=num_layers)\n",
    "\n",
    "methane_column_retrieval # units mol/m2\n",
    "\n",
    "# Save the output array as a new .tiff file\n",
    "output_tiff = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Varon methane detection code\\s2_ch4_code_share\\CH4_Concentration.tiff\"\n",
    "\n",
    "# Get the metadata of the original .tiff file to use the same attributes\n",
    "with rasterio.open(tiff_file) as src:\n",
    "    metadata = src.meta\n",
    "\n",
    "# Update metadata for the output file, ensure it's 1-band (grayscale)\n",
    "metadata.update(dtype=rasterio.float32, count=1)\n",
    "\n",
    "# Write the new data to a .tiff file\n",
    "with rasterio.open(output_tiff, 'w', **metadata) as dst:\n",
    "    dst.write(methane_column_retrieval.astype(rasterio.float32), 1)  # Ensure the data is written as float32\n",
    "\n",
    "print(f\"Output saved to: {output_tiff}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe5fa5-5283-4388-9060-e3e263be03e2",
   "metadata": {},
   "source": [
    "## Plume Masking\n",
    "\n",
    "Now the radiative transfer model has completed its work, we need to identify the plume's extent. This code box uses a 95 percentile thresholding method to determine which pixels constitute the plume. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d33511-2703-466c-95f2-bcb1ecc554ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "input_file = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Varon methane detection code\\s2_ch4_code_share\\CH4_Concentration.tiff\"\n",
    "output_mask_file = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Varon methane detection code\\s2_ch4_code_share\\plume_mask.tiff\"\n",
    "\n",
    "# Load the methane enhancement raster\n",
    "with rasterio.open(input_file) as src:\n",
    "    methane_data = src.read(1).astype(float)  # Read the first band\n",
    "    metadata = src.meta.copy()  # Copy metadata for output file\n",
    "\n",
    "# Step 1: Compute the 95th percentile threshold\n",
    "percentile_95 = np.nanpercentile(methane_data, 95)\n",
    "\n",
    "# Step 2: Create a binary plume mask\n",
    "plume_mask = np.where(methane_data >= percentile_95, 1, 0)\n",
    "\n",
    "# Step 3: Apply a 3×3 median filter for noise reduction\n",
    "plume_mask_filtered = ndimage.median_filter(plume_mask, size=3)\n",
    "\n",
    "# Step 4: Save the plume mask as a new TIFF file\n",
    "metadata.update(dtype=rasterio.uint8, count=1, nodata=None)  # Ensure nodata is removed\n",
    "\n",
    "with rasterio.open(output_mask_file, \"w\", **metadata) as dst:\n",
    "    dst.write(plume_mask_filtered.astype(rasterio.uint8), 1)\n",
    "\n",
    "# Print confirmation and threshold value\n",
    "print(f\"Plume mask saved to: {output_mask_file}\")\n",
    "print(f\"95th percentile threshold for methane enhancement: {percentile_95}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46c0d5-b0cc-4201-b7ac-a5a533ea5107",
   "metadata": {},
   "source": [
    "## Plume Dimentions\n",
    "\n",
    "This code box measures the length and area of the plume base on the mask. <b>The length currently doesn't work and so you will need to measure this in a GIS.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80583d-001a-411a-ac84-79057342d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for plume mask\n",
    "plume_mask_file = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Varon methane detection code\\s2_ch4_code_share\\plume_mask.tiff\"\n",
    "\n",
    "# Load the plume mask\n",
    "with rasterio.open(plume_mask_file) as src:\n",
    "    plume_mask = src.read(1).astype(float)  # Read binary plume mask (1 = plume, 0 = background)\n",
    "    transform = src.transform  # Get spatial transformation info\n",
    "\n",
    "# Step 1: Compute pixel area in square meters\n",
    "pixel_width = transform.a  # X-resolution (meters per pixel)\n",
    "pixel_height = -transform.e  # Y-resolution (meters per pixel, negative because of image orientation)\n",
    "pixel_area = pixel_width * pixel_height  # Area of a single pixel in square meters\n",
    "\n",
    "# Step 2: Compute total plume area (number of plume pixels * pixel area)\n",
    "plume_area = np.sum(plume_mask) * pixel_area  # Sum all plume pixels (value=1) and multiply by pixel area\n",
    "\n",
    "# Step 3: Compute plume length scale L\n",
    "L = np.sqrt(plume_area)\n",
    "\n",
    "# Print results\n",
    "print(f\"Pixel size: {pixel_width} x {pixel_height} meters\")\n",
    "print(f\"Total plume area: {plume_area:.2f} m²\")\n",
    "print(f\"Computed plume length scale (L): {L:.2f} m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7a33c-7b7c-49ff-9c07-64ebe2bdd0f7",
   "metadata": {},
   "source": [
    "## Wind Speed\n",
    "\n",
    "The next code box detemines wind speed using the ERA5 API which is then adjusted calibration parameters from large-eddy simulations that model how wind affects methane plumes from Varon er al. (2021).\n",
    "\n",
    "<div align=\"center\"><b>U_eff = 0.33 * U_10 + 0.45</b></div>\n",
    "\n",
    "Where:\n",
    "- <b>U_eff</b> is the effective wind speed.\n",
    "- <b>U_10</b> is tthe local 10m wind speed.  \n",
    "\n",
    "There will be a long warning message but it can be ignored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde37ed4-7d85-43fb-8843-03dbe30a8e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r'C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\Algerian_Oil_and_Gas_Fields.csv'\n",
    "\n",
    "\n",
    "# Function to extract bounding box and calculate center from site_id\n",
    "def get_location_from_site_id(site_id, csv_path):\n",
    "    \"\"\"\n",
    "    Extract center latitude and longitude for a site based on site_id.\n",
    "\n",
    "    Args:\n",
    "    - site_id (int): The ID of the site to extract.\n",
    "    - csv_path (str): Path to the CSV containing site boundaries.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary with latitude and longitude of the center.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    site = df[df['id'] == site_id]\n",
    "    if site.empty:\n",
    "        raise ValueError(f\"Site ID {site_id} not found in the CSV file.\")\n",
    "    site = site.iloc[0]\n",
    "    center_lat = (site['south'] + site['north']) / 2\n",
    "    center_lon = (site['west'] + site['east']) / 2\n",
    "    return {'latitude': center_lat, 'longitude': center_lon}\n",
    "\n",
    "# Get the location for the ERA5 data request\n",
    "location = get_location_from_site_id(site_id, csv_path)\n",
    "\n",
    "# Initialize the CDS API client\n",
    "c = cdsapi.Client()\n",
    "\n",
    "# Define parameters for the data request\n",
    "# Extract the start date from active_temporal_extent and assign it to date\n",
    "date = active_temporal_extent[0]  # Use the first element as the single date\n",
    "\n",
    "# Now the variable 'date' can be used with the other API\n",
    "\n",
    "# date = active_temporal_extent (update this somehow so that no input is needed in this box)\n",
    "\n",
    "# Retrieve ERA5 data and store it in a temporary file\n",
    "with NamedTemporaryFile(suffix='.nc') as tmp_file:\n",
    "    result = c.retrieve(\n",
    "        'reanalysis-era5-single-levels',\n",
    "        {\n",
    "            'product_type': 'reanalysis',\n",
    "            'variable': ['10m_u_component_of_wind', '10m_v_component_of_wind'],\n",
    "            'year': date.split('-')[0],\n",
    "            'month': date.split('-')[1],\n",
    "            'day': date.split('-')[2],\n",
    "            'time': ['10:00'],  # Specify time of interest\n",
    "            'format': 'netcdf',  # NetCDF format\n",
    "            'area': [\n",
    "                location['latitude'] + 0.25, location['longitude'] - 0.25,\n",
    "                location['latitude'] - 0.25, location['longitude'] + 0.25,\n",
    "            ],  # Small bounding box around the location\n",
    "        }\n",
    "    )\n",
    "    # Download data to the temporary file\n",
    "    result.download(tmp_file.name)\n",
    "    \n",
    "    # Load the dataset with xarray\n",
    "    ds = xr.open_dataset(tmp_file.name)\n",
    "\n",
    "# Extract u and v components\n",
    "u10 = ds['u10'].sel(latitude=location['latitude'], longitude=location['longitude'], method='nearest')\n",
    "v10 = ds['v10'].sel(latitude=location['latitude'], longitude=location['longitude'], method='nearest')\n",
    "\n",
    "# Calculate wind speed\n",
    "wind_speed = np.sqrt(u10**2 + v10**2)\n",
    "\n",
    "# Handle single timestep case\n",
    "if 'time' in u10.dims:\n",
    "    # Multiple timesteps (not likely in this case since we specified 10:00 only)\n",
    "    for time, speed in zip(u10.time.values, wind_speed.values):\n",
    "        print(f\"{time}: Wind Speed = {speed:.2f} m/s\")\n",
    "else:\n",
    "    # Single timestep\n",
    "    wind_speed_value = wind_speed.values.item()  # Convert array to scalar\n",
    "    \n",
    "\n",
    "# Plume wind adjustments Constants from Varon et al. 2021\n",
    "alpha = 0.33\n",
    "beta = 0.45  # in m/s\n",
    "\n",
    "# Compute the effective wind speed\n",
    "U_eff = alpha * wind_speed_value + beta\n",
    "\n",
    "# Print result\n",
    "print(f\"10m Wind Speed (U10) from ERA5: {wind_speed_value:.2f} m/s\")\n",
    "print(f\"Effective Wind Speed (Ueff): {U_eff:.2f} m/s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d5a4d-b645-42c6-81c9-c5e42b5a25fe",
   "metadata": {},
   "source": [
    "## Calculating total methane in kg\n",
    "\n",
    "The next codebox calculates the total amount of methane in the masked area in kg. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dd4514-07d8-4b98-86da-9fc803197ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "methane_file = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Varon methane detection code\\s2_ch4_code_share\\CH4_Concentration.tiff\"\n",
    "plume_mask_file = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Varon methane detection code\\s2_ch4_code_share\\plume_mask.tiff\"\n",
    "\n",
    "# Constants\n",
    "M_CH4 = 0.016  # kg/mol (molar mass of methane)\n",
    "\n",
    "# Load methane enhancement data\n",
    "with rasterio.open(methane_file) as src:\n",
    "    methane_data = src.read(1).astype(float)  # Read methane enhancement (mol/m²)\n",
    "    transform = src.transform  # Get pixel size information\n",
    "\n",
    "# Load plume mask\n",
    "with rasterio.open(plume_mask_file) as src:\n",
    "    plume_mask = src.read(1).astype(bool)  # Read plume mask (1 = plume, 0 = background)\n",
    "\n",
    "# Compute pixel area (same method as before)\n",
    "pixel_width = transform.a  # X-resolution (m per pixel)\n",
    "pixel_height = -transform.e  # Y-resolution (m per pixel, negative because of orientation)\n",
    "pixel_area = pixel_width * pixel_height  # m² per pixel\n",
    "\n",
    "# Compute IME: sum of (methane enhancement * pixel area * molar mass), only for plume pixels\n",
    "IME = np.sum(methane_data[plume_mask] * pixel_area * M_CH4)\n",
    "\n",
    "# Print result\n",
    "print(f\"Computed Integrated Methane Enhancement (IME): {IME:.4f} kg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d23799b-542e-492f-80be-2255e6d2394e",
   "metadata": {},
   "source": [
    "## Emission rate calculation\n",
    "\n",
    "The next section calculates the emission rate based on the total mass of methane in kg (IME), the effective windspeed (U_eff) and the plume legnth (L). Results are given in kg per second and per hour.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d7aca-afab-4291-a1c4-867bc76a6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "# IME = 2554.6573  # kg \n",
    "# U_eff = 1.06  # m/s \n",
    "# L = 358  # Placeholder: Replace with actual plume length scale from Step 2\n",
    "\n",
    "# Compute source rate Q (kg/s)\n",
    "Q_kg_s = (IME * U_eff) / L\n",
    "\n",
    "# Convert to kg/h\n",
    "Q_kg_h = Q_kg_s * 3600\n",
    "\n",
    "# Print result\n",
    "print(f\"Estimated Methane Source Rate: {Q_kg_s:.4f} kg/s\")\n",
    "print(f\"Estimated Methane Source Rate: {Q_kg_h:.2f} kg/h\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ddc7e8-6f62-4461-8f74-2cc6c38b3cde",
   "metadata": {},
   "source": [
    "## Uncertainty \n",
    "\n",
    "The final code box calculates the +- uncertanty values for the emission rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48142b-d0a5-44e0-95d6-bb9f6c074d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_10 = wind_speed_value\n",
    "\n",
    "# Use the median RMSE from the study for inland terrain\n",
    "wind_error = 1.34  # Median RMSE value for ERA5 wind speed over inland terrain\n",
    "# source: https://www.sciencedirect.com/science/article/pii/S1364032122006293\n",
    "\n",
    "# Compute relative wind uncertainty\n",
    "wind_error_percent = wind_error / U_10  \n",
    "sigma_wind = wind_error_percent * Q_kg_h  # Wind uncertainty contribution\n",
    "\n",
    "# Uncertainty estimates from study\n",
    "retrieval_error = 0.13  # Column retrieval precision (mol/m², from study)\n",
    "IME_error_percent = 0.15  # IME model error (15% of IME)\n",
    "multi_pass_error_percent = 0.01  # Multi-pass uncertainty (1%)\n",
    "\n",
    "# Compute individual uncertainties\n",
    "sigma_retrieval = retrieval_error * Q_kg_h  # Retrieval error contribution\n",
    "sigma_IME = IME_error_percent * Q_kg_h  # IME model error contribution\n",
    "sigma_multi_pass = multi_pass_error_percent * Q_kg_h  # Multi-pass retrieval error contribution\n",
    "\n",
    "# Compute total uncertainty using quadrature addition\n",
    "sigma_total = np.sqrt(sigma_wind**2 + sigma_retrieval**2 + sigma_IME**2 + sigma_multi_pass**2)\n",
    "\n",
    "# Compute uncertainty bounds\n",
    "Q_lower = Q_kg_h - sigma_total\n",
    "Q_upper = Q_kg_h + sigma_total\n",
    "\n",
    "# Print results\n",
    "print(f\"Estimated Methane Source Rate: {Q_kg_h:.2f} kg/h\")\n",
    "print(f\"Total Uncertainty (1σ): ±{sigma_total:.2f} kg/h\")\n",
    "print(f\"Final Source Rate Range: {Q_lower:.2f} to {Q_upper:.2f} kg/h\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0196ddb-3464-4834-8747-13c48b9f6c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
