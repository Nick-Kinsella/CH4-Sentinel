{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f561c3-51d4-4476-922d-876088df12c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentinel-2 Methane Emission Detection and Analysis Tool\n",
    "\n",
    "## Overview \n",
    "This notebook provides a comprehensive workflow for detecting and analysing methane plumes from oil and gas facilities using Sentinel-2 satellite data. It combines satellite imagery processing, wind speed analysis, and regression modelling to estimate methane emission rates accurately. Key functionalities include:\n",
    "\n",
    "1. **SWIR Analysis**: Utilises Sentinel-2's Short-Wave Infrared (SWIR) bands to highlight methane plumes by comparing active and non-active regions.\n",
    "2. **Plume Detection and Tagging**: Supports manual tagging of plume locations and segmentation for precise analysis.\n",
    "3. **Regression-Based Emission Estimation**: Employs a trained regression model to estimate methane emission rates based on plume characteristics and wind speed data.\n",
    "4. **Interactive Visualisation**: Creates interactive maps to visualise true-colour images, SWIR-derived plumes, and analysis results.\n",
    "5. **Dynamic Model Updates**: Facilitates the addition of new training data to refine the regression model for improved predictions.\n",
    "\n",
    "This tool is designed for researchers, policymakers, and environmental analysts aiming to quantify and monitor methane emissions efficiently.\n",
    "\n",
    "The section below imports the packages needed to run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af9cfbc-e95b-4685-a7e2-19f2ccc7cf3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Core System and Numerical Operations\n",
    "import os  # For file path and system-level operations\n",
    "import numpy as np  # For numerical operations and array manipulations\n",
    "import pandas as pd  # For handling tabular data (e.g., CSV files)\n",
    "\n",
    "# File Handling and Temporary Files\n",
    "from tempfile import NamedTemporaryFile  # For creating temporary files\n",
    "\n",
    "# Machine Learning and Statistical Analysis\n",
    "from sklearn.linear_model import LinearRegression  # Regression model for methane emission estimation\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # Metrics for model evaluation\n",
    "from sklearn.decomposition import PCA  # For principal component analysis (PCA)\n",
    "\n",
    "# Data Analysis and Manipulation\n",
    "import xarray as xr  # For working with multidimensional arrays (e.g., NetCDF files)\n",
    "import cdsapi  # For accessing the Copernicus Climate Data Store API\n",
    "import requests  # For making HTTP requests (e.g., downloading data)\n",
    "import openeo  # For cloud-based geospatial data processing\n",
    "\n",
    "# Geospatial Data Handling\n",
    "import geopandas as gpd  # For working with GeoJSON and vector geospatial data\n",
    "import rasterio  # For working with raster data\n",
    "from rasterio.enums import Resampling  # For resampling raster data\n",
    "from rasterio.plot import show  # For visualising raster data\n",
    "from rasterio.transform import from_origin  # For creating geospatial transformations\n",
    "from rasterio.warp import calculate_default_transform, reproject  # For reprojection of raster data\n",
    "from shapely.geometry import Point, LineString  # For geometric operations in geospatial analysis\n",
    "\n",
    "# Image Processing\n",
    "from skimage import exposure  # For adjusting image exposure and contrast\n",
    "from PIL import Image  # For basic image manipulation\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "\n",
    "# Mathematical and Geometric Computations\n",
    "from scipy.ndimage import label  # For segmentation and labelling of regions\n",
    "from scipy.spatial import ConvexHull  # For calculating convex hulls of shapes\n",
    "\n",
    "# Interactive Maps and Visualisation\n",
    "import folium  # For creating interactive maps\n",
    "from folium import Map, GeoJson, LayerControl, LatLngPopup  # Map features and interactions\n",
    "from folium.raster_layers import ImageOverlay  # Overlay raster images on maps\n",
    "from folium import FeatureGroup  # For grouping map layers\n",
    "import matplotlib.pyplot as plt  # For plotting and visualisation\n",
    "\n",
    "# Jupyter Notebook Integration\n",
    "from IPython.display import display as ipy_display  # For displaying outputs in notebooks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67714102-a656-4414-9e45-42c8c80460ea",
   "metadata": {},
   "source": [
    "## Connect to OpenEO\n",
    "\n",
    "The code below establishes a connection with the Copernicus openEO platform which provides a wide variety of earth observation datasets\n",
    "\n",
    "- If this does not read as 'Authorised successfully' or 'Authenticated using refresh token', then please ensure that you have completed the setup steps as outlined in section 2.3.6 of the how to guide. \n",
    "\n",
    "- If you have followed the steps in section 2.3.6 correctly and the problem persists, please look at https://dataspace.copernicus.eu/news for any information about service interruptions. \n",
    "\n",
    "- If there is no news of service problems you can raise a ticket here: https://helpcenter.dataspace.copernicus.eu/hc/en-gb/requests/new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdfface4-832c-4c3b-b79c-a6886878cd83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Connection to 'https://openeo.dataspace.copernicus.eu/openeo/1.2/' with OidcBearerAuth>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\n",
    "connection.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d0674c-3b9c-4ab0-aafe-0526baa82e66",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dispaly field names and select site_id. \n",
    "\n",
    "This loads the oil and gas field list Algeria. Hassi Messaoud is site 86. If you are interested in a different field, please look-up its id number. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3110af1e-a1d9-4fb8-8663-51d279eac192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id                   name      west     south      east     north\n",
      "  1           Gour Mahmoud  2.545738 26.832422  2.689150 26.980223\n",
      "  2          Hassi Hassine  2.481688 26.814902  2.556715 26.878123\n",
      "  3              In Sallah  2.451958 27.033471  2.528314 27.187470\n",
      "  4        Mahbes Guenatir  3.166512 26.177879  3.197605 26.203481\n",
      "  5           Djebel Thara  3.062622 25.988381  3.102147 26.022814\n",
      "  6                Unknown  3.243313 26.027347  3.265408 26.045501\n",
      "  7         Krebb Ed Douro  2.583645 25.944587  2.628648 25.980437\n",
      "  8              Tibardine  2.210629 25.929342  2.342364 26.046971\n",
      "  9            Oued Djaret  2.305817 26.640617  2.357529 26.703343\n",
      " 10      Djebel Mouahdrine  2.976608 26.088212  3.050097 26.165123\n",
      " 11          Hassi Moumene  2.458900 27.402452  2.631038 27.597842\n",
      " 12       Garet El Befinat  2.248445 27.743627  2.337012 27.842359\n",
      " 13                    Reg  1.914508 28.002131  2.231025 28.293102\n",
      " 14               Bouteraa  1.764153 27.805731  1.964158 27.966950\n",
      " 15          Garet El Guef  2.013804 27.266284  2.120814 27.427546\n",
      " 16             Oued Talha  1.185312 27.232915  1.355358 27.329163\n",
      " 17           Hassi M’Sari  1.135325 27.348024  1.292968 27.445458\n",
      " 18        Adrar Morrat NE  1.472323 25.758105  1.543072 25.820093\n",
      " 19        Adrar Morrat SW  1.325024 25.618675  1.362288 25.662098\n",
      " 20        Bahar El Hammar  1.690021 26.179910  1.909041 26.398500\n",
      " 21                    Tit  1.919312 26.799760  1.976488 26.848910\n",
      " 22           Tirechoumine  2.144657 26.302966  2.200625 26.376548\n",
      " 23                Anasmit  2.941959 26.183354  2.975698 26.225694\n",
      " 24             In Bazzene  2.817452 26.375095  2.873232 26.485052\n",
      " 25           In Bazzene N  2.746221 26.547543  2.826332 26.615277\n",
      " 26           Djebel Belda  3.109231 26.390537  3.186969 26.448736\n",
      " 27          Hassi Barouda  1.050097 28.343425  1.608158 28.791775\n",
      " 28             Teguentour  2.413269 28.304684  2.640477 28.617118\n",
      " 29                Krechba  2.122249 29.011002  2.300413 29.188907\n",
      " 30           Erg Choueref  1.143895 29.227357  1.201671 29.265672\n",
      " 31                Bejouen  0.990000 29.056624  1.101014 29.152182\n",
      " 32                 Ramedj  0.480000 29.758852  0.660000 29.919129\n",
      " 33              Oued Zine  0.210000 28.048114  0.420000 28.160796\n",
      " 34             Hassi Sbaa -0.170000 28.133191 -0.100000 28.184157\n",
      " 35          Hassi Llatoou  0.270000 27.742549  0.340000 27.794153\n",
      " 36       Hassi Llatoou NE  0.290000 27.817747  0.420000 27.927813\n",
      " 37 Hassi Llatoou Cambrien  0.220000 27.801823  0.270000 27.837598\n",
      " 38           Qued Tourhar  0.600000 27.763975  0.650000 27.805974\n",
      " 39                 Azzene  0.570000 27.950772  0.660000 28.025501\n",
      " 40               Foukroun  0.520000 28.102992  0.630000 28.171253\n",
      " 41            Mekerrane N  1.299061 26.534100  1.326334 26.557268\n",
      " 42             Azrafil SE  0.230000 26.685878  0.340000 26.767907\n",
      " 43                Reggane  0.040000 26.749394  0.250000 26.947726\n",
      " 44      Kahal Tabelbala N -0.960000 27.842503 -0.880000 27.890944\n",
      " 45  Djebel Heirane Kahal  -0.880000 27.627314 -0.840000 27.667681\n",
      " 46       Djebel Heirane N -0.860000 27.326894 -0.850000 27.335198\n",
      " 47           Feidj El Had -1.520000 28.127219 -1.500000 28.139278\n",
      " 48         Hassi M’Dakane -1.940000 28.282285 -1.800000 28.385187\n",
      " 49       Touat / Decheira -0.550000 28.146955 -0.470000 28.237020\n",
      " 50        Hassi Tidjerane  0.420000 30.818336  0.630000 30.967446\n",
      " 51        Hassi Ba Hammou  1.813823 30.800755  2.059613 31.006995\n",
      " 52                Meharez -1.820000 31.338219 -1.790000 31.358103\n",
      " 53            Hassi R’Mel  3.000179 32.599728  3.554483 33.260904\n",
      " 54          Hassi R’Mel S  2.937380 32.583015  3.091354 32.679863\n",
      " 55                Macouda  3.682521 32.370513  3.750694 32.424035\n",
      " 56                  Djorf  3.875494 32.547466  3.947155 32.591626\n",
      " 57            Oued Noumer  3.979121 32.355484  4.067678 32.438972\n",
      " 58                Unknown  4.011206 32.639105  4.025543 32.649208\n",
      " 59            Oued Noumer  3.950413 32.494619  3.987332 32.524576\n",
      " 60            Oued Noumer  3.935478 32.219795  4.034542 32.300954\n",
      " 61                Unknown  4.150629 32.219463  4.195374 32.251143\n",
      " 62                Unknown  4.086538 32.262291  4.134789 32.299504\n",
      " 63                Unknown  4.068948 32.242557  4.099153 32.263330\n",
      " 64              Ait Kheir  4.018101 32.124358  4.141814 32.228046\n",
      " 65                Unknown  3.944636 32.168058  3.966915 32.188722\n",
      " 66                Unknown  3.921997 32.119849  3.952077 32.145382\n",
      " 67        Fouye Tabankort  7.250395 28.244832  7.890242 28.791531\n",
      " 68               Adouhoum  7.614058 27.948427  7.687330 28.008990\n",
      " 69             Mezoratine  7.799437 27.707049  7.953025 27.973663\n",
      " 70                  Remal  8.320312 27.634681  8.393082 27.682262\n",
      " 71                  Alrar  9.473960 28.503828  9.912727 28.899910\n",
      " 72           Alar (Lybia)  9.885335 28.772161 10.125967 28.999661\n",
      " 73                   Stah  9.629285 28.843233  9.821029 28.992907\n",
      " 74              Mereksene  9.644143 29.088280  9.722838 29.159310\n",
      " 75                 Ohanet  8.747287 28.652888  9.080135 28.943321\n",
      " 76                 Dimera  9.241536 28.622614  9.298225 28.674360\n",
      " 77                 Dimera  9.226440 28.671757  9.284095 28.730235\n",
      " 78                 Dimera  9.237655 28.730859  9.311381 28.777953\n",
      " 79                 Dimera  9.273984 28.774812  9.292776 28.789583\n",
      " 80                 Dimera  9.246932 28.816764  9.289287 28.848681\n",
      " 81                 Dimera  9.105714 29.001807  9.149999 29.038799\n",
      " 82                  Antar  9.788025 28.988244  9.888014 29.116190\n",
      " 83         Rhourde Adra S  6.396711 29.178533  6.673247 29.610869\n",
      " 84          Rhourde Nouss  6.546406 29.629786  6.798899 29.804887\n",
      " 85           Rhourde Adra  6.701414 29.435238  6.830522 29.612676\n",
      " 86         Hassi Messaoud  5.732554 31.486297  6.308794 31.973124\n",
      " 87                  Nezia  6.478933 30.623645  6.579657 30.735782\n",
      " 88            Gassi Touil  6.424240 30.275509  6.615083 30.501270\n",
      " 89          Rhourde Akbar  6.707081 31.158087  6.835192 31.235315\n",
      " 90          Rhourde Sayah  6.624245 30.980125  6.658716 31.006952\n",
      " 91                El Merk  7.754826 29.869130  8.232034 30.352406\n",
      " 92                Ourhoud  7.955037 30.529811  8.231350 30.866118\n",
      " 93         Bir Sal Fatima  8.413974 31.115948  8.468348 31.165059\n",
      " 94         Bir Sal Fatima  8.352659 31.052656  8.430065 31.133495\n",
      " 95         Bir Sal Fatima  8.357446 30.949462  8.469877 31.035093\n",
      " 96         Bir Sal Fatima  8.470566 31.170334  8.605618 31.297526\n",
      " 97         Bir Sal Fatima  8.286654 31.248951  8.340893 31.343294\n",
      " 98               Qoubba N  8.049169 30.903886  8.291906 31.080596\n",
      " 99               El Borma  9.135643 31.557203  9.363310 31.737478\n",
      "100          Hassi Berkine  7.997137 31.041293  8.075740 31.113050\n",
      "101          Hassi Berkine  8.044411 31.121748  8.193575 31.249377\n"
     ]
    }
   ],
   "source": [
    "studysite_csv = pd.read_csv(r'C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\Algerian_Oil_and_Gas_Fields.csv')\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(studysite_csv.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4115bf0d-be37-48b7-bed1-f3929708b174",
   "metadata": {},
   "source": [
    "# Multi-Band Multi-Pass Analysis\n",
    "\n",
    "In the code box below, specify the field number we are interested in for analysis. \n",
    "\n",
    "<p style=\"text-align: center;\"><b>site_id</b> = 86</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f938e585-a992-4004-b7a6-c71fb7322bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site 86 (Hassi Messaoud) loaded correctly.\n"
     ]
    }
   ],
   "source": [
    "site_id = 86  # Specify the oil and gas field ID for the field you want to examine.\n",
    "\n",
    "# Retrieve the name of the field from the dataset\n",
    "field_name = studysite_csv[studysite_csv['id'] == site_id].iloc[0]['name']\n",
    "\n",
    "# Print a confirmation message\n",
    "print(f\"Site {site_id} ({field_name}) loaded correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb74f40-ba0f-4dbb-9d38-08e5b33dc11f",
   "metadata": {},
   "source": [
    "# Multi-Band Multi-Pass Analysis\n",
    "\n",
    "Varon et al. (2021) showed that methane plumes from point sources could be imaged by differencing Sentinel-2’s SWIR-1 and SWIR-2 bands. The tool runs an analysis using a  multi-band-multi-pass retrieval method: \n",
    "\n",
    "First it calculates a multi-band-single-pass calculation for both active emission and no emission dates, resulting in two datasets which are then used together for a multi-band-multi-pass method. \n",
    "The multi-band-single-pass equation is as follows: \n",
    "\n",
    "\n",
    "<div align=\"center\"><b>MBSP = B11 - cB12</b></div>\n",
    "\n",
    "Where:\n",
    "- <b>B12</b> is the Sentinel-2 SWIR-2 band.\n",
    "- <b>B11</b> is the Sentinel-2 SWIR-1 band. \n",
    "- <b>c</b> is calculated by least-squares fitting B12 to B11 across the scene.  \n",
    "\n",
    "Once active emission and no emission scenes have been calculated, the following equation is used to calculate the multi-band-multi-pass raster. \n",
    "\n",
    "<div align=\"center\"><b>MBMP = ActiveMBSP − NoMBSP</b></div>\n",
    "\n",
    "Where:\n",
    "- <b>ActiveMBSP</b> is the multiband single pass for the active emission scene\n",
    "- <b>NoMBSP</b> is the multiband single pass for the no emission scene.  \n",
    "\n",
    "The active emission scene and no emission scene are considered in this analysis to be one satelite pass apart. To begin this process we need to determine what days have available satelite data. \n",
    "\n",
    "# Available dates for the analysis. \n",
    "\n",
    "Sentinel 2 provides data aproximately once every 2 - 3 days, so not every date you can enter into this tool is valid. The code below will tell you what dates are available to use for the oil/gas field of your choice. \n",
    "\n",
    "The one parameter you need to modify before running the code is: \n",
    "\n",
    "- <b>temporal_extent</b> = [\"2020-01-01\", \"2020-01-31\"] (change this to your chosen date range using \"YYYY-MM-DD\" format.)\n",
    "\n",
    "Once you have done this run the code and the available dates should appear below in a matter of seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3feb8600-dfdd-491b-bde9-2eaa760af099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available dates: ['2021-08-16', '2021-08-16', '2021-08-16', '2021-08-16', '2021-08-19', '2021-08-19', '2021-08-19', '2021-08-19', '2021-08-21', '2021-08-21', '2021-08-21', '2021-08-24', '2021-08-24', '2021-08-24', '2021-08-24', '2021-08-26', '2021-08-26', '2021-08-26', '2021-08-29', '2021-08-29', '2021-08-29', '2021-08-29', '2021-08-31', '2021-08-31', '2021-08-31', '2021-08-31', '2021-09-03', '2021-09-03', '2021-09-05', '2021-09-05', '2021-09-08', '2021-09-10', '2021-09-10', '2021-09-10', '2021-09-10', '2021-09-13', '2021-09-13', '2021-09-13', '2021-09-13']\n"
     ]
    }
   ],
   "source": [
    "def get_spatial_extent(site_id):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "    return {\n",
    "        \"west\": site['west'],\n",
    "        \"south\": site['south'],\n",
    "        \"east\": site['east'],\n",
    "        \"north\": site['north']\n",
    "    }\n",
    "\n",
    "def fetch_available_dates(site_id, temporal_extent):\n",
    "    spatial_extent = get_spatial_extent(site_id)\n",
    "    catalog_url = f\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?box={spatial_extent['west']}%2C{spatial_extent['south']}%2C{spatial_extent['east']}%2C{spatial_extent['north']}&sortParam=startDate&sortOrder=ascending&page=1&maxRecords=1000&status=ONLINE&dataset=ESA-DATASET&productType=L2A&startDate={temporal_extent[0]}T00%3A00%3A00Z&completionDate={temporal_extent[1]}T00%3A00%3A00Z&cloudCover=%5B0%2C{cloud_cover}%5D\"\n",
    "    response = requests.get(catalog_url)\n",
    "    response.raise_for_status()\n",
    "    catalog = response.json()\n",
    "    dates = [date.split('T')[0] for date in map(lambda x: x['properties']['startDate'], catalog['features'])]\n",
    "    return dates\n",
    "\n",
    "# Please enter your perameters here.\n",
    "temporal_extent = [\"2021-08-15\", \"2021-09-15\"]  # Specify the the date range you want to check for available data.\n",
    "cloud_cover = 5\n",
    "\n",
    "available_dates = fetch_available_dates(site_id, temporal_extent)\n",
    "print(\"Available dates:\", available_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c953b692-eb71-4c15-b3d3-95025f77bcc4",
   "metadata": {},
   "source": [
    "## Choosing the \"Active Emission\" Date\n",
    "\n",
    "A so called active emission date must be chosen from one of the available datasets. This will be the chosen day we are looking for plumes.  \n",
    "\n",
    "Like before, the one parameter you need to modify before running the code is:\n",
    "\n",
    "<p style=\"text-align: center;\"><b>temporal_extent</b> = [\"2020-01-17\", \"2020-01-17\"]</p>\n",
    "\n",
    "Change this to your chosen date range using \"YYYY-MM-DD\" format. \n",
    "\n",
    "Please note that the temporal extent dates <b><u>MUST BE IDENTICAL</u></b> because we are only choosing a single date.\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a709165f-4542-46da-af8e-a7199df573c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_emission(site_id, active_temporal_extent):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    active_emission = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=active_temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B11\", \"B12\"],\n",
    "    )\n",
    "    active_emission.download(\"Sentinel-2_active_emissionMBMP.Tiff\")\n",
    "\n",
    "# Enter parameters for the active emission day\n",
    "active_temporal_extent = [\"2019-11-20\", \"2021-11-20\"]\n",
    "\n",
    "active_emission(site_id, active_temporal_extent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc9eea-43af-400e-822f-725ce1afb0b2",
   "metadata": {},
   "source": [
    "## Choosing the \"No Emission\" Date\n",
    "\n",
    "Next we choose the no emission date using the same process. This is the dataset we will compare the \"Active Emission\" one too. The recommended choice is the satelite overpass immediately before the \"Active Emission\" one. \n",
    "\n",
    "<b>So if your active emission day is 2020-01-17, your no emission day would be 2020-01-14</b>\n",
    "\n",
    "In an ideal world, the \"No Emission\" day should contain no emissions, but in fields with a lot of activity like Hassi Messaoud, this may not be possible. Such an instance will not cause problems in most cases. The emissions for these dates will simply appear as dark clouds on the SWIR data and can be ignored in the analysis. \n",
    "\n",
    "The one parameter you need to modify before running the code is:\n",
    "\n",
    "<p style=\"text-align: center;\"><b>temporal_extent</b> = [\"2020-01-14\", \"2020-01-14\"]</p>\n",
    "\n",
    "The temporal extent dates <b><u>MUST BE IDENTICAL</u></b>\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74d95f-bc49-4233-b767-6a1daaaf68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_emission(site_id, temporal_extent):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    no_emission = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=no_temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B11\", \"B12\"],\n",
    "    )\n",
    "    no_emission.download(\"Sentinel-2_no_emissionMBMP.Tiff\")\n",
    "\n",
    "# Enter perameters for the active emission day\n",
    "no_temporal_extent = [\"2019-11-18\", \"2019-11-18\"]\n",
    "\n",
    "no_emission(site_id, no_temporal_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de701594-5589-41ad-8750-5a57f70cc130",
   "metadata": {},
   "source": [
    "## Choosing a Background Satelite Image\n",
    "\n",
    "This section helps with locating the source of the emission by displaying a true colour satelite image of the oil/gas field that the data will be superimposed over. This will help distinguish between true emissions and visual spectrum observable clouds. It is recommended that you choose the same date as your active emission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9db215-2b88-4bf4-b65c-06dc75e94a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_to_epsg4326(data, meta):\n",
    "    \"\"\"\n",
    "    Reprojects the given raster data to EPSG:4326 and returns the updated data and metadata.\n",
    "    \"\"\"\n",
    "    target_crs = \"EPSG:4326\"\n",
    "    \n",
    "    # Calculate transform and metadata for the target CRS\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        meta['crs'], target_crs, meta['width'], meta['height'], *meta['bounds']\n",
    "    )\n",
    "    \n",
    "    # Update metadata for the new projection\n",
    "    new_meta = meta.copy()\n",
    "    new_meta.update({\n",
    "        \"crs\": target_crs,\n",
    "        \"transform\": transform,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "    })\n",
    "    \n",
    "    # Prepare an in-memory array for reprojected data\n",
    "    reprojected_data = []\n",
    "    for i in range(meta['count']):\n",
    "        # Create an empty numpy array to store the reprojected data for the band\n",
    "        destination = np.empty((height, width), dtype=data[i].dtype)\n",
    "        reproject(\n",
    "            source=data[i],\n",
    "            destination=destination,\n",
    "            src_transform=meta['transform'],\n",
    "            src_crs=meta['crs'],\n",
    "            dst_transform=transform,\n",
    "            dst_crs=target_crs,\n",
    "            resampling=Resampling.nearest\n",
    "        )\n",
    "        reprojected_data.append(destination)\n",
    "    \n",
    "    return reprojected_data, new_meta\n",
    "\n",
    "def truecolour_image(site_id, temporal_extent):\n",
    "    \"\"\"\n",
    "    Downloads and reprojects Sentinel-2 true-colour images for a given site and temporal extent.\n",
    "    \"\"\"\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    truecolour_image = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B02\", \"B03\", \"B04\"],\n",
    "    )\n",
    "    # Download the true colour image\n",
    "    file_path = \"Sentinel-2_truecolourMBMP.Tiff\"\n",
    "    truecolour_image.download(file_path)\n",
    "    \n",
    "    # Read the file into memory\n",
    "    with rasterio.open(file_path) as src:\n",
    "        data = [src.read(i) for i in range(1, src.count + 1)]\n",
    "        meta = src.meta.copy()\n",
    "        meta['bounds'] = src.bounds\n",
    "\n",
    "    # Reproject the data in memory\n",
    "    reprojected_data, reprojected_meta = reproject_to_epsg4326(data, meta)\n",
    "    \n",
    "    # Save the reprojected file\n",
    "    output_file = \"Sentinel-2_truecolour_reprojected.Tiff\"\n",
    "    with rasterio.open(output_file, \"w\", **reprojected_meta) as dest:\n",
    "        for i, band in enumerate(reprojected_data, start=1):\n",
    "            dest.write(band, i)\n",
    "    \n",
    "    # Print the CRS of the output file\n",
    "    with rasterio.open(output_file) as reprojected_file:\n",
    "        print(\"CRS of the reprojected file:\", reprojected_file.crs)\n",
    "\n",
    "# Enter parameters for the no emission day\n",
    "temporal_extent = active_temporal_extent\n",
    "\n",
    "truecolour_image(site_id, temporal_extent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fde51c-73cf-4816-b880-bf4715dc35aa",
   "metadata": {},
   "source": [
    "## Running Plume Visualiser Analysis\n",
    "The code below will use the satelite data to display plumes above 1,400kgh-1 in ideal conditions. Provided all the variables above have been run correctly, this next section should take moments to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e39a4-71fd-4190-9838-2348bd4ee736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a way to NaN the urban areas in the SWIR_diff raster\n",
    "\n",
    "# Function to get bounds from the Oil and Gas Field bounding file\n",
    "def get_bounds(site_id, csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    site = df[df['id'] == site_id]\n",
    "    if site.empty:\n",
    "        raise ValueError(f\"Site ID {site_id} not found in the CSV file.\")\n",
    "    site = site.iloc[0]\n",
    "    return [[site['south'], site['west']], [site['north'], site['east']]]\n",
    "\n",
    "csv_path = r'C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\Algerian_Oil_and_Gas_Fields.csv'\n",
    "bounds = get_bounds(site_id, csv_path)\n",
    "\n",
    "# Define file paths\n",
    "Active_Multiband = \"Sentinel-2_active_emissionMBMP.Tiff\"\n",
    "No_Multiband = \"Sentinel-2_no_emissionMBMP.Tiff\"\n",
    "output_file = \"SWIR_diff_4326.tiff\"\n",
    "\n",
    "# Define a function for least squares fitting\n",
    "def least_squares_fit(x, y):\n",
    "    mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x_valid = x[mask]\n",
    "    y_valid = y[mask]\n",
    "    A = np.vstack([x_valid, np.ones_like(x_valid)]).T\n",
    "    m, c = np.linalg.lstsq(A, y_valid, rcond=None)[0]\n",
    "    return m, c\n",
    "\n",
    "# Open datasets and perform least squares fitting\n",
    "with rasterio.open(Active_Multiband) as Active_img, rasterio.open(No_Multiband) as No_img:\n",
    "    Active_B11 = Active_img.read(1)\n",
    "    Active_B12 = Active_img.read(2)\n",
    "    No_B11 = No_img.read(1)\n",
    "    No_B12 = No_img.read(2)\n",
    "\n",
    "    m_active, c_active = least_squares_fit(Active_B11.flatten(), Active_B12.flatten())\n",
    "    Corrected_Active_B12 = m_active * Active_B12 + c_active\n",
    "\n",
    "    m_no, c_no = least_squares_fit(No_B11.flatten(), No_B12.flatten())\n",
    "    Corrected_No_B12 = m_no * No_B12 + c_no\n",
    "\n",
    "    SWIR_diff = (Active_B11 - Corrected_Active_B12) - (No_B11 - Corrected_No_B12)\n",
    "    min_value = np.min(SWIR_diff)\n",
    "    if min_value < 0:\n",
    "        SWIR_diff = SWIR_diff - min_value\n",
    "\n",
    "# Reproject and save SWIR_diff to EPSG:4326\n",
    "with rasterio.open(Active_Multiband) as src:\n",
    "    target_crs = \"EPSG:4326\"\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, target_crs, src.width, src.height, *src.bounds\n",
    "    )\n",
    "    meta = src.meta.copy()\n",
    "    meta.update({\n",
    "        \"crs\": target_crs,\n",
    "        \"transform\": transform,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"count\": 1,\n",
    "        \"dtype\": SWIR_diff.dtype\n",
    "    })\n",
    "    with rasterio.open(output_file, \"w\", **meta) as dest:\n",
    "        reproject(\n",
    "            source=SWIR_diff,\n",
    "            destination=rasterio.band(dest, 1),\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=transform,\n",
    "            dst_crs=target_crs,\n",
    "            resampling=Resampling.nearest\n",
    "        )\n",
    "\n",
    "# Calculate center for map\n",
    "center_lat = (bounds[0][0] + bounds[1][0]) / 2\n",
    "center_lon = (bounds[0][1] + bounds[1][1]) / 2\n",
    "\n",
    "# Create Folium map\n",
    "m = Map(location=[center_lat, center_lon], zoom_start=10, control_scale=True)\n",
    "\n",
    "# Load and stretch SWIR_diff for visualization\n",
    "with rasterio.open(output_file) as src:\n",
    "    swir_bounds = [[src.bounds.bottom, src.bounds.left], [src.bounds.top, src.bounds.right]]\n",
    "    swir_data = src.read(1)\n",
    "    nodata_value = src.nodata if src.nodata is not None else -9999\n",
    "    swir_data = np.ma.masked_equal(swir_data, nodata_value)\n",
    "\n",
    "    # Apply stretching logic\n",
    "    mean = np.nanmean(swir_data)\n",
    "    std = np.nanstd(swir_data)\n",
    "    std_factor = 2  # Stretch factor\n",
    "    lower_bound = mean - std_factor * std\n",
    "    upper_bound = mean + std_factor * std\n",
    "    normalized_swir_data = (swir_data - lower_bound) / (upper_bound - lower_bound)\n",
    "    normalized_swir_data = np.clip(normalized_swir_data, 0, 1)\n",
    "\n",
    "    # Apply colormap\n",
    "    cmap = plt.get_cmap('plasma')\n",
    "    rgb_data = (cmap(normalized_swir_data)[:, :, :3] * 255).astype(np.uint8)\n",
    "\n",
    "# Load the true color image\n",
    "truecolour_sat = 'Sentinel-2_truecolour_reprojected.Tiff'\n",
    "img = rasterio.open(truecolour_sat)\n",
    "blue, green, red = img.read(1), img.read(2), img.read(3)\n",
    "\n",
    "# Adjust brightness dynamically\n",
    "brightness_factor = 0.03\n",
    "blue = np.clip(blue * brightness_factor, 0, 255)\n",
    "green = np.clip(green * brightness_factor, 0, 255)\n",
    "red = np.clip(red * brightness_factor, 0, 255)\n",
    "\n",
    "# Stack bands to create RGB image\n",
    "rgb = np.dstack((red, green, blue))\n",
    "rgb = rgb / rgb.max()\n",
    "rgb = np.log1p(rgb)\n",
    "rgb = rgb / rgb.max()\n",
    "\n",
    "# Add true color image overlay\n",
    "truecolour_overlay = ImageOverlay(\n",
    "    image=rgb,\n",
    "    bounds=swir_bounds,\n",
    "    opacity=1,  # Lower opacity for blending with SWIR overlay\n",
    "    interactive=True,\n",
    "    cross_origin=False,\n",
    "    zindex=1,  # Lower zindex to place below SWIR overlay\n",
    ")\n",
    "truecolour_overlay.add_to(m)\n",
    "\n",
    "# Add SWIR_diff overlay to map\n",
    "swir_overlay = ImageOverlay(\n",
    "    image=rgb_data,\n",
    "    bounds=swir_bounds,\n",
    "    opacity=1,  # Adjust opacity for visibility\n",
    "    interactive=True,\n",
    "    zindex=2  # Ensure SWIR overlay is above other layers\n",
    ")\n",
    "swir_overlay.add_to(m)\n",
    "\n",
    "# Add GeoJSON data as a layer group\n",
    "vector_point_path = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\known_point_sources.geojson\"\n",
    "gdf = gpd.read_file(vector_point_path)\n",
    "geojson_layer = FeatureGroup(name=\"Known Point Sources\", show=False)\n",
    "GeoJson(gdf.to_json()).add_to(geojson_layer)\n",
    "geojson_layer.add_to(m)\n",
    "\n",
    "# Layer control\n",
    "LayerControl().add_to(m)\n",
    "m.add_child(LatLngPopup())\n",
    "\n",
    "# Display map\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8623c7-0247-4561-b42d-3e5922b60225",
   "metadata": {},
   "source": [
    "## Plume tagging\n",
    "\n",
    "Over an area the size of an oil and gas field, many objects can erroneously show up as methane like signals if a method like thresholding was used. These include urban areas, agriculrutal irrigation projects and new constructions. To deal with this problem we will select the plumes in the image using a manual tagging system. \n",
    "\n",
    "To do this, click on a plume somewhere along its legnth, and then copy the given latitude and longitude coordinates. \n",
    "\n",
    "Maually input plume source coordinates below in the format (latitude, longitude), for example:  \n",
    "<p style=\"text-align: center;\">(31.6887, 5.8102),  # Plume 1 (latitude, longitude)</p> <p style=\"text-align: center;\">(31.7910, 5.8263),  # Plume 2 (latitude, longitude)</p> \n",
    "\n",
    "Additional lines for more plumes can be added as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6528c93-29a2-4f84-8943-d5008410194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_coords = [\n",
    "    (31.7693, 6.0030),  # Plume 1 (latitude, longitude)\n",
    "    (31.7791, 5.9952),  # Plume 2 (latitude, longitude)\n",
    "    (31.7983, 6.0107),  # Plume 3 (latitude, longitude)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1567e74-955f-4dbb-b8ac-7b9c1b68671e",
   "metadata": {},
   "source": [
    "## Regression Model Development\n",
    "\n",
    "A regression model is a statistical tool used to predict a dependent variable (here, methane emission rate in kg/h) based on independent variables. It works by identifying relationships in the training data and using these to estimate outcomes for new data.\n",
    "\n",
    "To train the model, data from methane plumes with emission rates documented in peer-reviewed studies was collected (Gorroño et al., 2023; Pandey et al., 2023; Varon et al., 2021; Wang et al., 2023; Sanchez-Garcia et al., 2021). These plumes were then found using the MBMP Plume Visualiser. Each plume was measured for:\n",
    "\n",
    "- **Adjusted CS Sum**: The plume intensity in its cross-section after subtracting background values.\n",
    "- **Plume Width**: The plume's width in pixels, measured perpendicular to its direction of travel.\n",
    "- **Wind Speed**: ERA5 reanalysis data for the wind speed at the time of observation.\n",
    "\n",
    "The regression analysis identifies how these factors relate to emission rates, allowing the model to predict methane emissions for other plumes based on their characteristics.\n",
    "\n",
    "Below are the data that was collected for the regression analysis. Here more data can be added to improve the model, should more studies become available. The data used for the model as of publication, is listed below.\n",
    "\n",
    "| Plume | Longitude  | Latitude   | Date       | Emission Rate (Q) (kg/h) | Variance (kg/h) | CS Sum (digital numbers) | Width (px) | Wind Speed (m/s) | Source                                |\n",
    "|:-----:|:----------:|:----------:|:----------:|:------------------------:|:---------------:|:------------------------:|:----------:|:----------------:|:-------------------------------------:|\n",
    "|   1   |  6.154881  |  31.805489 | 31/08/2021 |          5453           |      ± 2200      |       1157.180431        |     13     |       4.37       |         Gorroño et al., 2023         |\n",
    "|   2   |   5.9968   |   31.7775  | 04/01/2020 |         21000           |      ± 6000      |       5595.239521        |     74     |       3.65       |         Pandey et al., 2023          |\n",
    "|   3   |   5.9053   |   31.6585  | 20/11/2019 |          8500           |      ± 5700      |       4520.473715        |     42     |       0.51       | Varon et al., 2021, Pandey et al., 2023 |\n",
    "|   4   |      6      |    31.78   | 19/08/2021 |          4326           |      ± 2453      |       320.936628         |     13     |       0.92       | Wang et al., 2023, Sanchez-Garcia et al., 2021 |\n",
    "|   5   |   5.9951   |   31.7789  | 19/08/2021 |          2160           |      ±1108       |       343.933175         |      8     |       0.92       | Wang et al., 2023, Sanchez-Garcia et al., 2021 |\n",
    "|   6   |   6.0107   |    31.798  | 19/08/2021 |          2757           |      ±1297       |       366.843504         |      7     |       0.92       | Wang et al., 2023, Sanchez-Garcia et al., 2021 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eff60e-16cc-4173-817f-8e9d758da69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial dataset for regression model (Add new plumes directly here as needed)\n",
    "initial_data = {\n",
    "    \"Cross_sectional_Adjusted_Sum\": [245.985248, 5626.58803, 4471.054728, 319.004091, 342.789593, 365.813576],\n",
    "    \"Wind_speed\": [4.37, 3.65, 0.51, 0.92, 0.92, 0.92],\n",
    "    \"Emission_rate_kg_h\": [5453, 21000, 8500, 4326, 2160, 2757],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf9ea84-33c0-40b7-a932-2709086f888a",
   "metadata": {},
   "source": [
    "## Detemining wind speed\n",
    "\n",
    "Wind speed is a crucial factor in determining emission rate. This next code box determines the wind speed on the \"Active Emission\" date as part of the gas flux calculation. Several warning messages will appear but these can be ignored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0feeddb-5d92-4834-b681-d64679f6a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract bounding box and calculate center from site_id\n",
    "def get_location_from_site_id(site_id, csv_path):\n",
    "    \"\"\"\n",
    "    Extract center latitude and longitude for a site based on site_id.\n",
    "\n",
    "    Args:\n",
    "    - site_id (int): The ID of the site to extract.\n",
    "    - csv_path (str): Path to the CSV containing site boundaries.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary with latitude and longitude of the center.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    site = df[df['id'] == site_id]\n",
    "    if site.empty:\n",
    "        raise ValueError(f\"Site ID {site_id} not found in the CSV file.\")\n",
    "    site = site.iloc[0]\n",
    "    center_lat = (site['south'] + site['north']) / 2\n",
    "    center_lon = (site['west'] + site['east']) / 2\n",
    "    return {'latitude': center_lat, 'longitude': center_lon}\n",
    "\n",
    "# Get the location for the ERA5 data request\n",
    "location = get_location_from_site_id(site_id, csv_path)\n",
    "\n",
    "# Initialize the CDS API client\n",
    "c = cdsapi.Client()\n",
    "\n",
    "# Define parameters for the data request\n",
    "# Extract the start date from active_temporal_extent and assign it to date\n",
    "date = active_temporal_extent[0]  # Use the first element as the single date\n",
    "\n",
    "# Now the variable 'date' can be used with the other API\n",
    "\n",
    "# date = active_temporal_extent (update this somehow so that no input is needed in this box)\n",
    "\n",
    "# Retrieve ERA5 data and store it in a temporary file\n",
    "with NamedTemporaryFile(suffix='.nc') as tmp_file:\n",
    "    result = c.retrieve(\n",
    "        'reanalysis-era5-single-levels',\n",
    "        {\n",
    "            'product_type': 'reanalysis',\n",
    "            'variable': ['10m_u_component_of_wind', '10m_v_component_of_wind'],\n",
    "            'year': date.split('-')[0],\n",
    "            'month': date.split('-')[1],\n",
    "            'day': date.split('-')[2],\n",
    "            'time': ['10:00'],  # Specify time of interest\n",
    "            'format': 'netcdf',  # NetCDF format\n",
    "            'area': [\n",
    "                location['latitude'] + 0.25, location['longitude'] - 0.25,\n",
    "                location['latitude'] - 0.25, location['longitude'] + 0.25,\n",
    "            ],  # Small bounding box around the location\n",
    "        }\n",
    "    )\n",
    "    # Download data to the temporary file\n",
    "    result.download(tmp_file.name)\n",
    "    \n",
    "    # Load the dataset with xarray\n",
    "    ds = xr.open_dataset(tmp_file.name)\n",
    "\n",
    "# Extract u and v components\n",
    "u10 = ds['u10'].sel(latitude=location['latitude'], longitude=location['longitude'], method='nearest')\n",
    "v10 = ds['v10'].sel(latitude=location['latitude'], longitude=location['longitude'], method='nearest')\n",
    "\n",
    "# Calculate wind speed\n",
    "wind_speed = np.sqrt(u10**2 + v10**2)\n",
    "\n",
    "# Handle single timestep case\n",
    "if 'time' in u10.dims:\n",
    "    # Multiple timesteps (not likely in this case since we specified 10:00 only)\n",
    "    for time, speed in zip(u10.time.values, wind_speed.values):\n",
    "        print(f\"{time}: Wind Speed = {speed:.2f} m/s\")\n",
    "else:\n",
    "    # Single timestep\n",
    "    wind_speed_value = wind_speed.values.item()  # Convert array to scalar\n",
    "    print(f\"Wind Speed at 10:00 on {date}: {wind_speed_value:.2f} m/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3930168-7e93-4e4c-9f83-011f6f6ea8c7",
   "metadata": {},
   "source": [
    "## Running the tagged plume analysis\n",
    "\n",
    "This section loads the SWIR data and loads the colourmap in preparation for the analysis. It also provides the average/mean value of the dataset, allowing us to see how much a plume rises above background levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ddc9d-9dfa-4b93-a935-df53d8ceb5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "swir_diff_path = r'C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\SWIR_diff_4326.tiff'\n",
    "\n",
    "\n",
    "with rasterio.open(swir_diff_path) as tiff_file:\n",
    "    raster_data = tiff_file.read(1)  # Read the first band\n",
    "    nodata_value = tiff_file.nodata if tiff_file.nodata is not None else -9999\n",
    "    bounds = tiff_file.bounds\n",
    "    transform = tiff_file.transform\n",
    "\n",
    "# Mask nodata values\n",
    "masked_data = np.ma.masked_equal(raster_data, nodata_value)\n",
    "\n",
    "# Calculate statistical values\n",
    "mean, std = np.nanmean(masked_data), np.nanstd(masked_data)\n",
    "std_factor = 2\n",
    "lower_bound, upper_bound = mean - std_factor * std, mean + std_factor * std\n",
    "normalized_data = (masked_data - lower_bound) / (upper_bound - lower_bound)\n",
    "normalized_data = np.clip(normalized_data, 0, 1)  # Clip to [0, 1]\n",
    "\n",
    "# Calculate the median value of the dataset\n",
    "dataset_median_value = np.ma.median(masked_data)\n",
    "print(f\"Median value of the dataset: {dataset_median_value}\")\n",
    "\n",
    "# Apply colormap\n",
    "cmap = plt.get_cmap('plasma')\n",
    "rgb_data = (cmap(normalized_data)[:, :, :3] * 255).astype(np.uint8)\n",
    "\n",
    "# Initialize the map\n",
    "center_lat = (bounds.top + bounds.bottom) / 2\n",
    "center_lon = (bounds.left + bounds.right) / 2\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=11, control_scale=True)\n",
    "\n",
    "# Define helper functions\n",
    "def get_raster_center(tiff_path):\n",
    "    with rasterio.open(tiff_path) as tiff_file:\n",
    "        bounds = tiff_file.bounds\n",
    "        center_lat = (bounds.top + bounds.bottom) / 2\n",
    "        center_lon = (bounds.left + bounds.right) / 2\n",
    "    return center_lat, center_lon\n",
    "\n",
    "def calculate_plume_width_pixels(plume_pixels, perp_direction):\n",
    "    perp_vector = np.array(perp_direction)\n",
    "    perp_vector = perp_vector / np.linalg.norm(perp_vector)\n",
    "    projections = plume_pixels @ perp_vector\n",
    "    return projections.ptp()  # Peak-to-peak width in the projection space\n",
    "\n",
    "def bresenham_line(x0, y0, x1, y1):\n",
    "    points = []\n",
    "    dx = abs(x1 - x0)\n",
    "    dy = abs(y1 - y0)\n",
    "    sx = 1 if x0 < x1 else -1\n",
    "    sy = 1 if y0 < y1 else -1\n",
    "    err = dx - dy\n",
    "\n",
    "    while True:\n",
    "        points.append((x0, y0))\n",
    "        if x0 == x1 and y0 == y1:\n",
    "            break\n",
    "        e2 = err * 2\n",
    "        if e2 > -dy:\n",
    "            err -= dy\n",
    "            x0 += sx\n",
    "        if e2 < dx:\n",
    "            err += dx\n",
    "            y0 += sy\n",
    "    return points\n",
    "\n",
    "def get_line_pixel_values(start, end, masked_data):\n",
    "    line_pixels = bresenham_line(int(start[0]), int(start[1]), int(end[0]), int(end[1]))\n",
    "    pixel_values = [masked_data[row, col] for row, col in line_pixels if 0 <= row < masked_data.shape[0] and 0 <= col < masked_data.shape[1]]\n",
    "    return pixel_values\n",
    "\n",
    "def count_line_pixels(start, end):\n",
    "    line_pixels = bresenham_line(int(start[0]), int(start[1]), int(end[0]), int(end[1]))\n",
    "    return len(line_pixels)\n",
    "\n",
    "def analyze_plume_with_cross_section_sum(masked_data, plume_coords, transform, initial_center):\n",
    "    plume_map = folium.Map(location=initial_center, zoom_start=11, control_scale=True)\n",
    "    plume_results = []\n",
    "    labeled_array, _ = label(masked_data > np.percentile(masked_data.compressed(), 80))\n",
    "\n",
    "    for i, (lat, lon) in enumerate(plume_coords):\n",
    "        try:\n",
    "            row, col = rasterio.transform.rowcol(transform, lon, lat)\n",
    "            row, col = int(row), int(col)\n",
    "            plume_label = labeled_array[row, col]\n",
    "            if plume_label == 0:\n",
    "                plume_results.append({\"Plume\": i + 1, \"Location (lat, lon)\": (lat, lon), \"Status\": \"No plume detected\"})\n",
    "                continue\n",
    "\n",
    "            plume_region = labeled_array == plume_label\n",
    "            plume_pixels = np.column_stack(np.where(plume_region))\n",
    "            pca = PCA(n_components=2)\n",
    "            pca.fit(plume_pixels)\n",
    "            perp_direction = [-pca.components_[0, 1], pca.components_[0, 0]]\n",
    "\n",
    "            plume_width_pixels = calculate_plume_width_pixels(plume_pixels, perp_direction)\n",
    "\n",
    "            centroid = plume_pixels.mean(axis=0)\n",
    "            perp_line_coords = [\n",
    "                (centroid[0] - perp_direction[0] * plume_width_pixels / 2, centroid[1] - perp_direction[1] * plume_width_pixels / 2),\n",
    "                (centroid[0] + perp_direction[0] * plume_width_pixels / 2, centroid[1] + perp_direction[1] * plume_width_pixels / 2),\n",
    "            ]\n",
    "\n",
    "            line_pixel_values = get_line_pixel_values(perp_line_coords[0], perp_line_coords[1], masked_data)\n",
    "            num_intersecting_pixels = count_line_pixels(perp_line_coords[0], perp_line_coords[1])\n",
    "\n",
    "            pixel_value_sum = sum(line_pixel_values)\n",
    "            adjusted_sum = pixel_value_sum - (dataset_median_value * num_intersecting_pixels)\n",
    "\n",
    "            perp_line_latlon = [\n",
    "                rasterio.transform.xy(transform, int(pt[0]), int(pt[1])) for pt in perp_line_coords\n",
    "            ]\n",
    "            folium.PolyLine(\n",
    "                locations=[(lat, lon) for lon, lat in perp_line_latlon],\n",
    "                color=\"red\",\n",
    "                weight=2,\n",
    "                opacity=1,\n",
    "                tooltip=f\"Plume {i + 1} Width Measurement\",\n",
    "            ).add_to(plume_map)\n",
    "\n",
    "            hull = ConvexHull(plume_pixels)\n",
    "            hull_coords = [(plume_pixels[vertex][0], plume_pixels[vertex][1]) for vertex in hull.vertices]\n",
    "            hull_latlon = [rasterio.transform.xy(transform, int(pt[0]), int(pt[1])) for pt in hull_coords]\n",
    "            folium.Polygon(\n",
    "                locations=[(lat, lon) for lon, lat in hull_latlon],\n",
    "                color=\"green\",\n",
    "                weight=3,\n",
    "                fill=False,\n",
    "                opacity=1,\n",
    "                popup=f\"Plume {i + 1} region\",\n",
    "            ).add_to(plume_map)\n",
    "\n",
    "            plume_results.append({\n",
    "                \"Plume\": i + 1,\n",
    "                \"Location (lat, lon)\": (lat, lon),\n",
    "                \"Intersecting Pixels\": num_intersecting_pixels,\n",
    "                \"Pixel Value Sum\": pixel_value_sum,\n",
    "                \"Adjusted Sum\": adjusted_sum\n",
    "            })\n",
    "        except Exception as e:\n",
    "            plume_results.append({\"Plume\": i + 1, \"Location (lat, lon)\": (lat, lon), \"Status\": f\"Error: {e}\"})\n",
    "    return plume_results, plume_map\n",
    "\n",
    "def add_swir_data_to_map(map_object, tiff_path):\n",
    "    with rasterio.open(tiff_path) as tiff_file:\n",
    "        swir_data = tiff_file.read(1)\n",
    "        bounds = tiff_file.bounds\n",
    "        nodata_value = tiff_file.nodata if tiff_file.nodata is not None else -9999\n",
    "    masked_data = np.ma.masked_equal(swir_data, nodata_value)\n",
    "    mean, std = np.nanmean(masked_data), np.nanstd(masked_data)\n",
    "    lower_bound, upper_bound = mean - 2 * std, mean + 2 * std\n",
    "    normalized_data = (masked_data - lower_bound) / (upper_bound - lower_bound)\n",
    "    normalized_data = np.clip(normalized_data, 0, 1)\n",
    "    cmap = plt.get_cmap(\"plasma\")\n",
    "    swir_rgb = (cmap(normalized_data)[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_bounds = [[bounds.bottom, bounds.left], [bounds.top, bounds.right]]\n",
    "    ImageOverlay(image=swir_rgb, bounds=image_bounds, opacity=1).add_to(map_object)\n",
    "\n",
    "# Convert the dataset into a DataFrame\n",
    "model_df = pd.DataFrame(initial_data)\n",
    "\n",
    "# Function to fit and update the regression model using Model 2\n",
    "def update_model(df):\n",
    "    \"\"\"\n",
    "    Update the regression model based on the current dataset.\n",
    "\n",
    "    Args:\n",
    "    - df: DataFrame containing the plume data.\n",
    "\n",
    "    Returns:\n",
    "    - Updated regression model parameters as a dictionary.\n",
    "    \"\"\"\n",
    "    # Prepare features (X) and target (y)\n",
    "    X = df[[\"Cross_sectional_Adjusted_Sum\", \"Wind_speed\"]]\n",
    "    y = df[\"Emission_rate_kg_h\"]\n",
    "\n",
    "    # Fit Model 2 (simple linear regression)\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X, y)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = reg.predict(X)\n",
    "    print(\"Model Evaluation:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mean_squared_error(y, y_pred):.2f}\")\n",
    "    print(f\"R-squared (R²): {r2_score(y, y_pred):.2f}\")\n",
    "\n",
    "    # Plot actual vs predicted emission rates\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y, y_pred, color=\"blue\", label=\"Predicted vs Actual\")\n",
    "    plt.plot([min(y), max(y)], [min(y), max(y)], color=\"red\", label=\"Ideal Fit Line\")\n",
    "    plt.xlabel(\"Actual Emission Rate (kg/h)\")\n",
    "    plt.ylabel(\"Predicted Emission Rate (kg/h)\")\n",
    "    plt.title(\"Regression Analysis: Actual vs Predicted\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Return updated model parameters\n",
    "    return {\n",
    "        \"intercept\": reg.intercept_,\n",
    "        \"CS_Sum_coef\": reg.coef_[0],\n",
    "        \"Wind_speed_coef\": reg.coef_[1],\n",
    "    }\n",
    "\n",
    "# Update the model with the initial data\n",
    "model_params = update_model(model_df)\n",
    "\n",
    "# Get the center of the SWIR TIFF\n",
    "center_coords = get_raster_center(swir_diff_path)\n",
    "\n",
    "# Perform plume analysis, centering the map on the SWIR TIFF\n",
    "plume_analysis_results, plume_map = analyze_plume_with_cross_section_sum(masked_data, plume_coords, transform, center_coords)\n",
    "\n",
    "# Add wind speed to each plume analysis result\n",
    "wind_speed_value = 2.0  # Example wind speed value\n",
    "for plume in plume_analysis_results:\n",
    "    if \"Adjusted Sum\" in plume:\n",
    "        adjusted_sum = plume[\"Adjusted Sum\"]\n",
    "        width_px = plume[\"Intersecting Pixels\"]\n",
    "        emission_rate = (\n",
    "            model_params[\"intercept\"]\n",
    "            + model_params[\"CS_Sum_coef\"] * adjusted_sum\n",
    "            + model_params[\"Wind_speed_coef\"] * wind_speed_value\n",
    "        )\n",
    "        plume[\"Predicted Emission Rate (kg/h)\"] = emission_rate\n",
    "\n",
    "# Convert updated results to a DataFrame\n",
    "plume_df = pd.DataFrame(plume_analysis_results)\n",
    "plume_df.set_index(\"Plume\", inplace=True)\n",
    "\n",
    "# Display updated DataFrame with predicted emission rates\n",
    "print(\"Plume Analysis Results with Predicted Emission Rates:\")\n",
    "print(plume_df)\n",
    "\n",
    "# Add SWIR overlay to the map\n",
    "add_swir_data_to_map(plume_map, swir_diff_path)\n",
    "\n",
    "# Add true color image overlay\n",
    "truecolor_overlay = ImageOverlay(\n",
    "    image=rgb_data,\n",
    "    bounds=[[bounds.bottom, bounds.left], [bounds.top, bounds.right]],\n",
    "    opacity=1,\n",
    "    interactive=True,\n",
    "    cross_origin=False,\n",
    "    zindex=1,\n",
    ")\n",
    "truecolor_overlay.add_to(plume_map)\n",
    "\n",
    "# Add a layer control to toggle map layers\n",
    "LayerControl().add_to(plume_map)\n",
    "\n",
    "# Display the map with updated analysis\n",
    "ipy_display(plume_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd935c-c4f0-469b-bcee-8fa746e9350a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
