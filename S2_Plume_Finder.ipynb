{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f561c3-51d4-4476-922d-876088df12c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentinel 2 CH4 Multi Band Multi Pass Mapper\n",
    "\n",
    "## Overview \n",
    "Varon et al. (2021) showed that methane plumes from point sources could be imaged by differencing Sentinel-2’s SWIR-1 and SWIR-2 bands. The tool runs an analysis using a  multi-band-multi-pass retrieval method: \n",
    "\n",
    "First it calculates a multi-band-single-pass calculation for both active emission and no emission dates, resulting in two datasets which are then used together for a multi-band-multi-pass method. \n",
    "The multi-band-single-pass equation is as follows: \n",
    "\n",
    "\n",
    "<div align=\"center\"><b>MBSP = B11 - cB12</b></div>\n",
    "\n",
    "Where:\n",
    "- B12 is the Sentinel-2 SWIR-2 band.\n",
    "- B11 is the Sentinel-2 SWIR-1 band. \n",
    "- c is calculated by least-squares fitting B12 to B11 across the scene.  \n",
    "\n",
    "Once active emission and no emission scenes have been calculated, the following equation is used to calculate the multi-band-multi-pass raster. \n",
    "\n",
    "<div align=\"center\"><b>MBMP = ActiveMBSP − NoMBSP</b></div>\n",
    "\n",
    "Where:\n",
    "- ActiveMBSP is the multiband single pass for the active emission scene\n",
    "- NoMBSP is the multiband single pass for the no emission scene.  \n",
    "\n",
    "The active emission scene and no emission scene are considered in this analysis to be one satelite pass apart.\n",
    "\n",
    "The section below imports the packages needed to run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9cfbc-e95b-4685-a7e2-19f2ccc7cf3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import folium\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import openeo\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.plot import show\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import numpy as np\n",
    "import requests\n",
    "from folium import Map, LayerControl, LatLngPopup, GeoJson\n",
    "from folium.raster_layers import ImageOverlay\n",
    "from IPython.display import display as ipy_display\n",
    "from skimage import exposure\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.ndimage import label\n",
    "from scipy.spatial import ConvexHull\n",
    "from shapely.geometry import Point, LineString\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67714102-a656-4414-9e45-42c8c80460ea",
   "metadata": {},
   "source": [
    "## Connect to OpenEO\n",
    "\n",
    "The code below establishes a connection with the Copernicus openEO platform which provides a wide variety of earth observation datasets\n",
    "\n",
    "- If this does not read as 'Authorised successfully' or 'Authenticated using refresh token', then please ensure that you have completed the setup steps as outlined in section 2.6 of the user guide. \n",
    "\n",
    "- If you have followed the steps in section 2.6 correctly and the problem persists, please look at https://dataspace.copernicus.eu/news for any information about service interruptions. \n",
    "\n",
    "- If there is no news of service problems you can raise a ticket here: https://helpcenter.dataspace.copernicus.eu/hc/en-gb/requests/new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfface4-832c-4c3b-b79c-a6886878cd83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "connection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\n",
    "connection.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d0674c-3b9c-4ab0-aafe-0526baa82e66",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Study Area. \n",
    "\n",
    "This loads the boudings for the oil and gas fields in Algeria. Hassi Messaoud is site 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110af1e-a1d9-4fb8-8663-51d279eac192",
   "metadata": {},
   "outputs": [],
   "source": [
    "studysite_csv = pandas.read_csv(r'C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\Algerian_Oil_and_Gas_Fields.csv')\n",
    "pandas.set_option('display.max_rows', None)\n",
    "print(studysite_csv.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0fbd3c-c769-490c-b130-5784a8138114",
   "metadata": {},
   "source": [
    "# Available dates for the analysis. \n",
    "\n",
    "Sentinel 2 provides data aproximately once every 3 days, so not every date you can enter into this tool is valid. The code below will tell you what dates are available to use for the oil/gas field of your choice. \n",
    "\n",
    "The two parameters you need to modify before running the code are: \n",
    "- site_id = 86 (change this to your chosen study site) \n",
    "- temporal_extent = [\"2023-01-31\", \"2023-03-12\"] (change this to your chosen date range using \"YYYY-MM-DD\" format)\n",
    "\n",
    "Once you have done this run the code and the available dates should appear below in a matter of seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb8600-dfdd-491b-bde9-2eaa760af099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spatial_extent(site_id):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "    return {\n",
    "        \"west\": site['west'],\n",
    "        \"south\": site['south'],\n",
    "        \"east\": site['east'],\n",
    "        \"north\": site['north']\n",
    "    }\n",
    "\n",
    "def fetch_available_dates(site_id, temporal_extent):\n",
    "    spatial_extent = get_spatial_extent(site_id)\n",
    "    catalog_url = f\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?box={spatial_extent['west']}%2C{spatial_extent['south']}%2C{spatial_extent['east']}%2C{spatial_extent['north']}&sortParam=startDate&sortOrder=ascending&page=1&maxRecords=1000&status=ONLINE&dataset=ESA-DATASET&productType=L2A&startDate={temporal_extent[0]}T00%3A00%3A00Z&completionDate={temporal_extent[1]}T00%3A00%3A00Z&cloudCover=%5B0%2C{cloud_cover}%5D\"\n",
    "    response = requests.get(catalog_url)\n",
    "    response.raise_for_status()\n",
    "    catalog = response.json()\n",
    "    dates = [date.split('T')[0] for date in map(lambda x: x['properties']['startDate'], catalog['features'])]\n",
    "    return dates\n",
    "\n",
    "# Please enter your perameters here.\n",
    "site_id = 86 # Specify the oil and gas field ID\n",
    "temporal_extent = [\"2021-01-01\", \"2021-01-31\"]  # Specify the the date range you want to check for available data.\n",
    "cloud_cover = 5\n",
    "\n",
    "available_dates = fetch_available_dates(site_id, temporal_extent)\n",
    "print(\"Available dates:\", available_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c953b692-eb71-4c15-b3d3-95025f77bcc4",
   "metadata": {},
   "source": [
    "## Choosing the Active Emission Date\n",
    "\n",
    "As mentioned in the overview, an active emission date must be chosen from one of the available datasets. \n",
    "\n",
    "Like before, the two parameters you need to modify before running the code are:\n",
    "\n",
    "- site_id = 86 (change this to your chosen study site)\n",
    "- temporal_extent = [\"2023-02-25\", \"2023-02-25\"] (change this to your chosen date range using \"YYYY-MM-DD\" format.) \n",
    "\n",
    "Please note that the temporal extent dates <u>MUST BE IDENTICAL</u> because we are only choosing a single date.\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a709165f-4542-46da-af8e-a7199df573c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_emission(site_id, temporal_extent):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    active_emission = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B11\", \"B12\"],\n",
    "    )\n",
    "    active_emission.download(\"Sentinel-2_active_emissionMBMP.Tiff\")\n",
    "\n",
    "# Enter perameters for the active emission day\n",
    "site_id = 86  # Specify the oil and gas field ID\n",
    "temporal_extent = [\"2021-01-11\", \"2021-01-11\"]\n",
    "\n",
    "active_emission(site_id, temporal_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc9eea-43af-400e-822f-725ce1afb0b2",
   "metadata": {},
   "source": [
    "## Choosing the No Emission Date\n",
    "\n",
    "Next we choose the no emission date using the same process. \n",
    "\n",
    "The two parameters you need to modify before running the code are:\n",
    "\n",
    "- site_id = 86 (change this to your chosen site)\n",
    "- temporal_extent = [\"2023-02-25\", \"2023-02-25\"] (change this to your chosen date range using \"YYYY-MM-DD\" format.) \n",
    "\n",
    "The temporal extent dates <u>MUST BE IDENTICAL</u>\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74d95f-bc49-4233-b767-6a1daaaf68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_emission(site_id, temporal_extent):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    no_emission = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B11\", \"B12\"],\n",
    "    )\n",
    "    no_emission.download(\"Sentinel-2_no_emissionMBMP.Tiff\")\n",
    "\n",
    "# Enter perameters for the active emission day\n",
    "site_id = 86  # Specify the oil and gas field ID\n",
    "temporal_extent = [\"2021-01-08\", \"2021-01-08\"]\n",
    "\n",
    "no_emission(site_id, temporal_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de701594-5589-41ad-8750-5a57f70cc130",
   "metadata": {},
   "source": [
    "## Choosing a Background Satelite Image\n",
    "\n",
    "This section helps with locating the source of the emission at the landfill by displaying a true colour satelite image of the landfill that the data will be superimposed over. I recommend choosing the same date as your active emission. \n",
    "\n",
    "Once again, the two parameters you need to modify before running the code are:\n",
    "\n",
    "- site_id = 86 (change this to your chosen site)\n",
    "- temporal_extent = [\"2023-02-25\", \"2023-02-25\"] (change this to your chosen date range using \"YYYY-MM-DD\" format.)\n",
    "\n",
    "The temporal extent dates <u>MUST BE IDENTICAL</u>\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9db215-2b88-4bf4-b65c-06dc75e94a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truecolour_image(site_id, temporal_extent):\n",
    "    site = studysite_csv[studysite_csv['id'] == site_id].iloc[0]\n",
    "\n",
    "    truecolour_image = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=temporal_extent,\n",
    "        spatial_extent={\n",
    "            \"west\": site['west'],\n",
    "            \"south\": site['south'],\n",
    "            \"east\": site['east'],\n",
    "            \"north\": site['north']\n",
    "        },\n",
    "        bands=[\"B02\", \"B03\", \"B04\"],\n",
    "    )\n",
    "    truecolour_image.download(\"Sentinel-2_truecolourMBMP.Tiff\")\n",
    "\n",
    "# Enter parameters for the no emission day\n",
    "site_id = 86  # Specify the oil and gas field ID\n",
    "temporal_extent = [\"2021-01-11\", \"2021-01-11\"]\n",
    "\n",
    "truecolour_image(site_id, temporal_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fde51c-73cf-4816-b880-bf4715dc35aa",
   "metadata": {},
   "source": [
    "## Running Plume Visualiser Analysis\n",
    "The code below will use the satelite data to display any plumes above 1,400kgh-1. Provided all the variables above have been run correctly, this next section should take moments to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a8d32-f346-44a6-bf1b-4c4acbb955dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "Active_Multiband = \"Sentinel-2_active_emissionMBMP.Tiff\"\n",
    "No_Multiband = \"Sentinel-2_no_emissionMBMP.Tiff\"\n",
    "output_file = \"SWIR_diff_4326.tiff\"\n",
    "\n",
    "# Define a function for least squares fitting\n",
    "def least_squares_fit(x, y):\n",
    "    # Remove NaNs (if any) for valid calculations\n",
    "    mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x_valid = x[mask]\n",
    "    y_valid = y[mask]\n",
    "    \n",
    "    # Calculate least squares fit parameters\n",
    "    A = np.vstack([x_valid, np.ones_like(x_valid)]).T\n",
    "    m, c = np.linalg.lstsq(A, y_valid, rcond=None)[0]\n",
    "    return m, c\n",
    "\n",
    "# Open datasets and perform least squares fitting\n",
    "with rasterio.open(Active_Multiband) as Active_img, rasterio.open(No_Multiband) as No_img:\n",
    "    Active_B11 = Active_img.read(1)\n",
    "    Active_B12 = Active_img.read(2)\n",
    "    No_B11 = No_img.read(1)\n",
    "    No_B12 = No_img.read(2)\n",
    "    \n",
    "    # Perform least squares fitting for Active_B11 vs Active_B12\n",
    "    m_active, c_active = least_squares_fit(Active_B11.flatten(), Active_B12.flatten())\n",
    "    Corrected_Active_B12 = m_active * Active_B12 + c_active\n",
    "    \n",
    "    # Perform least squares fitting for No_B11 vs No_B12\n",
    "    m_no, c_no = least_squares_fit(No_B11.flatten(), No_B12.flatten())\n",
    "    Corrected_No_B12 = m_no * No_B12 + c_no\n",
    "    \n",
    "    # Calculate the fractional change\n",
    "    SWIR_diff = (Active_B11 - Corrected_Active_B12) - (No_B11 - Corrected_No_B12)\n",
    "\n",
    "# Reproject and save SWIR_diff to EPSG:4326\n",
    "with rasterio.open(Active_Multiband) as src:\n",
    "    target_crs = \"EPSG:4326\"\n",
    "    \n",
    "    # Calculate transform and metadata for the target CRS\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, target_crs, src.width, src.height, *src.bounds\n",
    "    )\n",
    "    \n",
    "    # Prepare metadata for the new file\n",
    "    meta = src.meta.copy()\n",
    "    meta.update({\n",
    "        \"crs\": target_crs,\n",
    "        \"transform\": transform,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"count\": 1,  # Single band for SWIR_diff\n",
    "        \"dtype\": SWIR_diff.dtype\n",
    "    })\n",
    "    \n",
    "    # Save the reprojected SWIR_diff\n",
    "    with rasterio.open(output_file, \"w\", **meta) as dest:\n",
    "        reproject(\n",
    "            source=SWIR_diff,\n",
    "            destination=rasterio.band(dest, 1),\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=transform,\n",
    "            dst_crs=target_crs,\n",
    "            resampling=Resampling.nearest\n",
    "        )\n",
    "\n",
    "print(f\"SWIR_diff saved as {output_file} in CRS EPSG:4326.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e03e9-0ad7-4d49-9077-90f34f14dfcd",
   "metadata": {},
   "source": [
    "## Viewing the data. \n",
    "\n",
    "This section of code can be run to produce the map. Three peramaters can to be adjusted. \n",
    "\n",
    "- site_id = 86 (change this to your chosen site)\n",
    "- brightness_factor = 0.05 (occasionally the true colour satelite image can be too bright or too dark. You can change this number to fix it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bcc3d-b048-4bfb-9baf-4baf87a343fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get bounds from the Oil and Gas Field bounding file\n",
    "def get_bounds(site_id, csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    site = df[df['id'] == site_id]\n",
    "    if site.empty:\n",
    "        raise ValueError(f\"Site ID {site_id} not found in the CSV file.\")\n",
    "    site = site.iloc[0]\n",
    "    return [[site['south'], site['west']], [site['north'], site['east']]]\n",
    "\n",
    "# Specify the site ID and input paths\n",
    "site_id = 86\n",
    "csv_path = r'C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\Algerian_Oil_and_Gas_Fields.csv'\n",
    "bounds = get_bounds(site_id, csv_path)\n",
    "\n",
    "# Calculate the center of the map\n",
    "center_lat = (bounds[0][0] + bounds[1][0]) / 2\n",
    "center_lon = (bounds[0][1] + bounds[1][1]) / 2\n",
    "\n",
    "# Load the true color image\n",
    "truecolour_sat = 'Sentinel-2_truecolourMBMP.Tiff'\n",
    "img = rasterio.open(truecolour_sat)\n",
    "blue, green, red = img.read(1), img.read(2), img.read(3)\n",
    "\n",
    "# Adjust brightness dynamically\n",
    "brightness_factor = 0.03\n",
    "blue = np.clip(blue * brightness_factor, 0, 255)\n",
    "green = np.clip(green * brightness_factor, 0, 255)\n",
    "red = np.clip(red * brightness_factor, 0, 255)\n",
    "\n",
    "# Stack bands to create RGB image\n",
    "rgb = np.dstack((red, green, blue))\n",
    "rgb = rgb / rgb.max()\n",
    "rgb = np.log1p(rgb)\n",
    "rgb = rgb / rgb.max()\n",
    "\n",
    "# Create a Folium map with the dynamic center\n",
    "m = Map(location=[center_lat, center_lon], zoom_start=10, control_scale=True)\n",
    "\n",
    "# Add true color image overlay\n",
    "truecolour_overlay = ImageOverlay(\n",
    "    image=rgb,\n",
    "    bounds=bounds,\n",
    "    opacity=1,\n",
    "    interactive=True,\n",
    "    cross_origin=False,\n",
    "    zindex=1,\n",
    ")\n",
    "truecolour_overlay.add_to(m)\n",
    "\n",
    "# Load and process the SWIR_diff_4326.tiff file\n",
    "SWIR_diff_path = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\SWIR_diff_4326.tiff\"\n",
    "\n",
    "with rasterio.open(SWIR_diff_path) as src:\n",
    "    swir_data = src.read(1)  # Read the first band of the .tiff file\n",
    "    nodata_value = src.nodata if src.nodata is not None else -9999\n",
    "    bounds = [[src.bounds.bottom, src.bounds.left], [src.bounds.top, src.bounds.right]]\n",
    "\n",
    "    # Mask NoData values\n",
    "    swir_data = np.ma.masked_equal(swir_data, nodata_value)\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    mean = np.nanmean(swir_data)\n",
    "    std = np.nanstd(swir_data)\n",
    "\n",
    "    # Perform standard deviation stretch\n",
    "    std_factor = 2  # Stretch factor\n",
    "    lower_bound = mean - std_factor * std\n",
    "    upper_bound = mean + std_factor * std\n",
    "    normalized_swir_data = (swir_data - lower_bound) / (upper_bound - lower_bound)\n",
    "    normalized_swir_data = np.clip(normalized_swir_data, 0, 1)  # Clip values to [0, 1]\n",
    "\n",
    "    # Apply colormap to normalized data\n",
    "    cmap = plt.get_cmap('plasma')\n",
    "    rgb_data = (cmap(normalized_swir_data)[:, :, :3] * 255).astype(np.uint8)\n",
    "\n",
    "# Add SWIR_diff overlay to the map\n",
    "swir_overlay = ImageOverlay(\n",
    "    image=rgb_data,\n",
    "    bounds=bounds,\n",
    "    opacity=0.7,  # Adjust opacity for better layering\n",
    "    interactive=True,\n",
    "    cross_origin=False,\n",
    "    zindex=2,\n",
    ")\n",
    "swir_overlay.add_to(m)\n",
    "\n",
    "# Load GeoJSON file for known point sources\n",
    "vector_point_path = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\Data\\known_point_sources.geojson\"\n",
    "gdf = gpd.read_file(vector_point_path)\n",
    "\n",
    "# Add GeoJSON overlay to the map\n",
    "GeoJson(gdf.to_json()).add_to(m)\n",
    "\n",
    "# Add a layer control to toggle map layers\n",
    "LayerControl().add_to(m)\n",
    "\n",
    "# Add a click event to display latitude and longitude on the map\n",
    "m.add_child(LatLngPopup())\n",
    "\n",
    "# Display the map\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8623c7-0247-4561-b42d-3e5922b60225",
   "metadata": {},
   "source": [
    "## Plume tagging\n",
    "\n",
    "Maually input plume source coordinates here in the format (latitude, longitude), for example:  \n",
    "    (31.6887, 5.8102),  # Plume 1 (latitude, longitude)  \n",
    "    (31.7910, 5.8263),  # Plume 2 (latitude, longitude)  \n",
    "etc...\n",
    "\n",
    "Plumes that are segmented will need to have each of their segmets taged to be included in the analysis. Additional lines for more plumes can be added as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6528c93-29a2-4f84-8943-d5008410194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_coords = [\n",
    "    (31.6887, 5.8102),  # Plume 1 (latitude, longitude)\n",
    "    (31.7910, 5.8263),  # Plume 2 (latitude, longitude)\n",
    "    (31.7978, 5.8341),  # Plume 4 (latitude, longitude)\n",
    "    (31.9101, 6.0135),  # Plume 3 (latitude, longitude)\n",
    "    (31.6389, 6.0025),  # Plume 5 (latitude, longitude)\n",
    "    (31.6754, 6.2429),  # Plume 6 (latitude, longitude)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3930168-7e93-4e4c-9f83-011f6f6ea8c7",
   "metadata": {},
   "source": [
    "## Loading and configuring map.\n",
    "\n",
    "This section loads the SWIR data and loads the colourmap in preparation for the analysis. It also provides the average/mean value of the dataset, allowing us to see how much a plume rises above background levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ddc9d-9dfa-4b93-a935-df53d8ceb5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TIFF file\n",
    "tiff_file_path = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\SWIR_diff_4326.tiff\"\n",
    "with rasterio.open(tiff_file_path) as tiff_file:\n",
    "    raster_data = tiff_file.read(1)  # Read the first band\n",
    "    nodata_value = tiff_file.nodata if tiff_file.nodata is not None else -9999\n",
    "    bounds = tiff_file.bounds\n",
    "    transform = tiff_file.transform\n",
    "\n",
    "# Mask nodata values\n",
    "masked_data = np.ma.masked_equal(raster_data, nodata_value)\n",
    "mean, std = np.nanmean(masked_data), np.nanstd(masked_data)\n",
    "std_factor = 2\n",
    "lower_bound, upper_bound = mean - std_factor * std, mean + std_factor * std\n",
    "normalized_data = (masked_data - lower_bound) / (upper_bound - lower_bound)\n",
    "normalized_data = np.clip(normalized_data, 0, 1)  # Clip to [0, 1]\n",
    "\n",
    "# Apply colormap\n",
    "cmap = plt.get_cmap('plasma')\n",
    "rgb_data = (cmap(normalized_data)[:, :, :3] * 255).astype(np.uint8)\n",
    "\n",
    "# Initialize the map\n",
    "center_lat = (bounds.top + bounds.bottom) / 2\n",
    "center_lon = (bounds.left + bounds.right) / 2\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=11, control_scale=True)\n",
    "\n",
    "# Add SWIR_diff overlay\n",
    "image_bounds = [[bounds.bottom, bounds.left], [bounds.top, bounds.right]]\n",
    "swir_overlay = ImageOverlay(\n",
    "    image=rgb_data,\n",
    "    bounds=image_bounds,\n",
    "    opacity=1,\n",
    "    interactive=True,\n",
    "    cross_origin=False,\n",
    "    zindex=1,\n",
    ")\n",
    "swir_overlay.add_to(m)\n",
    "\n",
    "# Mark plume locations\n",
    "for i, (lat, lon) in enumerate(plume_coords):\n",
    "    folium.CircleMarker(\n",
    "        location=[lat, lon],\n",
    "        radius=5,\n",
    "        color=\"red\",\n",
    "        fill=True,\n",
    "        fill_color=\"red\",\n",
    "        fill_opacity=1,\n",
    "        popup=f\"Plume {i + 1}\",\n",
    "    ).add_to(m)\n",
    "\n",
    "# Calculate the mean value of the masked data\n",
    "dataset_mean_value = masked_data.mean()\n",
    "\n",
    "# Print the mean value\n",
    "print(f\"Mean value of the dataset: {dataset_mean_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c42726-641e-437e-95ff-7619431d88a3",
   "metadata": {},
   "source": [
    "## Viewing the data. \n",
    "\n",
    "Now everything is loaded, we can run the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c506dd-68ac-4de3-8297-f4db7fd6cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze plumes\n",
    "def analyze_plume(masked_data, plume_coords, transform):\n",
    "    plume_results = []\n",
    "    labeled_array, _ = label(masked_data > np.percentile(masked_data.compressed(), 65))  # Identify plumes\n",
    "    for i, (lat, lon) in enumerate(plume_coords):\n",
    "        try:\n",
    "            row, col = rasterio.transform.rowcol(transform, lon, lat)\n",
    "            row, col = int(row), int(col)\n",
    "            plume_label = labeled_array[row, col]\n",
    "            if plume_label == 0:\n",
    "                plume_results.append({\n",
    "                    \"Plume\": i + 1,\n",
    "                    \"Location (lat, lon)\": (lat, lon),\n",
    "                    \"Status\": \"No plume detected\",\n",
    "                })\n",
    "            else:\n",
    "                plume_region = labeled_array == plume_label\n",
    "                plume_values = masked_data[plume_region]\n",
    "                plume_pixels = np.column_stack(np.where(plume_region))\n",
    "\n",
    "                # Convert pixel coordinates to lat/lon\n",
    "                plume_longitudes, plume_latitudes = rasterio.transform.xy(\n",
    "                    transform, plume_pixels[:, 0], plume_pixels[:, 1]\n",
    "                )\n",
    "                points = np.array(list(zip(plume_latitudes, plume_longitudes)))\n",
    "                hull = ConvexHull(points)\n",
    "                polygon_coordinates = [(points[vertex, 0], points[vertex, 1]) for vertex in hull.vertices]\n",
    "\n",
    "                # Add polygon to the map\n",
    "                folium.Polygon(\n",
    "                    locations=polygon_coordinates,\n",
    "                    color=\"blue\",\n",
    "                    weight=1,\n",
    "                    fill=True,\n",
    "                    fill_color=\"blue\",\n",
    "                    fill_opacity=0.4,\n",
    "                    popup=f\"Plume {i + 1} region\",\n",
    "                ).add_to(m)\n",
    "\n",
    "                plume_results.append({\n",
    "                    \"Plume\": i + 1,\n",
    "                    \"Location (lat, lon)\": (lat, lon),\n",
    "                    \"Max Value\": plume_values.max(),\n",
    "                    \"Mean Value\": plume_values.mean(),\n",
    "                    \"Size (pixels)\": plume_region.sum(),\n",
    "                })\n",
    "        except Exception as e:\n",
    "            plume_results.append({\n",
    "                \"Plume\": i + 1,\n",
    "                \"Location (lat, lon)\": (lat, lon),\n",
    "                \"Status\": f\"Error: {e}\",\n",
    "            })\n",
    "    return plume_results\n",
    "\n",
    "# Perform analysis\n",
    "plume_results = analyze_plume(masked_data, plume_coords, transform)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "plume_df = pd.DataFrame([{\n",
    "    \"Plume\": result[\"Plume\"],\n",
    "    \"Location (lat, lon)\": result[\"Location (lat, lon)\"],\n",
    "    \"Max Value\": result.get(\"Max Value\", None),\n",
    "    \"Mean Value\": result.get(\"Mean Value\", None),\n",
    "    \"Size (pixels)\": result.get(\"Size (pixels)\", None),\n",
    "    \"Status\": result.get(\"Status\", \"Plume detected\"),\n",
    "} for result in plume_results])\n",
    "\n",
    "# Display DataFrame\n",
    "print(plume_df)\n",
    "\n",
    "# Add a layer control and click event\n",
    "LayerControl().add_to(m)\n",
    "m.add_child(LatLngPopup())\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562a179-7b1b-484c-8c6c-4a511807ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raster_center(tiff_path):\n",
    "    \"\"\"\n",
    "    Calculates the center of the raster's geographic bounds.\n",
    "\n",
    "    Args:\n",
    "    - tiff_path: Path to the raster file.\n",
    "\n",
    "    Returns:\n",
    "    - Center coordinates (latitude, longitude).\n",
    "    \"\"\"\n",
    "    with rasterio.open(tiff_path) as tiff_file:\n",
    "        bounds = tiff_file.bounds\n",
    "        center_lat = (bounds.top + bounds.bottom) / 2\n",
    "        center_lon = (bounds.left + bounds.right) / 2\n",
    "    return center_lat, center_lon\n",
    "\n",
    "\n",
    "def calculate_plume_width_pixels(plume_pixels, perp_direction):\n",
    "    \"\"\"\n",
    "    Calculate the plume width in pixels along the perpendicular direction to the principal axis.\n",
    "\n",
    "    Args:\n",
    "    - plume_pixels: Array of [row, col] indices of plume pixels.\n",
    "    - perp_direction: Vector [dy, dx] perpendicular to the principal axis.\n",
    "\n",
    "    Returns:\n",
    "    - Plume width in pixels.\n",
    "    \"\"\"\n",
    "    perp_vector = np.array(perp_direction)\n",
    "    perp_vector = perp_vector / np.linalg.norm(perp_vector)\n",
    "    projections = plume_pixels @ perp_vector\n",
    "    return projections.max() - projections.min()\n",
    "\n",
    "\n",
    "def calculate_cross_section_sum(plume_pixels, perp_direction, centroid, width_pixels, masked_data):\n",
    "    \"\"\"\n",
    "    Calculate the sum of pixel values along the cross-sectional width.\n",
    "\n",
    "    Args:\n",
    "    - plume_pixels: Array of [row, col] indices of plume pixels.\n",
    "    - perp_direction: Vector [dy, dx] perpendicular to the principal axis.\n",
    "    - centroid: Centroid of the plume in pixel coordinates.\n",
    "    - width_pixels: Width of the plume in pixels.\n",
    "    - masked_data: Array of pixel values.\n",
    "\n",
    "    Returns:\n",
    "    - Cross-sectional pixel sum.\n",
    "    \"\"\"\n",
    "    perp_vector = np.array(perp_direction)\n",
    "    perp_vector = perp_vector / np.linalg.norm(perp_vector)\n",
    "    cross_section_sum = 0\n",
    "    for row, col in plume_pixels:\n",
    "        pixel_point = np.array([row, col])\n",
    "        projection = np.dot(pixel_point - centroid, perp_vector)\n",
    "        if -width_pixels / 2 <= projection <= width_pixels / 2:\n",
    "            cross_section_sum += masked_data[row, col]\n",
    "    return cross_section_sum\n",
    "\n",
    "\n",
    "def analyze_plume_with_cross_section_sum(masked_data, plume_coords, transform, initial_center):\n",
    "    \"\"\"\n",
    "    Analyze plumes and calculate cross-sectional pixel sums.\n",
    "\n",
    "    Args:\n",
    "    - masked_data: The masked data array for analysis.\n",
    "    - plume_coords: List of plume centroid coordinates.\n",
    "    - transform: Affine transform of the raster.\n",
    "    - initial_center: Initial map center [latitude, longitude].\n",
    "\n",
    "    Returns:\n",
    "    - A tuple of plume analysis results and the Folium map.\n",
    "    \"\"\"\n",
    "    plume_map = folium.Map(location=initial_center, zoom_start=11, control_scale=True)\n",
    "    plume_results = []\n",
    "    labeled_array, _ = label(masked_data > np.percentile(masked_data.compressed(), 65))\n",
    "\n",
    "    for i, (lat, lon) in enumerate(plume_coords):\n",
    "        try:\n",
    "            row, col = rasterio.transform.rowcol(transform, lon, lat)\n",
    "            row, col = int(row), int(col)\n",
    "            plume_label = labeled_array[row, col]\n",
    "            if plume_label == 0:\n",
    "                plume_results.append({\"Plume\": i + 1, \"Location (lat, lon)\": (lat, lon), \"Status\": \"No plume detected\"})\n",
    "                continue\n",
    "\n",
    "            plume_region = labeled_array == plume_label\n",
    "            plume_pixels = np.column_stack(np.where(plume_region))\n",
    "            pca = PCA(n_components=2)\n",
    "            pca.fit(plume_pixels)\n",
    "            perp_direction = [-pca.components_[0, 1], pca.components_[0, 0]]\n",
    "\n",
    "            # Calculate plume width in pixels\n",
    "            plume_width_pixels = calculate_plume_width_pixels(plume_pixels, perp_direction)\n",
    "\n",
    "            # Calculate cross-sectional pixel sum\n",
    "            centroid = plume_pixels.mean(axis=0)\n",
    "            cross_section_sum = calculate_cross_section_sum(\n",
    "                plume_pixels, perp_direction, centroid, plume_width_pixels, masked_data\n",
    "            )\n",
    "\n",
    "            # Define a perpendicular line through the centroid\n",
    "            perp_line_coords = [\n",
    "                (centroid[0] - perp_direction[0] * plume_width_pixels / 2, centroid[1] - perp_direction[1] * plume_width_pixels / 2),\n",
    "                (centroid[0] + perp_direction[0] * plume_width_pixels / 2, centroid[1] + perp_direction[1] * plume_width_pixels / 2),\n",
    "            ]\n",
    "\n",
    "            # Add the perpendicular line to the map\n",
    "            perp_line_latlon = [\n",
    "                rasterio.transform.xy(transform, int(pt[0]), int(pt[1]))[::-1] for pt in perp_line_coords\n",
    "            ]\n",
    "            folium.PolyLine(\n",
    "                locations=[(lat, lon) for lat, lon in perp_line_latlon],\n",
    "                color=\"red\",\n",
    "                weight=2,\n",
    "                opacity=0.8,\n",
    "                tooltip=f\"Plume {i + 1} Width Measurement\",\n",
    "            ).add_to(plume_map)\n",
    "\n",
    "            # Add plume polygon to map\n",
    "            hull = ConvexHull(plume_pixels)\n",
    "            hull_coords = [(plume_pixels[vertex][0], plume_pixels[vertex][1]) for vertex in hull.vertices]\n",
    "            hull_latlon = [rasterio.transform.xy(transform, int(pt[0]), int(pt[1]))[::-1] for pt in hull_coords]\n",
    "            folium.Polygon(\n",
    "                locations=[(lat, lon) for lat, lon in hull_latlon],\n",
    "                color=\"blue\",\n",
    "                weight=2,\n",
    "                fill=False,\n",
    "                popup=f\"Plume {i + 1} region\",\n",
    "            ).add_to(plume_map)\n",
    "\n",
    "            plume_results.append({\n",
    "                \"Plume\": i + 1,\n",
    "                \"Location (lat, lon)\": (lat, lon),\n",
    "                \"Plume Width (pixels)\": plume_width_pixels,\n",
    "                \"Cross-Section Pixel Sum\": cross_section_sum\n",
    "            })\n",
    "        except Exception as e:\n",
    "            plume_results.append({\"Plume\": i + 1, \"Location (lat, lon)\": (lat, lon), \"Status\": f\"Error: {e}\"})\n",
    "    return plume_results, plume_map\n",
    "\n",
    "\n",
    "def add_swir_data_to_map(map_object, tiff_path):\n",
    "    \"\"\"\n",
    "    Adds SWIR data as an overlay to the map.\n",
    "\n",
    "    Args:\n",
    "    - map_object: Folium map object to overlay the SWIR data.\n",
    "    - tiff_path: Path to the SWIR TIFF file.\n",
    "    \"\"\"\n",
    "    with rasterio.open(tiff_path) as tiff_file:\n",
    "        swir_data = tiff_file.read(1)\n",
    "        bounds = tiff_file.bounds\n",
    "        nodata_value = tiff_file.nodata if tiff_file.nodata is not None else -9999\n",
    "    masked_data = np.ma.masked_equal(swir_data, nodata_value)\n",
    "    mean, std = np.nanmean(masked_data), np.nanstd(masked_data)\n",
    "    lower_bound, upper_bound = mean - 2 * std, mean + 2 * std\n",
    "    normalized_data = (masked_data - lower_bound) / (upper_bound - lower_bound)\n",
    "    normalized_data = np.clip(normalized_data, 0, 1)\n",
    "    cmap = plt.get_cmap(\"plasma\")\n",
    "    swir_rgb = (cmap(normalized_data)[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_bounds = [[bounds.bottom, bounds.left], [bounds.top, bounds.right]]\n",
    "    ImageOverlay(image=swir_rgb, bounds=image_bounds, opacity=1).add_to(map_object)\n",
    "\n",
    "\n",
    "# File path to SWIR TIFF\n",
    "swir_tiff_path = r\"C:\\GIS_Course\\Methane_Point_Detection\\Sentinel-2_Algeria_Methane\\SWIR_diff_4326.tiff\"\n",
    "\n",
    "# Get the center of the SWIR TIFF\n",
    "center_coords = get_raster_center(swir_tiff_path)\n",
    "\n",
    "# Perform plume analysis, centering the map on the SWIR TIFF\n",
    "plume_analysis_results, plume_map = analyze_plume_with_cross_section_sum(masked_data, plume_coords, transform, center_coords)\n",
    "\n",
    "# Add SWIR overlay to the map\n",
    "add_swir_data_to_map(plume_map, swir_tiff_path)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "plume_df = pd.DataFrame(plume_analysis_results)\n",
    "\n",
    "# Display DataFrame and Map\n",
    "print(plume_df)\n",
    "ipy_display(plume_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee330d5-8b44-475f-900d-d7381a6f3c03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
